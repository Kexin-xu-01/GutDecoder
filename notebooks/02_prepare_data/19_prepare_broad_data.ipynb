{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "554830f4",
   "metadata": {},
   "source": [
    "### Prepare broad data for training in /project/simmons_hts/kxu/hest/eval/data/broad/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "219917e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Standard library ---\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "# --- Third-party ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "\n",
    "# --- HEST ---\n",
    "from hest import iter_hest\n",
    "from hest.utils import get_k_genes\n",
    "from hest.HESTData import create_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eef903f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ---------- helpers ----------\n",
    "\n",
    "def _discover_samples_broad(broad_root: Path, ids: Optional[List[str]] = None) -> Dict[str, Dict[str, Path]]:\n",
    "    \"\"\"\n",
    "    Return: {sample_id: {\"adata\": Path, \"patch\": Path|None, \"vis\": Path|None}}\n",
    "    \"\"\"\n",
    "    samples = {}\n",
    "    if ids is None:\n",
    "        ids = sorted([p.name for p in Path(broad_root).iterdir() if p.is_dir()])\n",
    "\n",
    "    for sid in ids:\n",
    "        sdir = Path(broad_root) / sid\n",
    "        if not sdir.is_dir():\n",
    "            continue\n",
    "\n",
    "        adata = sdir / \"aligned_adata.h5ad\"\n",
    "        patches_dir = sdir / \"patches\"\n",
    "        vis_dir = sdir / \"patches_vis\"\n",
    "\n",
    "        patch_h5 = None\n",
    "        if patches_dir.exists():\n",
    "            cand = sorted(patches_dir.glob(\"*.h5\"))\n",
    "            if cand:\n",
    "                exact = [c for c in cand if c.name == f\"{sid}.h5\"]\n",
    "                patch_h5 = exact[0] if exact else cand[0]\n",
    "\n",
    "        vis_png = None\n",
    "        if vis_dir.exists():\n",
    "            cand = sorted(vis_dir.glob(\"*.png\"))\n",
    "            if cand:\n",
    "                exact = [c for c in cand if c.name == f\"{sid}_patch_vis.png\"]\n",
    "                vis_png = exact[0] if exact else cand[0]\n",
    "\n",
    "        if adata.exists():\n",
    "            samples[sid] = {\"adata\": adata, \"patch\": patch_h5, \"vis\": vis_png}\n",
    "\n",
    "    return samples\n",
    "\n",
    "\n",
    "def _transfer(src: Optional[Path], dst: Path, label: str, symlink: bool, missing_list: list):\n",
    "    if src is None or not Path(src).exists():\n",
    "        missing_list.append((dst.stem, label, str(src) if src is not None else \"<none>\"))\n",
    "        return\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if dst.exists():\n",
    "        dst.unlink()\n",
    "    if symlink:\n",
    "        try:\n",
    "            os.symlink(src, dst)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "    else:\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "\n",
    "def write_var_k_genes_from_paths(\n",
    "    adata_paths,\n",
    "    k,\n",
    "    criteria,\n",
    "    var_out_path,\n",
    "    all_genes_out_path=None,\n",
    "    exclude_keywords=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Load all adatas, call HEST's get_k_genes() for top-k variable genes,\n",
    "    and also save all common genes (filtered). Suppresses anndata FutureWarnings.\n",
    "\n",
    "    Args:\n",
    "        adata_paths (list[Path]): paths to aligned_adata.h5ad\n",
    "        k (int): number of top variable genes\n",
    "        criteria (str): selection criteria\n",
    "        var_out_path (Path): output path for var_k_genes.json\n",
    "        all_genes_out_path (Path|None): output path for all_genes.json\n",
    "        exclude_keywords (list[str]|None): list of substrings to filter out\n",
    "    \"\"\"\n",
    "    import scanpy as sc\n",
    "    from hest.utils import get_k_genes\n",
    "    import json, warnings\n",
    "\n",
    "    if exclude_keywords is None:\n",
    "        exclude_keywords = [\"NegControl\", \"Codeword\", \"Intergenic_Region\", \"Control\", \"BLANK\"]\n",
    "\n",
    "    # suppress FutureWarnings (e.g. is_categorical_dtype)\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"anndata\")\n",
    "\n",
    "    # Load all adatas\n",
    "    adata_list = []\n",
    "    for p in adata_paths:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "            ad = sc.read_h5ad(str(p))\n",
    "        adata_list.append(ad)\n",
    "\n",
    "    # Get top-k variable genes (writes to var_out_path)\n",
    "    _ = get_k_genes(adata_list, k, criteria, save_dir=str(var_out_path))\n",
    "\n",
    "    # Collect *all* common genes\n",
    "    common_genes = set(adata_list[0].var_names)\n",
    "    for ad in adata_list[1:]:\n",
    "        common_genes &= set(ad.var_names)\n",
    "\n",
    "    # Filter unwanted genes\n",
    "    def _keep(gene: str) -> bool:\n",
    "        for kw in exclude_keywords:\n",
    "            if kw in gene:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    filtered_genes = [g for g in common_genes if _keep(g)]\n",
    "\n",
    "    # Write all_genes.json\n",
    "    if all_genes_out_path is None:\n",
    "        all_genes_out_path = var_out_path.parent / \"all_genes.json\"\n",
    "\n",
    "    with open(all_genes_out_path, \"w\") as f:\n",
    "        json.dump({\"genes\": sorted(filtered_genes)}, f)\n",
    "\n",
    "    print(f\"[INFO] Wrote {var_out_path} (top-{k}) and {all_genes_out_path} ({len(filtered_genes)} filtered common genes)\")\n",
    "\n",
    "\n",
    "\n",
    "# ---------- main entry ----------\n",
    "\n",
    "def create_benchmark_data_broad_autodiscover(\n",
    "    save_dir: str | Path,\n",
    "    K: int,\n",
    "    broad_root: str | Path = \"/project/simmons_hts/kxu/hest/xenium_data/broad\",\n",
    "    ids: Optional[List[str]] = None,\n",
    "    gene_k: int = 50,\n",
    "    gene_criteria: str = \"var\",\n",
    "    symlink: bool = False,\n",
    "    seed: int = 0,   # for reproducible shuffling before create_splits\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a HEST benchmark package from 'broad' without a metadata DF, using HEST's create_splits & get_k_genes.\n",
    "\n",
    "    Output:\n",
    "      <save_dir>/\n",
    "        var_50genes.json\n",
    "        splits/...\n",
    "        patches/<id>.h5\n",
    "        patches/vis/<id>.png\n",
    "        adata/<id>.h5ad\n",
    "    \"\"\"\n",
    "    save_dir = Path(save_dir)\n",
    "    broad_root = Path(broad_root)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1) Discover samples\n",
    "    samples = _discover_samples_broad(broad_root, ids=ids)\n",
    "    if not samples:\n",
    "        raise ValueError(f\"No valid samples (with aligned_adata.h5ad) found under {broad_root}.\")\n",
    "    discovered_ids = sorted(samples.keys())\n",
    "    print(f\"[INFO] Discovered {len(discovered_ids)} samples: {discovered_ids}\")\n",
    "\n",
    "    # 2) Build a minimal \"metadata\" DF for splitting (patient from prefix; dataset_title='broad')\n",
    "    #    e.g., 'UC6_I' -> patient='UC6'\n",
    "    def _infer_patient(sid: str) -> str:\n",
    "        return sid.split(\"_\")[0] if \"_\" in sid else sid\n",
    "\n",
    "    meta = pd.DataFrame({\n",
    "        \"id\": discovered_ids,\n",
    "        \"patient\": [ _infer_patient(s) for s in discovered_ids ],\n",
    "        \"dataset_title\": [\"broad\"] * len(discovered_ids),\n",
    "    })\n",
    "\n",
    "    # 3) Compute var_k genes → var_50genes.json\n",
    "    adata_paths = [samples[sid][\"adata\"] for sid in discovered_ids]\n",
    "    var_json = save_dir / f\"var_{gene_k}genes.json\"\n",
    "    write_var_k_genes_from_paths(adata_paths, gene_k, gene_criteria, var_json)\n",
    "    print(f\"[INFO] Wrote {var_json}\")\n",
    "\n",
    "    # 4) K-fold splits using HEST's create_splits\n",
    "    #    HEST expects a dict mapping groups to list of sample ids.\n",
    "    #    Match your old logic: group by (dataset_title, patient)\n",
    "    group = meta.groupby([\"dataset_title\", \"patient\"])[\"id\"].agg(list).to_dict()\n",
    "    # shuffle deterministically within each group for stronger randomness\n",
    "    rng = np.random.RandomState(seed)\n",
    "    for key, id_list in group.items():\n",
    "        rng.shuffle(id_list)\n",
    "    splits_dir = save_dir / \"splits\"\n",
    "    splits_dir.mkdir(parents=True, exist_ok=True)\n",
    "    create_splits(str(splits_dir), group, K=K)\n",
    "    print(f\"[INFO] Wrote {K}-fold splits to {splits_dir}\")\n",
    "\n",
    "    # 5) Copy/symlink assets\n",
    "    (save_dir / \"patches\").mkdir(exist_ok=True, parents=True)\n",
    "    (save_dir / \"patches\" / \"vis\").mkdir(exist_ok=True, parents=True)\n",
    "    (save_dir / \"adata\").mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    missing = []\n",
    "    for sid in discovered_ids:\n",
    "        info = samples[sid]\n",
    "        _transfer(info.get(\"patch\"), save_dir / \"patches\" / f\"{sid}.h5\", \"patch\", symlink, missing)\n",
    "        _transfer(info.get(\"vis\"),   save_dir / \"patches\" / \"vis\" / f\"{sid}.png\", \"vis\",   symlink, missing)\n",
    "        _transfer(info.get(\"adata\"), save_dir / \"adata\" / f\"{sid}.h5ad\", \"adata\", symlink, missing)\n",
    "\n",
    "    if missing:\n",
    "        print(\"[WARN] Missing files:\")\n",
    "        for sid, lbl, path in missing:\n",
    "            print(f\"  - {sid} [{lbl}] → {path}\")\n",
    "\n",
    "    print(f\"✅ Benchmark dataset created at {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f577d898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Discovered 7 samples: ['DC5', 'UC1_I', 'UC1_NI', 'UC6_I', 'UC6_NI', 'UC7_I', 'UC9_I']\n",
      "min_cells is  757.0\n",
      "min_cells is  826.0\n",
      "min_cells is  695.0\n",
      "min_cells is  936.0\n",
      "min_cells is  678.0\n",
      "min_cells is  438.0\n",
      "min_cells is  1002.0\n",
      "\u001b[32m00:07:41\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mFound 404 common genes\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/package/python-cbrg/current/3.11.3/lib/python3.11/site-packages/anndata/_core/anndata.py:1830: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/package/python-cbrg/current/3.11.3/lib/python3.11/site-packages/anndata/_core/anndata.py:1830: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m00:07:41\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mselected genes ['BANK1', 'CA1', 'CA2', 'CA4', 'CCR7', 'CD19', 'CD22', 'CD3D', 'CD40LG', 'CD5', 'CD6', 'CDHR5', 'CEACAM1', 'CLCA4', 'CXCL13', 'CXCL5', 'CXCR4', 'DMBT1', 'DUOX2', 'EPCAM', 'FCER2', 'FCRLA', 'HHLA2', 'HLA-DRA', 'IGHG2', 'IGHG3', 'IGHM', 'IL23A', 'IL7R', 'KRT19', 'LEF1', 'MS4A1', 'MS4A12', 'NOS2', 'NXPE1', 'OLFM4', 'OSM', 'PENK', 'PKIB', 'PROK2', 'RAB3B', 'SDCBP2', 'SNAP25', 'SPIB', 'TCF7', 'TIGIT', 'TRAC', 'TRAT1', 'UCHL1', 'UGT2B17']\u001b[0m\n",
      "[INFO] Wrote /project/simmons_hts/kxu/hest/eval/data/broad/var_50genes.json (top-50) and /project/simmons_hts/kxu/hest/eval/data/broad/all_genes.json (460 filtered common genes)\n",
      "[INFO] Wrote /project/simmons_hts/kxu/hest/eval/data/broad/var_50genes.json\n",
      "Split 0/5\n",
      "train set is  ['UC1_NI', 'UC1_I', 'UC6_I', 'UC6_NI', 'UC7_I', 'UC9_I']\n",
      "\n",
      "test set is  ['DC5']\n",
      "\n",
      "Split 1/5\n",
      "train set is  ['DC5', 'UC6_I', 'UC6_NI', 'UC7_I', 'UC9_I']\n",
      "\n",
      "test set is  ['UC1_NI' 'UC1_I']\n",
      "\n",
      "Split 2/5\n",
      "train set is  ['DC5', 'UC1_NI', 'UC1_I', 'UC7_I', 'UC9_I']\n",
      "\n",
      "test set is  ['UC6_I' 'UC6_NI']\n",
      "\n",
      "Split 3/5\n",
      "train set is  ['DC5', 'UC1_NI', 'UC1_I', 'UC6_I', 'UC6_NI', 'UC9_I']\n",
      "\n",
      "test set is  ['UC7_I']\n",
      "\n",
      "Split 4/5\n",
      "train set is  ['DC5', 'UC1_NI', 'UC1_I', 'UC6_I', 'UC6_NI', 'UC7_I']\n",
      "\n",
      "test set is  ['UC9_I']\n",
      "\n",
      "[INFO] Wrote 5-fold splits to /project/simmons_hts/kxu/hest/eval/data/broad/splits\n",
      "✅ Benchmark dataset created at /project/simmons_hts/kxu/hest/eval/data/broad\n"
     ]
    }
   ],
   "source": [
    "create_benchmark_data_broad_autodiscover(\n",
    "    save_dir=\"/project/simmons_hts/kxu/hest/eval/data/broad\",\n",
    "    K=5, # 5 patients with 7 samples\n",
    "    broad_root=\"/project/simmons_hts/kxu/hest/xenium_data/broad\",\n",
    "    # ids=[\"UC1_I\",\"UC2_I\"],  # optionally limit to a subset\n",
    "    gene_k=50,\n",
    "    gene_criteria=\"var\",\n",
    "    symlink=False,            # set True to save disk space\n",
    "    seed=0                    # controls fold assignment deterministically\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
