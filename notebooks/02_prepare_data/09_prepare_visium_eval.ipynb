{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfc29d2c",
   "metadata": {},
   "source": [
    "### Prepare XeniumPR1_segger data for training in /project/simmons_hts/kxu/hest/eval/data/XeniumPR1_segger/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4ef3bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Standard library ---\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "# --- Third-party ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "\n",
    "# --- HEST ---\n",
    "from hest import iter_hest\n",
    "from hest.utils import get_k_genes\n",
    "from hest.HESTData import create_splits\n",
    "\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _sanitize_tag(s: str, maxlen: int = 8) -> str:\n",
    "    s2 = re.sub(r'[^A-Za-z0-9]', '', s)\n",
    "    return s2.upper()[:maxlen] or \"R\"\n",
    "\n",
    "def _extract_pr_number(path: Path) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Look for 'VisiumR<digit>' pattern in the path (case-insensitive).\n",
    "    Returns int digit (1..9) or None.\n",
    "    \"\"\"\n",
    "    m = re.search(r'VisiumR(\\d)', str(path), flags=re.IGNORECASE)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def _extract_slide_number(root: Path) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Look for 'slideN' pattern in the root folder name and return the digit as string.\n",
    "    If not found, try to infer from name like 'S1' or 's1' inside the folder name.\n",
    "    \"\"\"\n",
    "    n = root.name.lower()\n",
    "    m = re.search(r'slide[_\\-]?(\\d+)', n)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    m2 = re.search(r'\\bS(\\d+)\\b', root.name, flags=re.IGNORECASE)\n",
    "    if m2:\n",
    "        return m2.group(1)\n",
    "    return None\n",
    "\n",
    "def _discover_samples_from_roots(\n",
    "    roots: List[Path],\n",
    "    ids: Optional[List[str]] = None,\n",
    ") -> Dict[str, Dict[str, Path]]:\n",
    "    \"\"\"\n",
    "    Discover samples under multiple roots and merge into a single map.\n",
    "    \"\"\"\n",
    "    roots = [Path(r) for r in roots]\n",
    "    roots = [r for r in roots if r.exists() and r.is_dir()]\n",
    "    collected = []\n",
    "\n",
    "    if ids is None:\n",
    "        for r in sorted(roots, key=lambda p: str(p)):\n",
    "            for p in sorted([d for d in r.iterdir() if d.is_dir()], key=lambda d: d.name):\n",
    "                collected.append((r, p.name))\n",
    "    else:\n",
    "        for sid in sorted(ids):\n",
    "            for r in sorted(roots, key=lambda p: str(p)):\n",
    "                if (r / sid).is_dir():\n",
    "                    collected.append((r, sid))\n",
    "\n",
    "    samples: Dict[str, Dict[str, Path]] = {}\n",
    "    for root, sid in collected:\n",
    "        sdir = root / sid\n",
    "        adata = sdir / \"aligned_adata.h5ad\"\n",
    "        if not adata.exists():\n",
    "            continue\n",
    "\n",
    "        # pick patch .h5\n",
    "        patch_h5 = None\n",
    "        patches_dir = sdir / \"patches\"\n",
    "        if patches_dir.exists():\n",
    "            cands = sorted(patches_dir.glob(\"*.h5\"))\n",
    "            if cands:\n",
    "                exact = [c for c in cands if c.name == f\"{sid}.h5\"]\n",
    "                patch_h5 = exact[0] if exact else cands[0]\n",
    "\n",
    "        # pick vis .png\n",
    "        vis_png = None\n",
    "        vis_dir = sdir / \"patches_vis\"\n",
    "        if vis_dir.exists():\n",
    "            cands = sorted(vis_dir.glob(\"*.png\"))\n",
    "            if cands:\n",
    "                exact = [c for c in cands if c.name == f\"{sid}_patch_vis.png\"]\n",
    "                vis_png = exact[0] if exact else cands[0]\n",
    "\n",
    "        # --- Naming rule ---\n",
    "        pr_num = _extract_pr_number(root)\n",
    "        slide_num = _extract_slide_number(root) or _sanitize_tag(root.name, 3)\n",
    "\n",
    "        if pr_num is not None:\n",
    "            prefix = f\"VisiumR{pr_num}S{slide_num}\"\n",
    "        else:\n",
    "            # fallback for unknown roots\n",
    "            prefix = f\"{_sanitize_tag(root.name)}S{slide_num}\"\n",
    "\n",
    "        new_id = f\"{prefix}{sid}\"\n",
    "        if new_id in samples:\n",
    "            raise ValueError(\n",
    "                f\"Duplicate renamed sample id '{new_id}' (collision between roots for sid='{sid}').\"\n",
    "            )\n",
    "\n",
    "        samples[new_id] = {\"adata\": adata, \"patch\": patch_h5, \"vis\": vis_png}\n",
    "\n",
    "    return samples\n",
    "\n",
    "\n",
    "\n",
    "def _transfer(src: Optional[Path], dst: Path, label: str, symlink: bool, missing_list: list):\n",
    "    if src is None or not Path(src).exists():\n",
    "        missing_list.append((dst.stem, label, str(src) if src is not None else \"<none>\"))\n",
    "        return\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if dst.exists():\n",
    "        dst.unlink()\n",
    "    if symlink:\n",
    "        try:\n",
    "            os.symlink(src, dst)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "    else:\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "\n",
    "def write_var_k_genes_from_paths(\n",
    "    adata_paths,\n",
    "    k,\n",
    "    criteria,\n",
    "    var_out_path,\n",
    "    all_genes_out_path=None,\n",
    "    exclude_keywords=None,\n",
    "    filtered_common_out_path=None,\n",
    "    min_cells_pct: float = 0.10,\n",
    "):\n",
    "    \"\"\"\n",
    "    Load all adatas, call HEST's get_k_genes() for top-k genes,\n",
    "    and also save:\n",
    "      - all common genes (keyword-filtered, no expression threshold)\n",
    "      - filtered common genes using min_cells_pct across each sample\n",
    "\n",
    "    Returns:\n",
    "        (var_k_genes, all_common_genes, filtered_common_genes)\n",
    "\n",
    "    Notes:\n",
    "        - 'all_common_genes' uses only keyword filtering (like before).\n",
    "        - 'filtered_common_genes' reproduces the min_cells_pct filtering\n",
    "          logic used by get_k_genes: for each AnnData, genes not expressed\n",
    "          in at least ceil(min_cells_pct * n_obs) spots are removed,\n",
    "          then we intersect across samples, and finally drop BLANK/Control.\n",
    "    \"\"\"\n",
    "    import json, warnings\n",
    "    import numpy as np\n",
    "    import scanpy as sc\n",
    "    from hest.utils import get_k_genes\n",
    "\n",
    "    if exclude_keywords is None:\n",
    "        exclude_keywords = [\"NegControl\", \"Codeword\", \"Intergenic_Region\", \"Control\", \"BLANK\"]\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"anndata\")\n",
    "\n",
    "    # ---- Load all adatas\n",
    "    adata_list = []\n",
    "    for p in adata_paths:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "            ad = sc.read_h5ad(str(p))\n",
    "        adata_list.append(ad)\n",
    "\n",
    "    # ---- Top-k variable/mean genes (delegates JSON writing to get_k_genes if var_out_path is a file path)\n",
    "    var_k_genes = get_k_genes(adata_list, k, criteria, save_dir=str(var_out_path), min_cells_pct=min_cells_pct)\n",
    "\n",
    "    # ---- ALL common genes (keyword-filtered only; preserves your original behavior)\n",
    "    common_genes = set(adata_list[0].var_names)\n",
    "    for ad in adata_list[1:]:\n",
    "        common_genes &= set(ad.var_names)\n",
    "\n",
    "    def _keep_keyword(gene: str) -> bool:\n",
    "        for kw in exclude_keywords:\n",
    "            if kw in gene:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    all_common_genes = sorted([g for g in common_genes if _keep_keyword(g)])\n",
    "\n",
    "    # ---- Filtered common genes (expression threshold per sample, then intersect)\n",
    "    filtered_sets = []\n",
    "    for ad in adata_list:\n",
    "        # work on a shallow copy to avoid mutating caller's object\n",
    "        ad_tmp = ad[:, :].copy()\n",
    "        min_cells = int(np.ceil(min_cells_pct * ad_tmp.n_obs)) if min_cells_pct else 0\n",
    "        if min_cells > 0:\n",
    "            sc.pp.filter_genes(ad_tmp, min_cells=min_cells)\n",
    "        filtered_sets.append(set(ad_tmp.var_names))\n",
    "\n",
    "    filtered_common = set.intersection(*filtered_sets) if filtered_sets else set()\n",
    "    # remove BLANK/Control like in get_k_genes\n",
    "    filtered_common_genes = sorted(\n",
    "        [g for g in filtered_common if (\"BLANK\" not in g and \"Control\" not in g)]\n",
    "    )\n",
    "\n",
    "    # ---- Write JSONs\n",
    "    if all_genes_out_path is None:\n",
    "        all_genes_out_path = Path(var_out_path).parent / \"all_genes.json\"\n",
    "    with open(all_genes_out_path, \"w\") as f:\n",
    "        json.dump({\"genes\": all_common_genes}, f)\n",
    "\n",
    "    if filtered_common_out_path is None:\n",
    "        filtered_common_out_path = Path(var_out_path).parent / \"common_genes_0.1.json\"\n",
    "    with open(filtered_common_out_path, \"w\") as f:\n",
    "        json.dump({\"genes\": filtered_common_genes, \"min_cells_pct\": min_cells_pct}, f)\n",
    "\n",
    "    print(\n",
    "        f\"[INFO] Wrote {var_out_path} (top-{k}, criteria={criteria}); \"\n",
    "        f\"{all_genes_out_path} (all_common={len(all_common_genes)}); \"\n",
    "        f\"{filtered_common_out_path} (filtered_common={len(filtered_common_genes)}, min_cells_pct={min_cells_pct})\"\n",
    "    )\n",
    "\n",
    "    return var_k_genes, all_common_genes, filtered_common_genes\n",
    "\n",
    "\n",
    "# ---------- main entry ----------\n",
    "\n",
    "def create_benchmark_data_multislide(\n",
    "    save_dir: str | Path,\n",
    "    K: int,\n",
    "    base_root: str | Path = \"sftp://login1.molbiol.ox.ac.uk/ceph/project/simmons_hts/kxu/hest/xenium_data/XeniumPR1_segger\",\n",
    "    slide_subdirs: List[str] | tuple = (\"slide1\", \"slide2\"),\n",
    "    ids: Optional[List[str]] = None,\n",
    "    gene_k: int = 50,\n",
    "    gene_criteria: str = \"var\",\n",
    "    symlink: bool = False,\n",
    "    seed: int = 0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a HEST benchmark package from both slide1 and slide2 under the XeniumPR1_segger tree\n",
    "    (or any set of slide subfolders you pass), without relying on a prebuilt metadata DF.\n",
    "\n",
    "    Expected layout:\n",
    "        <base_root>/slide1/<sample_id>/...\n",
    "        <base_root>/slide2/<sample_id>/...\n",
    "\n",
    "    Output tree:\n",
    "      <save_dir>/\n",
    "        var_50genes.json\n",
    "        splits/...\n",
    "        patches/<id>.h5\n",
    "        patches/vis/<id>.png\n",
    "        adata/<id>.h5ad\n",
    "\n",
    "    Args:\n",
    "        save_dir: destination directory for the assembled benchmark package\n",
    "        K: number of folds for HEST's create_splits\n",
    "        base_root: base directory containing slide subfolders\n",
    "        slide_subdirs: which slide folders to include (defaults to [\"slide1\", \"slide2\"])\n",
    "        ids: optional list of sample IDs to include (if None, auto-discovers)\n",
    "        gene_k: number of variable genes to select\n",
    "        gene_criteria: criteria for get_k_genes (e.g., \"var\")\n",
    "        symlink: if True, symlink files instead of copying\n",
    "        seed: RNG seed used to deterministically shuffle within groups before splitting\n",
    "    \"\"\"\n",
    "    \n",
    "    from hest.HESTData import create_splits\n",
    "\n",
    "    save_dir = Path(save_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1) Build slide roots list and discover samples across them\n",
    "    base_root = Path(base_root)\n",
    "    roots = [base_root / sd for sd in slide_subdirs]\n",
    "    print(f\"[INFO] Using slide roots: {roots}\")\n",
    "\n",
    "    samples = _discover_samples_from_roots(roots, ids=ids)\n",
    "    if not samples:\n",
    "        raise ValueError(\n",
    "            f\"No valid samples (with aligned_adata.h5ad) found under any of: {roots}.\"\n",
    "        )\n",
    "    discovered_ids = sorted(samples.keys())\n",
    "    print(f\"[INFO] Discovered {len(discovered_ids)} samples: {discovered_ids}\")\n",
    "\n",
    "    # 2) Minimal metadata DF for splitting (patient from prefix; dataset_title from base folder name)\n",
    "    def _infer_patient(sid: str) -> str:\n",
    "        return sid.split(\"_\")[0] if \"_\" in sid else sid\n",
    "\n",
    "    dataset_title = base_root.name or \"xenium\"\n",
    "    meta = pd.DataFrame(\n",
    "        {\n",
    "            \"id\": discovered_ids,\n",
    "            \"patient\": [_infer_patient(s) for s in discovered_ids],\n",
    "            \"dataset_title\": [dataset_title] * len(discovered_ids),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # 3) Compute var_k genes → var_50genes.json\n",
    "    adata_paths = [samples[sid][\"adata\"] for sid in discovered_ids]\n",
    "    var_json = save_dir / f\"var_{gene_k}genes.json\"\n",
    "    write_var_k_genes_from_paths(adata_paths, gene_k, gene_criteria, var_json)\n",
    "    print(f\"[INFO] Wrote {var_json}\")\n",
    "\n",
    "    # 4) K-fold splits using HEST's create_splits\n",
    "    #    Group by (dataset_title, patient)\n",
    "    group = meta.groupby([\"dataset_title\", \"patient\"])[\"id\"].agg(list).to_dict()\n",
    "\n",
    "    # Deterministic shuffle within each group\n",
    "    rng = np.random.RandomState(seed)\n",
    "    for key, id_list in group.items():\n",
    "        rng.shuffle(id_list)\n",
    "\n",
    "    splits_dir = save_dir / \"splits\"\n",
    "    splits_dir.mkdir(parents=True, exist_ok=True)\n",
    "    create_splits(str(splits_dir), group, K=K)\n",
    "    print(f\"[INFO] Wrote {K}-fold splits to {splits_dir}\")\n",
    "\n",
    "    # 5) Copy/symlink assets\n",
    "    (save_dir / \"patches\").mkdir(exist_ok=True, parents=True)\n",
    "    (save_dir / \"patches\" / \"vis\").mkdir(exist_ok=True, parents=True)\n",
    "    (save_dir / \"adata\").mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    missing: List[tuple] = []\n",
    "    for sid in discovered_ids:\n",
    "        info = samples[sid]\n",
    "        _transfer(info.get(\"patch\"), save_dir / \"patches\" / f\"{sid}.h5\", \"patch\", symlink, missing, overwrite=False)\n",
    "        _transfer(info.get(\"vis\"), save_dir / \"patches\" / \"vis\" / f\"{sid}.png\", \"vis\", symlink, missing, overwrite=False)\n",
    "        _transfer(info.get(\"adata\"), save_dir / \"adata\" / f\"{sid}.h5ad\", \"adata\", symlink, missing, overwrite=False)\n",
    "\n",
    "    if missing:\n",
    "        print(\"[WARN] Missing files:\")\n",
    "        for sid, lbl, path in missing:\n",
    "            print(f\"  - {sid} [{lbl}] → {path}\")\n",
    "\n",
    "    print(f\"✅ Benchmark dataset created at {save_dir}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "772abed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using slide roots: [PosixPath('/project/simmons_hts/kxu/hest/visium_data/VisiumR1/slide1'), PosixPath('/project/simmons_hts/kxu/hest/visium_data/VisiumR1/slide2')]\n",
      "[INFO] Discovered 4 samples: ['VisiumR1S1ROI1', 'VisiumR1S1ROI2', 'VisiumR1S1ROI3', 'VisiumR1S1ROI4']\n",
      "min_cells is  173.0\n",
      "min_cells is  163.0\n",
      "min_cells is  175.0\n",
      "min_cells is  134.0\n",
      "\u001b[32m12:20:13\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mFound 643 common genes\u001b[0m\n",
      "\u001b[32m12:20:14\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mselected genes ['APLP2', 'ARF4', 'ATP1B1', 'ATP6V0D1', 'C1QC', 'CAST', 'CCNL1', 'CLU', 'COX6A1', 'CREB3L1', 'CTSZ', 'DEFA5', 'ECE1', 'EFHD2', 'ETFB', 'FAM102A', 'FN1', 'FTH1', 'GADD45B', 'GNB1', 'HIST1H4A', 'HLA-DRA', 'HSPB6', 'IER3', 'IER5', 'IGFBP5', 'ISG20', 'JPT1', 'LGALS3', 'LYZ', 'MAP1B', 'MBOAT7', 'OGN', 'PEX26', 'PLA2G2A', 'PRR13', 'RAB5A', 'REG1A', 'RHOG', 'SAT1', 'SERPINB6', 'SMTN', 'STAT6', 'TCF7L2', 'TIMP3', 'TNFRSF1A', 'TNFRSF21', 'TNIP1', 'VAMP8', 'VASP']\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Wrote /project/simmons_hts/kxu/hest/eval/data/VisiumR1/var_50genes.json (top-50, criteria=var); /project/simmons_hts/kxu/hest/eval/data/VisiumR1/all_genes.json (all_common=17943); /project/simmons_hts/kxu/hest/eval/data/VisiumR1/common_genes_0.1.json (filtered_common=643, min_cells_pct=0.1)\n",
      "[INFO] Wrote /project/simmons_hts/kxu/hest/eval/data/VisiumR1/var_50genes.json\n",
      "K=15 doesnt match the number of patients, try to distribute the patients instead\n",
      "Split 0/4\n",
      "train set is  ['VisiumR1S1ROI2', 'VisiumR1S1ROI3', 'VisiumR1S1ROI4']\n",
      "\n",
      "test set is  ['VisiumR1S1ROI1']\n",
      "\n",
      "Split 1/4\n",
      "train set is  ['VisiumR1S1ROI1', 'VisiumR1S1ROI3', 'VisiumR1S1ROI4']\n",
      "\n",
      "test set is  ['VisiumR1S1ROI2']\n",
      "\n",
      "Split 2/4\n",
      "train set is  ['VisiumR1S1ROI1', 'VisiumR1S1ROI2', 'VisiumR1S1ROI4']\n",
      "\n",
      "test set is  ['VisiumR1S1ROI3']\n",
      "\n",
      "Split 3/4\n",
      "train set is  ['VisiumR1S1ROI1', 'VisiumR1S1ROI2', 'VisiumR1S1ROI3']\n",
      "\n",
      "test set is  ['VisiumR1S1ROI4']\n",
      "\n",
      "[INFO] Wrote 15-fold splits to /project/simmons_hts/kxu/hest/eval/data/VisiumR1/splits\n",
      "✅ Benchmark dataset created at /project/simmons_hts/kxu/hest/eval/data/VisiumR1\n"
     ]
    }
   ],
   "source": [
    "create_benchmark_data_multislide(\n",
    "    save_dir=\"/project/simmons_hts/kxu/hest/eval/data/VisiumR1\",\n",
    "    K=15, \n",
    "    base_root=\"/project/simmons_hts/kxu/hest/visium_data/VisiumR1\",\n",
    "    gene_k=50,\n",
    "    gene_criteria=\"var\",\n",
    "    symlink=False,            # set True to save disk space\n",
    "    seed=0                    # controls fold assignment deterministically\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2ea31dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using slide roots: [PosixPath('/project/simmons_hts/kxu/hest/visium_data/VisiumR1/slide1'), PosixPath('/project/simmons_hts/kxu/hest/visium_data/VisiumR1/slide2')]\n",
      "[INFO] Discovered 4 samples: ['VisiumR1S1ROI1', 'VisiumR1S1ROI2', 'VisiumR1S1ROI3', 'VisiumR1S1ROI4']\n",
      "min_cells is  173.0\n",
      "min_cells is  163.0\n",
      "min_cells is  175.0\n",
      "min_cells is  134.0\n",
      "\u001b[32m12:21:35\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mFound 643 common genes\u001b[0m\n",
      "\u001b[32m12:21:36\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mselected genes ['APLP2', 'ARF4', 'ATP1B1', 'ATP6V0D1', 'C1QC', 'CAST', 'CCNL1', 'CLU', 'COX6A1', 'CREB3L1', 'CTSZ', 'DEFA5', 'ECE1', 'EFHD2', 'ETFB', 'FAM102A', 'FN1', 'FTH1', 'GADD45B', 'GNB1', 'HIST1H4A', 'HLA-DRA', 'HSPB6', 'IER3', 'IER5', 'IGFBP5', 'ISG20', 'JPT1', 'LGALS3', 'LYZ', 'MAP1B', 'MBOAT7', 'OGN', 'PEX26', 'PLA2G2A', 'PRR13', 'RAB5A', 'REG1A', 'RHOG', 'SAT1', 'SERPINB6', 'SMTN', 'STAT6', 'TCF7L2', 'TIMP3', 'TNFRSF1A', 'TNFRSF21', 'TNIP1', 'VAMP8', 'VASP']\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Wrote /project/simmons_hts/kxu/hest/eval/data/VisiumR1/var_50genes.json (top-50, criteria=var); /project/simmons_hts/kxu/hest/eval/data/VisiumR1/all_genes.json (all_common=17943); /project/simmons_hts/kxu/hest/eval/data/VisiumR1/common_genes_0.1.json (filtered_common=643, min_cells_pct=0.1)\n",
      "[INFO] Wrote /project/simmons_hts/kxu/hest/eval/data/VisiumR1/var_50genes.json\n",
      "K=15 doesnt match the number of patients, try to distribute the patients instead\n",
      "Split 0/4\n",
      "train set is  ['VisiumR1S1ROI2', 'VisiumR1S1ROI3', 'VisiumR1S1ROI4']\n",
      "\n",
      "test set is  ['VisiumR1S1ROI1']\n",
      "\n",
      "Split 1/4\n",
      "train set is  ['VisiumR1S1ROI1', 'VisiumR1S1ROI3', 'VisiumR1S1ROI4']\n",
      "\n",
      "test set is  ['VisiumR1S1ROI2']\n",
      "\n",
      "Split 2/4\n",
      "train set is  ['VisiumR1S1ROI1', 'VisiumR1S1ROI2', 'VisiumR1S1ROI4']\n",
      "\n",
      "test set is  ['VisiumR1S1ROI3']\n",
      "\n",
      "Split 3/4\n",
      "train set is  ['VisiumR1S1ROI1', 'VisiumR1S1ROI2', 'VisiumR1S1ROI3']\n",
      "\n",
      "test set is  ['VisiumR1S1ROI4']\n",
      "\n",
      "[INFO] Wrote 15-fold splits to /project/simmons_hts/kxu/hest/eval/data/VisiumR1/splits\n",
      "✅ Benchmark dataset created at /project/simmons_hts/kxu/hest/eval/data/VisiumR1\n",
      "[INFO] Using slide roots: [PosixPath('/project/simmons_hts/kxu/hest/visium_data/VisiumR2/slide1'), PosixPath('/project/simmons_hts/kxu/hest/visium_data/VisiumR2/slide2')]\n",
      "[INFO] Discovered 8 samples: ['VisiumR2S1ROI1', 'VisiumR2S1ROI2', 'VisiumR2S1ROI3', 'VisiumR2S1ROI4', 'VisiumR2S2ROI1', 'VisiumR2S2ROI2', 'VisiumR2S2ROI3', 'VisiumR2S2ROI4']\n",
      "min_cells is  295.0\n",
      "min_cells is  455.0\n",
      "min_cells is  460.0\n",
      "min_cells is  462.0\n",
      "min_cells is  274.0\n",
      "min_cells is  382.0\n",
      "min_cells is  280.0\n",
      "min_cells is  393.0\n",
      "\u001b[32m12:21:42\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mFound 130 common genes\u001b[0m\n",
      "\u001b[32m12:21:44\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mselected genes ['ACTA2', 'ATP5PD', 'B2M', 'CAPN1', 'CD74', 'CFD', 'CHCHD2', 'CIRBP', 'CNDP2', 'COL1A2', 'COX5B', 'COX8A', 'CTSD', 'CYC1', 'CYCS', 'EDF1', 'EEF1B2', 'EIF4A1', 'ENO1', 'FKBP8', 'FLNA', 'FN1', 'FTH1', 'GOLM1', 'GSN', 'GSTP1', 'HDGF', 'HNRNPA3', 'HSPB1', 'IFNGR2', 'IGKC', 'IL32', 'LASP1', 'LGALS3BP', 'LRP10', 'MT1X', 'MT2A', 'NDUFB7', 'P4HB', 'PABPC1', 'PNPLA2', 'POR', 'RBM3', 'S100A6', 'TAGLN2', 'TMSB4X', 'TPM1', 'UBA52', 'UBC', 'VDAC1']\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Wrote /project/simmons_hts/kxu/hest/eval/data/VisiumR2/var_50genes.json (top-50, criteria=var); /project/simmons_hts/kxu/hest/eval/data/VisiumR2/all_genes.json (all_common=17943); /project/simmons_hts/kxu/hest/eval/data/VisiumR2/common_genes_0.1.json (filtered_common=130, min_cells_pct=0.1)\n",
      "[INFO] Wrote /project/simmons_hts/kxu/hest/eval/data/VisiumR2/var_50genes.json\n",
      "K=15 doesnt match the number of patients, try to distribute the patients instead\n",
      "Split 0/8\n",
      "train set is  ['VisiumR2S1ROI2', 'VisiumR2S1ROI3', 'VisiumR2S1ROI4', 'VisiumR2S2ROI1', 'VisiumR2S2ROI2', 'VisiumR2S2ROI3', 'VisiumR2S2ROI4']\n",
      "\n",
      "test set is  ['VisiumR2S1ROI1']\n",
      "\n",
      "Split 1/8\n",
      "train set is  ['VisiumR2S1ROI1', 'VisiumR2S1ROI3', 'VisiumR2S1ROI4', 'VisiumR2S2ROI1', 'VisiumR2S2ROI2', 'VisiumR2S2ROI3', 'VisiumR2S2ROI4']\n",
      "\n",
      "test set is  ['VisiumR2S1ROI2']\n",
      "\n",
      "Split 2/8\n",
      "train set is  ['VisiumR2S1ROI1', 'VisiumR2S1ROI2', 'VisiumR2S1ROI4', 'VisiumR2S2ROI1', 'VisiumR2S2ROI2', 'VisiumR2S2ROI3', 'VisiumR2S2ROI4']\n",
      "\n",
      "test set is  ['VisiumR2S1ROI3']\n",
      "\n",
      "Split 3/8\n",
      "train set is  ['VisiumR2S1ROI1', 'VisiumR2S1ROI2', 'VisiumR2S1ROI3', 'VisiumR2S2ROI1', 'VisiumR2S2ROI2', 'VisiumR2S2ROI3', 'VisiumR2S2ROI4']\n",
      "\n",
      "test set is  ['VisiumR2S1ROI4']\n",
      "\n",
      "Split 4/8\n",
      "train set is  ['VisiumR2S1ROI1', 'VisiumR2S1ROI2', 'VisiumR2S1ROI3', 'VisiumR2S1ROI4', 'VisiumR2S2ROI2', 'VisiumR2S2ROI3', 'VisiumR2S2ROI4']\n",
      "\n",
      "test set is  ['VisiumR2S2ROI1']\n",
      "\n",
      "Split 5/8\n",
      "train set is  ['VisiumR2S1ROI1', 'VisiumR2S1ROI2', 'VisiumR2S1ROI3', 'VisiumR2S1ROI4', 'VisiumR2S2ROI1', 'VisiumR2S2ROI3', 'VisiumR2S2ROI4']\n",
      "\n",
      "test set is  ['VisiumR2S2ROI2']\n",
      "\n",
      "Split 6/8\n",
      "train set is  ['VisiumR2S1ROI1', 'VisiumR2S1ROI2', 'VisiumR2S1ROI3', 'VisiumR2S1ROI4', 'VisiumR2S2ROI1', 'VisiumR2S2ROI2', 'VisiumR2S2ROI4']\n",
      "\n",
      "test set is  ['VisiumR2S2ROI3']\n",
      "\n",
      "Split 7/8\n",
      "train set is  ['VisiumR2S1ROI1', 'VisiumR2S1ROI2', 'VisiumR2S1ROI3', 'VisiumR2S1ROI4', 'VisiumR2S2ROI1', 'VisiumR2S2ROI2', 'VisiumR2S2ROI3']\n",
      "\n",
      "test set is  ['VisiumR2S2ROI4']\n",
      "\n",
      "[INFO] Wrote 15-fold splits to /project/simmons_hts/kxu/hest/eval/data/VisiumR2/splits\n",
      "✅ Benchmark dataset created at /project/simmons_hts/kxu/hest/eval/data/VisiumR2\n",
      "[INFO] Using slide roots: [PosixPath('/project/simmons_hts/kxu/hest/visium_data/VisiumR3/slide1'), PosixPath('/project/simmons_hts/kxu/hest/visium_data/VisiumR3/slide2')]\n",
      "[INFO] Discovered 4 samples: ['VisiumR3S1ROI1', 'VisiumR3S1ROI2', 'VisiumR3S1ROI3', 'VisiumR3S1ROI4']\n",
      "min_cells is  282.0\n",
      "min_cells is  421.0\n",
      "min_cells is  389.0\n",
      "min_cells is  382.0\n",
      "\u001b[32m12:22:15\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mFound 2388 common genes\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m12:22:17\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mselected genes ['ADAMTS1', 'ADIRF', 'ALDH1B1', 'ATP8B1', 'BHLHE40', 'C1QB', 'C7', 'CAV1', 'CD68', 'CD9', 'CDC42EP5', 'CNN1', 'CRYAB', 'CTSC', 'CTSS', 'DSTN', 'FBP1', 'FXYD1', 'HAND2', 'HBA2', 'HIST1H2BN', 'HIST1H4A', 'HSPA1B', 'IER2', 'IGF1', 'IGLV3-1', 'ITGB2', 'LYZ', 'MAP1B', 'MFSD11', 'NUCKS1', 'OGN', 'PALLD', 'PGD', 'PGM5', 'PMP22', 'PRUNE2', 'PSMB10', 'RGS1', 'S100A8', 'S100A9', 'SDC4', 'SELENOP', 'SFRP4', 'SLMAP', 'SORBS1', 'ST6GALNAC6', 'SVIL', 'SYNM', 'TPSB2']\u001b[0m\n",
      "[INFO] Wrote /project/simmons_hts/kxu/hest/eval/data/VisiumR3/var_50genes.json (top-50, criteria=var); /project/simmons_hts/kxu/hest/eval/data/VisiumR3/all_genes.json (all_common=17943); /project/simmons_hts/kxu/hest/eval/data/VisiumR3/common_genes_0.1.json (filtered_common=2388, min_cells_pct=0.1)\n",
      "[INFO] Wrote /project/simmons_hts/kxu/hest/eval/data/VisiumR3/var_50genes.json\n",
      "K=15 doesnt match the number of patients, try to distribute the patients instead\n",
      "Split 0/4\n",
      "train set is  ['VisiumR3S1ROI2', 'VisiumR3S1ROI3', 'VisiumR3S1ROI4']\n",
      "\n",
      "test set is  ['VisiumR3S1ROI1']\n",
      "\n",
      "Split 1/4\n",
      "train set is  ['VisiumR3S1ROI1', 'VisiumR3S1ROI3', 'VisiumR3S1ROI4']\n",
      "\n",
      "test set is  ['VisiumR3S1ROI2']\n",
      "\n",
      "Split 2/4\n",
      "train set is  ['VisiumR3S1ROI1', 'VisiumR3S1ROI2', 'VisiumR3S1ROI4']\n",
      "\n",
      "test set is  ['VisiumR3S1ROI3']\n",
      "\n",
      "Split 3/4\n",
      "train set is  ['VisiumR3S1ROI1', 'VisiumR3S1ROI2', 'VisiumR3S1ROI3']\n",
      "\n",
      "test set is  ['VisiumR3S1ROI4']\n",
      "\n",
      "[INFO] Wrote 15-fold splits to /project/simmons_hts/kxu/hest/eval/data/VisiumR3/splits\n",
      "✅ Benchmark dataset created at /project/simmons_hts/kxu/hest/eval/data/VisiumR3\n",
      "[INFO] Using slide roots: [PosixPath('/project/simmons_hts/kxu/hest/visium_data/VisiumR4/slide1'), PosixPath('/project/simmons_hts/kxu/hest/visium_data/VisiumR4/slide2')]\n",
      "[INFO] Discovered 4 samples: ['VisiumR4S1ROI1', 'VisiumR4S1ROI2', 'VisiumR4S1ROI3', 'VisiumR4S1ROI4']\n",
      "min_cells is  381.0\n",
      "min_cells is  461.0\n",
      "min_cells is  493.0\n",
      "min_cells is  428.0\n",
      "\u001b[32m12:22:34\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mFound 3907 common genes\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m12:22:38\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mselected genes ['ATP5MC3', 'BAG3', 'CCT2', 'CLTB', 'CRABP2', 'CSTB', 'CTNNBIP1', 'CYB5R1', 'DNAJA4', 'DNAJB1', 'DST', 'EBNA1BP2', 'EIF2S3', 'EIF4A3', 'ERO1A', 'FLNB', 'FSCN1', 'GJA1', 'GLTP', 'HEBP2', 'HSPA1B', 'HSPH1', 'ID1', 'IGFBP3', 'ITGA3', 'KPNA2', 'KRT10', 'KTN1', 'MYL12B', 'MYO1B', 'NAA20', 'NDRG1', 'ODC1', 'PLS3', 'PNP', 'PRNP', 'PRXL2A', 'PSMB6', 'PTBP3', 'RAB10', 'S100A16', 'SCD', 'SF3B6', 'SLC25A39', 'SLC38A2', 'TRAP1', 'TSTA3', 'TUBA4A', 'TXN', 'TXNDC17']\u001b[0m\n",
      "[INFO] Wrote /project/simmons_hts/kxu/hest/eval/data/VisiumR4/var_50genes.json (top-50, criteria=var); /project/simmons_hts/kxu/hest/eval/data/VisiumR4/all_genes.json (all_common=17943); /project/simmons_hts/kxu/hest/eval/data/VisiumR4/common_genes_0.1.json (filtered_common=3907, min_cells_pct=0.1)\n",
      "[INFO] Wrote /project/simmons_hts/kxu/hest/eval/data/VisiumR4/var_50genes.json\n",
      "K=15 doesnt match the number of patients, try to distribute the patients instead\n",
      "Split 0/4\n",
      "train set is  ['VisiumR4S1ROI2', 'VisiumR4S1ROI3', 'VisiumR4S1ROI4']\n",
      "\n",
      "test set is  ['VisiumR4S1ROI1']\n",
      "\n",
      "Split 1/4\n",
      "train set is  ['VisiumR4S1ROI1', 'VisiumR4S1ROI3', 'VisiumR4S1ROI4']\n",
      "\n",
      "test set is  ['VisiumR4S1ROI2']\n",
      "\n",
      "Split 2/4\n",
      "train set is  ['VisiumR4S1ROI1', 'VisiumR4S1ROI2', 'VisiumR4S1ROI4']\n",
      "\n",
      "test set is  ['VisiumR4S1ROI3']\n",
      "\n",
      "Split 3/4\n",
      "train set is  ['VisiumR4S1ROI1', 'VisiumR4S1ROI2', 'VisiumR4S1ROI3']\n",
      "\n",
      "test set is  ['VisiumR4S1ROI4']\n",
      "\n",
      "[INFO] Wrote 15-fold splits to /project/simmons_hts/kxu/hest/eval/data/VisiumR4/splits\n",
      "✅ Benchmark dataset created at /project/simmons_hts/kxu/hest/eval/data/VisiumR4\n",
      "[INFO] Using slide roots: [PosixPath('/project/simmons_hts/kxu/hest/visium_data/VisiumR5/slide1'), PosixPath('/project/simmons_hts/kxu/hest/visium_data/VisiumR5/slide2')]\n",
      "[INFO] Discovered 7 samples: ['VisiumR5S1ROI1', 'VisiumR5S1ROI2', 'VisiumR5S1ROI3', 'VisiumR5S1ROI4', 'VisiumR5S2ROI1', 'VisiumR5S2ROI2', 'VisiumR5S2ROI3']\n",
      "min_cells is  432.0\n",
      "min_cells is  225.0\n",
      "min_cells is  413.0\n",
      "min_cells is  253.0\n",
      "min_cells is  406.0\n",
      "min_cells is  235.0\n",
      "min_cells is  191.0\n",
      "\u001b[32m12:23:00\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mFound 2951 common genes\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m12:23:05\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mselected genes ['ANPEP', 'APOL1', 'BAG3', 'BHLHE40', 'BLMH', 'BST2', 'C1QB', 'CD82', 'CD9', 'CFB', 'CLEC3B', 'COX7B', 'CSTB', 'CTNNBIP1', 'CYB5R1', 'DYNLL1', 'EIF3K', 'GM2A', 'HIST1H2BD', 'HIST1H4I', 'HIST2H2AB', 'HRAS', 'IFI27', 'IFI6', 'IFITM1', 'IGFBP3', 'IMPDH2', 'INSIG1', 'KPNA2', 'LMNB2', 'LY6E', 'MYL12B', 'NDRG1', 'NDUFB9', 'OAT', 'PML', 'PRXL2A', 'PSMA2', 'PSMB6', 'PSMB8', 'RAB3D', 'RUVBL2', 'S100A16', 'SELENOP', 'TAP1', 'TDP2', 'TRAP1', 'UBE2L6', 'WARS', 'ZC3H12A']\u001b[0m\n",
      "[INFO] Wrote /project/simmons_hts/kxu/hest/eval/data/VisiumR5/var_50genes.json (top-50, criteria=var); /project/simmons_hts/kxu/hest/eval/data/VisiumR5/all_genes.json (all_common=17943); /project/simmons_hts/kxu/hest/eval/data/VisiumR5/common_genes_0.1.json (filtered_common=2951, min_cells_pct=0.1)\n",
      "[INFO] Wrote /project/simmons_hts/kxu/hest/eval/data/VisiumR5/var_50genes.json\n",
      "K=15 doesnt match the number of patients, try to distribute the patients instead\n",
      "Split 0/7\n",
      "train set is  ['VisiumR5S1ROI2', 'VisiumR5S1ROI3', 'VisiumR5S1ROI4', 'VisiumR5S2ROI1', 'VisiumR5S2ROI2', 'VisiumR5S2ROI3']\n",
      "\n",
      "test set is  ['VisiumR5S1ROI1']\n",
      "\n",
      "Split 1/7\n",
      "train set is  ['VisiumR5S1ROI1', 'VisiumR5S1ROI3', 'VisiumR5S1ROI4', 'VisiumR5S2ROI1', 'VisiumR5S2ROI2', 'VisiumR5S2ROI3']\n",
      "\n",
      "test set is  ['VisiumR5S1ROI2']\n",
      "\n",
      "Split 2/7\n",
      "train set is  ['VisiumR5S1ROI1', 'VisiumR5S1ROI2', 'VisiumR5S1ROI4', 'VisiumR5S2ROI1', 'VisiumR5S2ROI2', 'VisiumR5S2ROI3']\n",
      "\n",
      "test set is  ['VisiumR5S1ROI3']\n",
      "\n",
      "Split 3/7\n",
      "train set is  ['VisiumR5S1ROI1', 'VisiumR5S1ROI2', 'VisiumR5S1ROI3', 'VisiumR5S2ROI1', 'VisiumR5S2ROI2', 'VisiumR5S2ROI3']\n",
      "\n",
      "test set is  ['VisiumR5S1ROI4']\n",
      "\n",
      "Split 4/7\n",
      "train set is  ['VisiumR5S1ROI1', 'VisiumR5S1ROI2', 'VisiumR5S1ROI3', 'VisiumR5S1ROI4', 'VisiumR5S2ROI2', 'VisiumR5S2ROI3']\n",
      "\n",
      "test set is  ['VisiumR5S2ROI1']\n",
      "\n",
      "Split 5/7\n",
      "train set is  ['VisiumR5S1ROI1', 'VisiumR5S1ROI2', 'VisiumR5S1ROI3', 'VisiumR5S1ROI4', 'VisiumR5S2ROI1', 'VisiumR5S2ROI3']\n",
      "\n",
      "test set is  ['VisiumR5S2ROI2']\n",
      "\n",
      "Split 6/7\n",
      "train set is  ['VisiumR5S1ROI1', 'VisiumR5S1ROI2', 'VisiumR5S1ROI3', 'VisiumR5S1ROI4', 'VisiumR5S2ROI1', 'VisiumR5S2ROI2']\n",
      "\n",
      "test set is  ['VisiumR5S2ROI3']\n",
      "\n",
      "[INFO] Wrote 15-fold splits to /project/simmons_hts/kxu/hest/eval/data/VisiumR5/splits\n",
      "✅ Benchmark dataset created at /project/simmons_hts/kxu/hest/eval/data/VisiumR5\n",
      "[INFO] Using slide roots: [PosixPath('/project/simmons_hts/kxu/hest/visium_data/VisiumR6/slide1'), PosixPath('/project/simmons_hts/kxu/hest/visium_data/VisiumR6/slide2')]\n",
      "[INFO] Discovered 8 samples: ['VisiumR6S1ROI1', 'VisiumR6S1ROI2', 'VisiumR6S1ROI3', 'VisiumR6S1ROI4', 'VisiumR6S2ROI1', 'VisiumR6S2ROI2', 'VisiumR6S2ROI3', 'VisiumR6S2ROI4']\n",
      "min_cells is  245.0\n",
      "min_cells is  353.0\n",
      "min_cells is  358.0\n",
      "min_cells is  422.0\n",
      "min_cells is  303.0\n",
      "min_cells is  290.0\n",
      "min_cells is  370.0\n",
      "min_cells is  483.0\n",
      "\u001b[32m12:23:33\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mFound 1996 common genes\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m12:23:36\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mselected genes ['AMOTL1', 'ANXA1', 'APOL1', 'BCR', 'BICD2', 'BLMH', 'CA12', 'CD44', 'CDC42EP1', 'CDC42EP5', 'CLTB', 'CTNNBIP1', 'DBI', 'DYNLL1', 'EGR1', 'EMP1', 'FASN', 'FCHSD1', 'G0S2', 'GIPC1', 'GPC1', 'H2AFJ', 'IFI27', 'MFSD11', 'MINK1', 'MTSS1', 'MYO15B', 'NDRG1', 'NDRG2', 'NFIB', 'NIBAN2', 'NUPR1', 'PHGDH', 'PLIN3', 'PLS3', 'PRXL2A', 'RARG', 'RMND5A', 'ROBO1', 'SDC1', 'SNX21', 'SPTLC2', 'TCF7L2', 'THBD', 'TMEM134', 'TUBA4A', 'TWIST2', 'TXN', 'UPP1', 'VWF']\u001b[0m\n",
      "[INFO] Wrote /project/simmons_hts/kxu/hest/eval/data/VisiumR6/var_50genes.json (top-50, criteria=var); /project/simmons_hts/kxu/hest/eval/data/VisiumR6/all_genes.json (all_common=17943); /project/simmons_hts/kxu/hest/eval/data/VisiumR6/common_genes_0.1.json (filtered_common=1996, min_cells_pct=0.1)\n",
      "[INFO] Wrote /project/simmons_hts/kxu/hest/eval/data/VisiumR6/var_50genes.json\n",
      "K=15 doesnt match the number of patients, try to distribute the patients instead\n",
      "Split 0/8\n",
      "train set is  ['VisiumR6S1ROI2', 'VisiumR6S1ROI3', 'VisiumR6S1ROI4', 'VisiumR6S2ROI1', 'VisiumR6S2ROI2', 'VisiumR6S2ROI3', 'VisiumR6S2ROI4']\n",
      "\n",
      "test set is  ['VisiumR6S1ROI1']\n",
      "\n",
      "Split 1/8\n",
      "train set is  ['VisiumR6S1ROI1', 'VisiumR6S1ROI3', 'VisiumR6S1ROI4', 'VisiumR6S2ROI1', 'VisiumR6S2ROI2', 'VisiumR6S2ROI3', 'VisiumR6S2ROI4']\n",
      "\n",
      "test set is  ['VisiumR6S1ROI2']\n",
      "\n",
      "Split 2/8\n",
      "train set is  ['VisiumR6S1ROI1', 'VisiumR6S1ROI2', 'VisiumR6S1ROI4', 'VisiumR6S2ROI1', 'VisiumR6S2ROI2', 'VisiumR6S2ROI3', 'VisiumR6S2ROI4']\n",
      "\n",
      "test set is  ['VisiumR6S1ROI3']\n",
      "\n",
      "Split 3/8\n",
      "train set is  ['VisiumR6S1ROI1', 'VisiumR6S1ROI2', 'VisiumR6S1ROI3', 'VisiumR6S2ROI1', 'VisiumR6S2ROI2', 'VisiumR6S2ROI3', 'VisiumR6S2ROI4']\n",
      "\n",
      "test set is  ['VisiumR6S1ROI4']\n",
      "\n",
      "Split 4/8\n",
      "train set is  ['VisiumR6S1ROI1', 'VisiumR6S1ROI2', 'VisiumR6S1ROI3', 'VisiumR6S1ROI4', 'VisiumR6S2ROI2', 'VisiumR6S2ROI3', 'VisiumR6S2ROI4']\n",
      "\n",
      "test set is  ['VisiumR6S2ROI1']\n",
      "\n",
      "Split 5/8\n",
      "train set is  ['VisiumR6S1ROI1', 'VisiumR6S1ROI2', 'VisiumR6S1ROI3', 'VisiumR6S1ROI4', 'VisiumR6S2ROI1', 'VisiumR6S2ROI3', 'VisiumR6S2ROI4']\n",
      "\n",
      "test set is  ['VisiumR6S2ROI2']\n",
      "\n",
      "Split 6/8\n",
      "train set is  ['VisiumR6S1ROI1', 'VisiumR6S1ROI2', 'VisiumR6S1ROI3', 'VisiumR6S1ROI4', 'VisiumR6S2ROI1', 'VisiumR6S2ROI2', 'VisiumR6S2ROI4']\n",
      "\n",
      "test set is  ['VisiumR6S2ROI3']\n",
      "\n",
      "Split 7/8\n",
      "train set is  ['VisiumR6S1ROI1', 'VisiumR6S1ROI2', 'VisiumR6S1ROI3', 'VisiumR6S1ROI4', 'VisiumR6S2ROI1', 'VisiumR6S2ROI2', 'VisiumR6S2ROI3']\n",
      "\n",
      "test set is  ['VisiumR6S2ROI4']\n",
      "\n",
      "[INFO] Wrote 15-fold splits to /project/simmons_hts/kxu/hest/eval/data/VisiumR6/splits\n",
      "✅ Benchmark dataset created at /project/simmons_hts/kxu/hest/eval/data/VisiumR6\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 7):  # R1 to R6\n",
    "    tag = f\"VisiumR{i}\"\n",
    "    create_benchmark_data_multislide(\n",
    "        save_dir=f\"/project/simmons_hts/kxu/hest/eval/data/{tag}\",\n",
    "        K=15,\n",
    "        base_root=f\"/project/simmons_hts/kxu/hest/visium_data/{tag}\",\n",
    "        gene_k=50,\n",
    "        gene_criteria=\"var\",\n",
    "        symlink=False,  # set True to save disk space\n",
    "        seed=0          # controls fold assignment deterministically\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad7c280",
   "metadata": {},
   "source": [
    "# create VisiumR folder containing all prime runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97e1bfbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>technology</th>\n",
       "      <th>panel</th>\n",
       "      <th>panel_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>run_name</th>\n",
       "      <th>run_id</th>\n",
       "      <th>slide</th>\n",
       "      <th>slide_id</th>\n",
       "      <th>roi</th>\n",
       "      <th>...</th>\n",
       "      <th>alignment</th>\n",
       "      <th>directory_xenium_output</th>\n",
       "      <th>rds</th>\n",
       "      <th>alignment_note</th>\n",
       "      <th>crop_100_um</th>\n",
       "      <th>segmentation_target_pxl_size</th>\n",
       "      <th>num_patches_100um</th>\n",
       "      <th>num_patches_50um</th>\n",
       "      <th>num_patches_50um_0.25_um_px</th>\n",
       "      <th>num_patches_25um</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XeniumPR1S1ROI1</td>\n",
       "      <td>10x Xenium</td>\n",
       "      <td>5k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CAM006</td>\n",
       "      <td>RUNTrexBIO</td>\n",
       "      <td>PR1</td>\n",
       "      <td>1</td>\n",
       "      <td>43739.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>CAM006_Xenium5K_post_HnE_matrix.csv</td>\n",
       "      <td>/project/simmons_hts/shared/20_11_2024_xenium_...</td>\n",
       "      <td>/project/simmons_hts/jpark/1_project/1_objects...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"type\": \"strip\", \"side\": \"right\", \"size\": 0.1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>684.0</td>\n",
       "      <td>2727.0</td>\n",
       "      <td>2603.0</td>\n",
       "      <td>9950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XeniumPR1S1ROI2</td>\n",
       "      <td>10x Xenium</td>\n",
       "      <td>5k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TIP877</td>\n",
       "      <td>RUNTrexBIO</td>\n",
       "      <td>PR1</td>\n",
       "      <td>1</td>\n",
       "      <td>43739.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>TIP877_Xenium5K_post_HnE_matrix.csv</td>\n",
       "      <td>/project/simmons_hts/shared/20_11_2024_xenium_...</td>\n",
       "      <td>/project/simmons_hts/jpark/1_project/1_objects...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>482.0</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>1838.0</td>\n",
       "      <td>7130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XeniumPR1S1ROI3</td>\n",
       "      <td>10x Xenium</td>\n",
       "      <td>5k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GI9389</td>\n",
       "      <td>RUNTrexBIO</td>\n",
       "      <td>PR1</td>\n",
       "      <td>1</td>\n",
       "      <td>43739.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>GI9389_Xenium5K_post_HnE_matrix.csv</td>\n",
       "      <td>/project/simmons_hts/shared/20_11_2024_xenium_...</td>\n",
       "      <td>/project/simmons_hts/jpark/1_project/1_objects...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'type':'corner', 'corner':'top-left', 'width'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1168.0</td>\n",
       "      <td>4627.0</td>\n",
       "      <td>4502.0</td>\n",
       "      <td>17368.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XeniumPR1S1ROI4</td>\n",
       "      <td>10x Xenium</td>\n",
       "      <td>5k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GI9077</td>\n",
       "      <td>RUNTrexBIO</td>\n",
       "      <td>PR1</td>\n",
       "      <td>1</td>\n",
       "      <td>43739.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>GI9077_Xenium5K_post_HnE_matrix.csv</td>\n",
       "      <td>/project/simmons_hts/shared/20_11_2024_xenium_...</td>\n",
       "      <td>/project/simmons_hts/jpark/1_project/1_objects...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'type':'corner', 'corner':'bottom-left', 'wid...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1253.0</td>\n",
       "      <td>5010.0</td>\n",
       "      <td>4903.0</td>\n",
       "      <td>19360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XeniumPR1S1ROI5</td>\n",
       "      <td>10x Xenium</td>\n",
       "      <td>5k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GI9612</td>\n",
       "      <td>RUNTrexBIO</td>\n",
       "      <td>PR1</td>\n",
       "      <td>1</td>\n",
       "      <td>43739.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>GI9612_Xenium5K_post_HnE_matrix.csv</td>\n",
       "      <td>/project/simmons_hts/shared/20_11_2024_xenium_...</td>\n",
       "      <td>/project/simmons_hts/jpark/1_project/1_objects...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>893.0</td>\n",
       "      <td>3520.0</td>\n",
       "      <td>3289.0</td>\n",
       "      <td>12449.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>XeniumR6S2ROI7</td>\n",
       "      <td>10x Xenium</td>\n",
       "      <td>480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JR_50621_22</td>\n",
       "      <td>RUN6</td>\n",
       "      <td>R6</td>\n",
       "      <td>2</td>\n",
       "      <td>31265.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>XeniumR6S2ROI7_alignment_files/matrix.csv</td>\n",
       "      <td>/project/simmons_hts/shared/06_05_2024_xenium_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4212.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>XeniumR6S2ROI8</td>\n",
       "      <td>10x Xenium</td>\n",
       "      <td>480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JR_18170_21</td>\n",
       "      <td>RUN6</td>\n",
       "      <td>R6</td>\n",
       "      <td>2</td>\n",
       "      <td>31265.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>XeniumR6S2ROI8_alignment_files/matrix.csv</td>\n",
       "      <td>/project/simmons_hts/shared/06_05_2024_xenium_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>XeniumR6S2ROI9</td>\n",
       "      <td>10x Xenium</td>\n",
       "      <td>480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JR_8610_23</td>\n",
       "      <td>RUN6</td>\n",
       "      <td>R6</td>\n",
       "      <td>2</td>\n",
       "      <td>31265.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>XeniumR6S2ROI9_alignment_files/matrix.csv</td>\n",
       "      <td>/project/simmons_hts/shared/06_05_2024_xenium_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>XeniumR6S2ROI10</td>\n",
       "      <td>10x Xenium</td>\n",
       "      <td>480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JR_20687_20</td>\n",
       "      <td>RUN6</td>\n",
       "      <td>R6</td>\n",
       "      <td>2</td>\n",
       "      <td>31265.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>XeniumR6S2ROI10_alignment_files/matrix.csv</td>\n",
       "      <td>/project/simmons_hts/shared/06_05_2024_xenium_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>665.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>XeniumR6S2ROI11</td>\n",
       "      <td>10x Xenium</td>\n",
       "      <td>480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JR_23234_23</td>\n",
       "      <td>RUN6</td>\n",
       "      <td>R6</td>\n",
       "      <td>2</td>\n",
       "      <td>31265.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>XeniumR6S2ROI11_alignment_files/matrix.csv</td>\n",
       "      <td>/project/simmons_hts/shared/06_05_2024_xenium_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8006.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           sample_id  technology panel panel_name   patient_id    run_name  \\\n",
       "0    XeniumPR1S1ROI1  10x Xenium    5k        NaN       CAM006  RUNTrexBIO   \n",
       "1    XeniumPR1S1ROI2  10x Xenium    5k        NaN       TIP877  RUNTrexBIO   \n",
       "2    XeniumPR1S1ROI3  10x Xenium    5k        NaN       GI9389  RUNTrexBIO   \n",
       "3    XeniumPR1S1ROI4  10x Xenium    5k        NaN       GI9077  RUNTrexBIO   \n",
       "4    XeniumPR1S1ROI5  10x Xenium    5k        NaN       GI9612  RUNTrexBIO   \n",
       "..               ...         ...   ...        ...          ...         ...   \n",
       "115   XeniumR6S2ROI7  10x Xenium   480        NaN  JR_50621_22        RUN6   \n",
       "116   XeniumR6S2ROI8  10x Xenium   480        NaN  JR_18170_21        RUN6   \n",
       "117   XeniumR6S2ROI9  10x Xenium   480        NaN   JR_8610_23        RUN6   \n",
       "118  XeniumR6S2ROI10  10x Xenium   480        NaN  JR_20687_20        RUN6   \n",
       "119  XeniumR6S2ROI11  10x Xenium   480        NaN  JR_23234_23        RUN6   \n",
       "\n",
       "    run_id  slide  slide_id   roi  ...  \\\n",
       "0      PR1      1   43739.0   1.0  ...   \n",
       "1      PR1      1   43739.0   2.0  ...   \n",
       "2      PR1      1   43739.0   3.0  ...   \n",
       "3      PR1      1   43739.0   4.0  ...   \n",
       "4      PR1      1   43739.0   5.0  ...   \n",
       "..     ...    ...       ...   ...  ...   \n",
       "115     R6      2   31265.0   7.0  ...   \n",
       "116     R6      2   31265.0   8.0  ...   \n",
       "117     R6      2   31265.0   9.0  ...   \n",
       "118     R6      2   31265.0  10.0  ...   \n",
       "119     R6      2   31265.0  11.0  ...   \n",
       "\n",
       "                                      alignment  \\\n",
       "0           CAM006_Xenium5K_post_HnE_matrix.csv   \n",
       "1           TIP877_Xenium5K_post_HnE_matrix.csv   \n",
       "2           GI9389_Xenium5K_post_HnE_matrix.csv   \n",
       "3           GI9077_Xenium5K_post_HnE_matrix.csv   \n",
       "4           GI9612_Xenium5K_post_HnE_matrix.csv   \n",
       "..                                          ...   \n",
       "115   XeniumR6S2ROI7_alignment_files/matrix.csv   \n",
       "116   XeniumR6S2ROI8_alignment_files/matrix.csv   \n",
       "117   XeniumR6S2ROI9_alignment_files/matrix.csv   \n",
       "118  XeniumR6S2ROI10_alignment_files/matrix.csv   \n",
       "119  XeniumR6S2ROI11_alignment_files/matrix.csv   \n",
       "\n",
       "                               directory_xenium_output  \\\n",
       "0    /project/simmons_hts/shared/20_11_2024_xenium_...   \n",
       "1    /project/simmons_hts/shared/20_11_2024_xenium_...   \n",
       "2    /project/simmons_hts/shared/20_11_2024_xenium_...   \n",
       "3    /project/simmons_hts/shared/20_11_2024_xenium_...   \n",
       "4    /project/simmons_hts/shared/20_11_2024_xenium_...   \n",
       "..                                                 ...   \n",
       "115  /project/simmons_hts/shared/06_05_2024_xenium_...   \n",
       "116  /project/simmons_hts/shared/06_05_2024_xenium_...   \n",
       "117  /project/simmons_hts/shared/06_05_2024_xenium_...   \n",
       "118  /project/simmons_hts/shared/06_05_2024_xenium_...   \n",
       "119  /project/simmons_hts/shared/06_05_2024_xenium_...   \n",
       "\n",
       "                                                   rds alignment_note  \\\n",
       "0    /project/simmons_hts/jpark/1_project/1_objects...            NaN   \n",
       "1    /project/simmons_hts/jpark/1_project/1_objects...            NaN   \n",
       "2    /project/simmons_hts/jpark/1_project/1_objects...            NaN   \n",
       "3    /project/simmons_hts/jpark/1_project/1_objects...            NaN   \n",
       "4    /project/simmons_hts/jpark/1_project/1_objects...            NaN   \n",
       "..                                                 ...            ...   \n",
       "115                                                NaN            NaN   \n",
       "116                                                NaN            NaN   \n",
       "117                                                NaN            NaN   \n",
       "118                                                NaN            NaN   \n",
       "119                                                NaN            NaN   \n",
       "\n",
       "                                           crop_100_um  \\\n",
       "0    {\"type\": \"strip\", \"side\": \"right\", \"size\": 0.1...   \n",
       "1                                                  NaN   \n",
       "2    {'type':'corner', 'corner':'top-left', 'width'...   \n",
       "3    {'type':'corner', 'corner':'bottom-left', 'wid...   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "115                                                NaN   \n",
       "116                                                NaN   \n",
       "117                                                NaN   \n",
       "118                                                NaN   \n",
       "119                                                NaN   \n",
       "\n",
       "    segmentation_target_pxl_size num_patches_100um num_patches_50um  \\\n",
       "0                            NaN             684.0           2727.0   \n",
       "1                            NaN             482.0           1886.0   \n",
       "2                            NaN            1168.0           4627.0   \n",
       "3                            NaN            1253.0           5010.0   \n",
       "4                            NaN             893.0           3520.0   \n",
       "..                           ...               ...              ...   \n",
       "115                          NaN            4212.0              NaN   \n",
       "116                          NaN            2016.0              NaN   \n",
       "117                          NaN            3130.0              NaN   \n",
       "118                          NaN             665.0              NaN   \n",
       "119                          NaN            8006.0              NaN   \n",
       "\n",
       "    num_patches_50um_0.25_um_px num_patches_25um  \n",
       "0                        2603.0           9950.0  \n",
       "1                        1838.0           7130.0  \n",
       "2                        4502.0          17368.0  \n",
       "3                        4903.0          19360.0  \n",
       "4                        3289.0          12449.0  \n",
       "..                          ...              ...  \n",
       "115                         NaN              NaN  \n",
       "116                         NaN              NaN  \n",
       "117                         NaN              NaN  \n",
       "118                         NaN              NaN  \n",
       "119                         NaN              NaN  \n",
       "\n",
       "[120 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv(\"/project/simmons_hts/kxu/hest/hest_directory.csv\")\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0e0dd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from hest.utils import get_k_genes  # used by write_var_k_genes_from_paths; create_splits imported inside main\n",
    "\n",
    "\n",
    "# ---------- helpers ----------\n",
    "\n",
    "def _extract_slide_number_from_name(name: str) -> Optional[str]:\n",
    "    \"\"\"Extract slide number from a folder name like 'slide1', 'slide_2', 'S3', etc.\"\"\"\n",
    "    n = name.lower()\n",
    "    m = re.search(r\"slide[_\\-]?(\\d+)\", n)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    m2 = re.search(r\"\\bS(\\d+)\\b\", name, flags=re.IGNORECASE)\n",
    "    if m2:\n",
    "        return m2.group(1)\n",
    "    return None\n",
    "\n",
    "def _is_slide_like_folder(folder: Path) -> bool:\n",
    "    \"\"\"Return True if folder name looks like a slide folder and it contains subfolders.\"\"\"\n",
    "    if not folder.is_dir():\n",
    "        return False\n",
    "    if _extract_slide_number_from_name(folder.name) is not None:\n",
    "        return True\n",
    "    # also treat names starting with 'slide' case-insensitively\n",
    "    if folder.name.lower().startswith(\"slide\"):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def _expand_to_slide_paths(roots: List[Path]) -> List[Path]:\n",
    "    \"\"\"\n",
    "    Given a list of roots, expand any PR-level root that contains slide-like subfolders\n",
    "    into a list of slide paths. If a root already looks like a slide (contains aligned_adata.h5ad\n",
    "    in its immediate subfolders), it's kept as-is.\n",
    "    \"\"\"\n",
    "    expanded: List[Path] = []\n",
    "    for r in roots:\n",
    "        if not r.exists() or not r.is_dir():\n",
    "            continue\n",
    "        # find immediate subdirectories\n",
    "        immediate_subdirs = sorted([d for d in r.iterdir() if d.is_dir()], key=lambda p: p.name)\n",
    "        # if any immediate subdir looks like a slide and that slide has child sample folders, expand\n",
    "        slide_candidates = [d for d in immediate_subdirs if _is_slide_like_folder(d)]\n",
    "        if slide_candidates:\n",
    "            # For each slide candidate, add it (but only if it contains sample subfolders)\n",
    "            for s in slide_candidates:\n",
    "                # if s contains at least one subdir with aligned_adata.h5ad, keep it\n",
    "                has_sample_subdir = any((sd / \"aligned_adata.h5ad\").exists() for sd in sorted([d for d in s.iterdir() if d.is_dir()]))\n",
    "                if has_sample_subdir:\n",
    "                    expanded.append(s)\n",
    "                else:\n",
    "                    # if slide folder itself directly contains aligned_adata.h5ad files (uncommon), treat slide as sample root\n",
    "                    if any((s / f).is_file() and f.endswith(\".h5ad\") for f in os.listdir(s)):\n",
    "                        expanded.append(s)\n",
    "        else:\n",
    "            # No slide-like immediate subdirs. Check if this root itself directly contains sample subfolders (with aligned_adata.h5ad)\n",
    "            has_direct_samples = any((d / \"aligned_adata.h5ad\").exists() for d in immediate_subdirs)\n",
    "            if has_direct_samples:\n",
    "                expanded.append(r)\n",
    "            else:\n",
    "                # fallback: if immediate_subdirs is non-empty, treat each immediate subdir as a slide candidate\n",
    "                for d in immediate_subdirs:\n",
    "                    if any((sd / \"aligned_adata.h5ad\").exists() for sd in sorted([sd for sd in d.iterdir() if sd.is_dir()])):\n",
    "                        expanded.append(d)\n",
    "    # dedupe while preserving order\n",
    "    seen = set()\n",
    "    uniq = []\n",
    "    for p in expanded:\n",
    "        if str(p) not in seen:\n",
    "            uniq.append(p)\n",
    "            seen.add(str(p))\n",
    "    return uniq\n",
    "\n",
    "\n",
    "def _discover_samples_from_slide_paths(\n",
    "    slide_paths: List[Path],\n",
    "    ids: Optional[List[str]] = None,\n",
    ") -> Dict[str, Dict[str, Path]]:\n",
    "    \"\"\"\n",
    "    Discover samples under *slide* paths (each slide path should contain sample subfolders).\n",
    "    Returns mapping {new_id: {\"adata\": Path, \"patch\": Path|None, \"vis\": Path|None, \"orig\": orig_sid}}\n",
    "    Naming: XeniumPR{n}S{slide}{ROI}\n",
    "    \"\"\"\n",
    "    collected = []\n",
    "    for sp in slide_paths:\n",
    "        # sample subfolders are immediate children of the slide path\n",
    "        for p in sorted([d for d in sp.iterdir() if d.is_dir()], key=lambda d: d.name):\n",
    "            collected.append((sp, p.name))\n",
    "\n",
    "    if ids is not None:\n",
    "        # filter collected by ids list\n",
    "        collected = [(sp, sid) for sp, sid in collected if sid in ids]\n",
    "\n",
    "    samples: Dict[str, Dict[str, Path]] = {}\n",
    "    for slide_path, sid in collected:\n",
    "        sdir = slide_path / sid\n",
    "        adata = sdir / \"aligned_adata.h5ad\"\n",
    "        if not adata.exists():\n",
    "            continue\n",
    "\n",
    "        # find patch .h5 (optional)\n",
    "        patch_h5 = None\n",
    "        patches_dir = sdir / \"patches\"\n",
    "        if patches_dir.exists():\n",
    "            cands = sorted(patches_dir.glob(\"*.h5\"))\n",
    "            if cands:\n",
    "                exact = [c for c in cands if c.name == f\"{sid}.h5\"]\n",
    "                patch_h5 = exact[0] if exact else cands[0]\n",
    "\n",
    "        # find vis png (optional)\n",
    "        vis_png = None\n",
    "        vis_dir = sdir / \"patches_vis\"\n",
    "        if vis_dir.exists():\n",
    "            cands = sorted(vis_dir.glob(\"*.png\"))\n",
    "            if cands:\n",
    "                exact = [c for c in cands if c.name == f\"{sid}_patch_vis.png\"]\n",
    "                vis_png = exact[0] if exact else cands[0]\n",
    "\n",
    "        # determine PR number from slide_path or its ancestors\n",
    "        pr_num = _extract_pr_number(slide_path)\n",
    "        # if not present, try ancestors\n",
    "        if pr_num is None:\n",
    "            for ancestor in slide_path.parents:\n",
    "                pr_num = _extract_pr_number(ancestor)\n",
    "                if pr_num is not None:\n",
    "                    break\n",
    "\n",
    "        # slide number from slide path name (if can't find, use sanitized short tag)\n",
    "        slide_num = _extract_slide_number_from_name(slide_path.name) or _sanitize_tag(slide_path.name, maxlen=3)\n",
    "\n",
    "        if pr_num is not None:\n",
    "            prefix = f\"VisiumR{pr_num}S{slide_num}\"\n",
    "        else:\n",
    "            # fallback if no PR number found anywhere upstream\n",
    "            prefix = f\"{_sanitize_tag(slide_path.name, maxlen=6)}S{slide_num}\"\n",
    "\n",
    "        new_id = f\"{prefix}{sid}\"\n",
    "        if new_id in samples:\n",
    "            raise ValueError(f\"Duplicate renamed sample id '{new_id}' (collision for sid='{sid}').\")\n",
    "\n",
    "        samples[new_id] = {\"adata\": adata, \"patch\": patch_h5, \"vis\": vis_png, \"orig\": sid}\n",
    "\n",
    "    return samples\n",
    "\n",
    "\n",
    "def _transfer(src: Optional[Path], dst: Path, label: str, symlink: bool, missing_list: list, overwrite: bool = False):\n",
    "    \"\"\"\n",
    "    Copy or symlink `src` -> `dst`. By default skip if dst exists (no-op).\n",
    "    If overwrite=True, existing dst will be replaced.\n",
    "    Records missing items into missing_list.\n",
    "    \"\"\"\n",
    "    if src is None or not Path(src).exists():\n",
    "        missing_list.append((dst.stem, label, str(src) if src is not None else \"<none>\"))\n",
    "        return\n",
    "\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # If destination exists and we don't want to overwrite -> skip\n",
    "    if dst.exists():\n",
    "        # Optionally detect identical file (size + mtime) to avoid unnecessary replacement:\n",
    "        try:\n",
    "            src_stat = Path(src).stat()\n",
    "            dst_stat = dst.stat()\n",
    "            same_size = src_stat.st_size == dst_stat.st_size\n",
    "            same_mtime = int(src_stat.st_mtime) == int(dst_stat.st_mtime)\n",
    "        except Exception:\n",
    "            same_size = False\n",
    "            same_mtime = False\n",
    "\n",
    "        if not overwrite and same_size and same_mtime:\n",
    "            # identical (likely), skip quietly\n",
    "            return\n",
    "        if not overwrite:\n",
    "            # dst exists but not identical (or we couldn't stat) — skip by default but warn\n",
    "            print(f\"[SKIP] {label} exists: {dst} (use overwrite=True to replace)\")\n",
    "            return\n",
    "\n",
    "        # If overwrite requested: remove existing\n",
    "        try:\n",
    "            dst.unlink()\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] could not remove existing {dst}: {e}\")\n",
    "\n",
    "    # perform transfer\n",
    "    if symlink:\n",
    "        try:\n",
    "            os.symlink(src, dst)\n",
    "        except FileExistsError:\n",
    "            # already exists (race) — ignore\n",
    "            pass\n",
    "    else:\n",
    "        shutil.copy2(src, dst)  # copy2 preserves mtime/metadata\n",
    "\n",
    "\n",
    "\n",
    "def write_var_k_genes_from_paths(\n",
    "    adata_paths,\n",
    "    k,\n",
    "    criteria,\n",
    "    var_out_path,\n",
    "    all_genes_out_path=None,\n",
    "    exclude_keywords=None,\n",
    "    filtered_common_out_path=None,\n",
    "    min_cells_pct: float = 0.10,\n",
    "):\n",
    "    \"\"\"\n",
    "    Same behavior as before: load adatas, call get_k_genes, write JSONs.\n",
    "    \"\"\"\n",
    "    import json, warnings\n",
    "    import numpy as np\n",
    "    import scanpy as sc\n",
    "    from hest.utils import get_k_genes\n",
    "\n",
    "    if exclude_keywords is None:\n",
    "        exclude_keywords = [\"NegControl\", \"Codeword\", \"Intergenic_Region\", \"Control\", \"BLANK\"]\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"anndata\")\n",
    "\n",
    "    adata_list = []\n",
    "    for p in adata_paths:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "            ad = sc.read_h5ad(str(p))\n",
    "        adata_list.append(ad)\n",
    "\n",
    "    var_k_genes = get_k_genes(adata_list, k, criteria, save_dir=str(var_out_path), min_cells_pct=min_cells_pct)\n",
    "\n",
    "    common_genes = set(adata_list[0].var_names) if adata_list else set()\n",
    "    for ad in adata_list[1:]:\n",
    "        common_genes &= set(ad.var_names)\n",
    "\n",
    "    def _keep_keyword(gene: str) -> bool:\n",
    "        for kw in exclude_keywords:\n",
    "            if kw in gene:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    all_common_genes = sorted([g for g in common_genes if _keep_keyword(g)])\n",
    "\n",
    "    filtered_sets = []\n",
    "    for ad in adata_list:\n",
    "        ad_tmp = ad[:, :].copy()\n",
    "        min_cells = int(np.ceil(min_cells_pct * ad_tmp.n_obs)) if min_cells_pct else 0\n",
    "        if min_cells > 0:\n",
    "            sc.pp.filter_genes(ad_tmp, min_cells=min_cells)\n",
    "        filtered_sets.append(set(ad_tmp.var_names))\n",
    "\n",
    "    filtered_common = set.intersection(*filtered_sets) if filtered_sets else set()\n",
    "    filtered_common_genes = sorted([g for g in filtered_common if (\"BLANK\" not in g and \"Control\" not in g)])\n",
    "\n",
    "    if all_genes_out_path is None:\n",
    "        all_genes_out_path = Path(var_out_path).parent / \"all_genes.json\"\n",
    "    with open(all_genes_out_path, \"w\") as f:\n",
    "        json.dump({\"genes\": all_common_genes}, f)\n",
    "\n",
    "    if filtered_common_out_path is None:\n",
    "        filtered_common_out_path = Path(var_out_path).parent / f\"common_genes_{min_cells_pct}.json\"\n",
    "    with open(filtered_common_out_path, \"w\") as f:\n",
    "        json.dump({\"genes\": filtered_common_genes, \"min_cells_pct\": min_cells_pct}, f)\n",
    "\n",
    "    print(\n",
    "        f\"[INFO] Wrote {var_out_path} (top-{k}, criteria={criteria}); \"\n",
    "        f\"{all_genes_out_path} (all_common={len(all_common_genes)}); \"\n",
    "        f\"{filtered_common_out_path} (filtered_common={len(filtered_common_genes)}, min_cells_pct={min_cells_pct})\"\n",
    "    )\n",
    "\n",
    "    return var_k_genes, all_common_genes, filtered_common_genes\n",
    "\n",
    "# copy directly from other eval folder\n",
    "def create_benchmark_from_eval_dirs(\n",
    "    save_dir: str | Path,\n",
    "    K: int,\n",
    "    eval_dirs: List[str | Path],\n",
    "    gene_k: int = 50,\n",
    "    gene_criteria: str = \"var\",\n",
    "    symlink: bool = False,\n",
    "    seed: int = 0,\n",
    "    metadata_csv: str = \"/project/simmons_hts/kxu/hest/hest_directory.csv\",\n",
    "    dry_run: bool = False,\n",
    "    exclude_ids: Optional[List[str]] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a merged benchmark package by copying (or symlinking) assets from one or more\n",
    "    'eval' dataset folders that already contain:\n",
    "        <eval_dir>/\n",
    "            patches/\n",
    "                *.h5\n",
    "                vis/\n",
    "                    *.png\n",
    "            adata/\n",
    "                *.h5ad\n",
    "\n",
    "    Args:\n",
    "        save_dir: destination directory to create merged dataset (will contain patches/, patches/vis/, adata/, splits/, var_*.json)\n",
    "        K: number of folds (patient-level)\n",
    "        eval_dirs: list of dataset root paths to copy from (e.g. XeniumPR2 eval folder)\n",
    "        gene_k, gene_criteria: forwarded to get_k_genes\n",
    "        symlink: if True, create symlinks instead of copying\n",
    "        seed: RNG seed for deterministic fold assignment\n",
    "        metadata_csv: CSV mapping sample_id -> patient_id\n",
    "        dry_run: if True, only print planned actions without copying\n",
    "    Returns:\n",
    "        pd.DataFrame meta (columns: id, patient, dataset_title)\n",
    "    \"\"\"\n",
    "    from hest.HESTData import create_splits\n",
    "\n",
    "    save_dir = Path(save_dir)\n",
    "    eval_dirs = [Path(x) for x in eval_dirs]\n",
    "    # sanitise and check inputs\n",
    "    existing = [d for d in eval_dirs if d.exists() and d.is_dir()]\n",
    "    if not existing:\n",
    "        raise ValueError(f\"No valid eval_dirs found among: {eval_dirs}\")\n",
    "    print(f\"[INFO] Using eval dirs: {existing}\")\n",
    "\n",
    "    # discover sample ids by scanning adata/ and patches/ for filenames\n",
    "    discovered_ids = set()\n",
    "    sample_sources = {}  # id -> dict(sources found)\n",
    "    for d in existing:\n",
    "        adata_dir = d / \"adata\"\n",
    "        patches_dir = d / \"patches\"\n",
    "        vis_dir = patches_dir / \"vis\"\n",
    "\n",
    "        # adata\n",
    "        if adata_dir.exists() and adata_dir.is_dir():\n",
    "            for f in sorted(adata_dir.glob(\"*.h5ad\")):\n",
    "                sid = f.stem\n",
    "                discovered_ids.add(sid)\n",
    "                sample_sources.setdefault(sid, {}).setdefault(\"adata\", []).append(f)\n",
    "\n",
    "        # patches\n",
    "        if patches_dir.exists() and patches_dir.is_dir():\n",
    "            for f in sorted(patches_dir.glob(\"*.h5\")):\n",
    "                sid = f.stem\n",
    "                discovered_ids.add(sid)\n",
    "                sample_sources.setdefault(sid, {}).setdefault(\"patch\", []).append(f)\n",
    "\n",
    "            # vis images\n",
    "            if vis_dir.exists() and vis_dir.is_dir():\n",
    "                for f in sorted(vis_dir.glob(\"*.png\")):\n",
    "                    # allow vis file names like '<sid>_patch_vis.png' or '<sid>.png' or anything; map by stem heuristics\n",
    "                    stem = f.stem\n",
    "                    # normalize: if stem endswith '_patch_vis', strip it\n",
    "                    stem_clean = re.sub(r\"_?patch_vis$\", \"\", stem, flags=re.IGNORECASE)\n",
    "                    # sometimes vis is named '<sid>_patch_vis' or '<sid>'\n",
    "                    sid = stem_clean\n",
    "                    discovered_ids.add(sid)\n",
    "                    sample_sources.setdefault(sid, {}).setdefault(\"vis\", []).append(f)\n",
    "                    \n",
    "    # ---- Apply exclusion ----\n",
    "    if exclude_ids:\n",
    "        exclude_set = set(exclude_ids)\n",
    "        before = len(discovered_ids)\n",
    "        discovered_ids = [sid for sid in discovered_ids if sid not in exclude_set]\n",
    "\n",
    "        missing_excludes = exclude_set - set(discovered_ids)\n",
    "        if missing_excludes:\n",
    "            print(f\"[WARN] Some exclude_ids not found: {sorted(missing_excludes)}\")\n",
    "\n",
    "        removed = before - len(discovered_ids)\n",
    "        print(f\"[INFO] Excluded {removed} samples → remaining {len(discovered_ids)}\")\n",
    "        if removed > 0:\n",
    "            for e in sorted(exclude_set & set(discovered_ids)):\n",
    "                print(f\"   - excluded: {e}\")\n",
    "\n",
    "    discovered_ids = sorted(discovered_ids)\n",
    "    if not discovered_ids:\n",
    "        raise ValueError(\"No samples discovered in provided eval_dirs (no *.h5ad or *.h5 files found).\")\n",
    "    print(f\"[INFO] Discovered sample IDs ({len(discovered_ids)}): {discovered_ids}\")\n",
    "\n",
    "    # Prepare save_dir layout\n",
    "    patches_out = save_dir / \"patches\"\n",
    "    patches_vis_out = patches_out / \"vis\"\n",
    "    adata_out = save_dir / \"adata\"\n",
    "    for p in (patches_out, patches_vis_out, adata_out):\n",
    "        if not dry_run:\n",
    "            p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Load metadata CSV mapping sample_id -> patient_id\n",
    "    patient_map = {}\n",
    "    meta_df_csv = None\n",
    "    if Path(metadata_csv).exists():\n",
    "        meta_df_csv = pd.read_csv(metadata_csv, dtype=str)\n",
    "        if {\"sample_id\", \"patient_id\"}.issubset(meta_df_csv.columns):\n",
    "            meta_df_csv[\"sample_id\"] = meta_df_csv[\"sample_id\"].astype(str).str.strip()\n",
    "            meta_df_csv[\"patient_id\"] = meta_df_csv[\"patient_id\"].astype(str).str.strip()\n",
    "            patient_map = dict(zip(meta_df_csv[\"sample_id\"], meta_df_csv[\"patient_id\"]))\n",
    "            print(f\"[INFO] Loaded {len(patient_map)} entries from {metadata_csv}\")\n",
    "        else:\n",
    "            print(f\"[WARN] metadata_csv missing columns 'sample_id'/'patient_id'; will fallback to automatic patient inference\")\n",
    "    else:\n",
    "        print(f\"[WARN] metadata_csv not found: {metadata_csv}; will fallback to automatic patient inference\")\n",
    "\n",
    "    # Copy / symlink files into save_dir using sample id as filename stem\n",
    "    missing = []\n",
    "    planned_actions = []\n",
    "    for sid in discovered_ids:\n",
    "        srcs = sample_sources.get(sid, {})\n",
    "        # choose one adata: prefer first available\n",
    "        adata_src = None\n",
    "        if \"adata\" in srcs and srcs[\"adata\"]:\n",
    "            adata_src = srcs[\"adata\"][0]\n",
    "        # else fallback to none\n",
    "\n",
    "        patch_src = None\n",
    "        if \"patch\" in srcs and srcs[\"patch\"]:\n",
    "            patch_src = srcs[\"patch\"][0]\n",
    "\n",
    "        # vis: there may be multiple pngs per sample across eval_dirs — keep all but use a standardized name\n",
    "        vis_srcs = srcs.get(\"vis\", [])\n",
    "\n",
    "        # plan copy/symlink\n",
    "        if adata_src:\n",
    "            dst = adata_out / f\"{sid}.h5ad\"\n",
    "            planned_actions.append((\"adata\", adata_src, dst))\n",
    "        else:\n",
    "            # warn — adata missing for this sid\n",
    "            missing.append((sid, \"adata\"))\n",
    "\n",
    "        if patch_src:\n",
    "            dst = patches_out / f\"{sid}.h5\"\n",
    "            planned_actions.append((\"patch\", patch_src, dst))\n",
    "        else:\n",
    "            missing.append((sid, \"patch\"))\n",
    "\n",
    "        # for vis, when multiple sources exist, copy each with a numeric suffix if needed\n",
    "        for i, vs in enumerate(vis_srcs, start=1):\n",
    "            # try base name '<sid>.png' then '<sid>_1.png', '<sid>_2.png'...\n",
    "            if i == 1:\n",
    "                dst = patches_vis_out / f\"{sid}.png\"\n",
    "            else:\n",
    "                dst = patches_vis_out / f\"{sid}_{i}.png\"\n",
    "            planned_actions.append((\"vis\", vs, dst))\n",
    "\n",
    "    # Show dry run summary\n",
    "    print(f\"[INFO] Planned actions: {len(planned_actions)} file operations; {len(missing)} missing types.\")\n",
    "    if dry_run:\n",
    "        for act, src, dst in planned_actions[:200]:\n",
    "            print(f\"  - [{act}] {src} -> {dst}\")\n",
    "        if missing:\n",
    "            print(\"[WARN] Missing items:\")\n",
    "            for sid, typ in missing[:50]:\n",
    "                print(f\"  - {sid}: missing {typ}\")\n",
    "        print(\"[INFO] dry_run=True → no files were copied.\")\n",
    "    else:\n",
    "        # perform file ops\n",
    "        for act, src, dst in planned_actions:\n",
    "            try:\n",
    "                _transfer(src, dst, act, symlink, [], overwrite=False)  # we pass temporary missing list per transfer\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] transferring {src} -> {dst}: {e}\")\n",
    "\n",
    "    # Build metadata DataFrame: use discovered sample IDs and patient mapping (full sample id)\n",
    "    patient_ids = []\n",
    "    unresolved = []\n",
    "    for sid in discovered_ids:\n",
    "        pid = patient_map.get(sid)\n",
    "        if pid is None:\n",
    "            # fallback: try a stem match where original source had 'orig' info: try to find sample with full stem in filenames\n",
    "            # attempt to match any filename that contains sid as suffix: useful if CSV used 'XeniumPR1S1ROI1' but discovered was 'ROI1' etc.\n",
    "            # we'll try simple heuristics:\n",
    "            matched = None\n",
    "            if meta_df_csv is not None:\n",
    "                # try find any csv sample_id that endswith sid\n",
    "                candidates = [s for s in meta_df_csv[\"sample_id\"].values if str(s).endswith(str(sid))]\n",
    "                if candidates:\n",
    "                    matched = candidates[0]\n",
    "                    pid = patient_map.get(matched)\n",
    "            if pid is None:\n",
    "                # fallback to using prefix before '_' or the sid itself as patient\n",
    "                pid = sid.split(\"_\")[0] if \"_\" in sid else sid\n",
    "                unresolved.append(sid)\n",
    "        patient_ids.append(pid)\n",
    "\n",
    "    meta = pd.DataFrame({\"id\": discovered_ids, \"patient\": patient_ids, \"dataset_title\": [\"XeniumPR\"] * len(discovered_ids)})\n",
    "\n",
    "    print(f\"[INFO] Built metadata: {len(meta)} samples, {meta['patient'].nunique()} unique patients.\")\n",
    "    print(meta.head(20).to_string(index=False))\n",
    "\n",
    "    # write var_k genes (requires adata files to be present in save_dir or accessible)\n",
    "    adata_paths = [adata_out / f\"{sid}.h5ad\" for sid in discovered_ids]\n",
    "    # If dry_run, don't run get_k_genes; just return meta\n",
    "\n",
    "    var_json = save_dir / f\"var_{gene_k}genes.json\"\n",
    "    write_var_k_genes_from_paths(adata_paths, gene_k, gene_criteria, var_json)\n",
    "    print(f\"[INFO] Wrote {var_json}\")\n",
    "\n",
    "    # patient-level splits\n",
    "    group = meta.groupby([\"dataset_title\", \"patient\"])[\"id\"].agg(list).to_dict()\n",
    "    rng = np.random.RandomState(seed)\n",
    "    for key, id_list in group.items():\n",
    "        rng.shuffle(id_list)\n",
    "\n",
    "    splits_dir = save_dir / \"splits\"\n",
    "    splits_dir.mkdir(parents=True, exist_ok=True)\n",
    "    create_splits(str(splits_dir), group, K=K)\n",
    "    print(f\"[INFO] Wrote {K}-fold patient-level splits to {splits_dir}\")\n",
    "\n",
    "    # final warnings about missing files\n",
    "    if missing:\n",
    "        print(\"[WARN] Some samples were missing adata/patch files (listing up to 50):\")\n",
    "        for sid, typ in missing[:50]:\n",
    "            print(f\"  - {sid}: missing {typ}\")\n",
    "\n",
    "    print(f\"✅ Merged benchmark created at {save_dir}\")\n",
    "    return meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ec88b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_benchmark_from_eval_dirs(\n",
    "    save_dir: str | Path,\n",
    "    K: int,\n",
    "    eval_dirs: List[str | Path],\n",
    "    gene_k: int = 50,\n",
    "    gene_criteria: str = \"var\",\n",
    "    symlink: bool = False,\n",
    "    seed: int = 0,\n",
    "    metadata_csv: str = \"/project/simmons_hts/kxu/hest/hest_directory.csv\",\n",
    "    exclude_ids: Optional[List[str]] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a merged benchmark package by copying (or symlinking) assets from one or more\n",
    "    'eval' dataset folders that already contain:\n",
    "        <eval_dir>/\n",
    "            patches/\n",
    "                *.h5\n",
    "                vis/\n",
    "                    *.png\n",
    "            adata/\n",
    "                *.h5ad\n",
    "\n",
    "    Args:\n",
    "        save_dir: destination directory to create merged dataset (will contain patches/, patches/vis/, adata/, splits/, var_*.json)\n",
    "        K: number of folds (patient-level)\n",
    "        eval_dirs: list of dataset root paths to copy from (e.g. XeniumPR2 eval folder)\n",
    "        gene_k, gene_criteria: forwarded to get_k_genes\n",
    "        symlink: if True, create symlinks instead of copying\n",
    "        seed: RNG seed for deterministic fold assignment\n",
    "        metadata_csv: CSV mapping sample_id -> patient_id\n",
    "    Returns:\n",
    "        pd.DataFrame meta (columns: id, patient, dataset_title)\n",
    "    \"\"\"\n",
    "    from hest.HESTData import create_splits\n",
    "\n",
    "    save_dir = Path(save_dir)\n",
    "    eval_dirs = [Path(x) for x in eval_dirs]\n",
    "    # sanitise and check inputs\n",
    "    existing = [d for d in eval_dirs if d.exists() and d.is_dir()]\n",
    "    if not existing:\n",
    "        raise ValueError(f\"No valid eval_dirs found among: {eval_dirs}\")\n",
    "    print(f\"[INFO] Using eval dirs: {existing}\")\n",
    "\n",
    "    # discover sample ids by scanning adata/ and patches/ for filenames\n",
    "    discovered_ids = set()\n",
    "    sample_sources = {}  # id -> dict(sources found)\n",
    "    for d in existing:\n",
    "        adata_dir = d / \"adata\"\n",
    "        patches_dir = d / \"patches\"\n",
    "        vis_dir = patches_dir / \"vis\"\n",
    "\n",
    "        # adata\n",
    "        if adata_dir.exists() and adata_dir.is_dir():\n",
    "            for f in sorted(adata_dir.glob(\"*.h5ad\")):\n",
    "                sid = f.stem\n",
    "                discovered_ids.add(sid)\n",
    "                sample_sources.setdefault(sid, {}).setdefault(\"adata\", []).append(f)\n",
    "\n",
    "        # patches\n",
    "        if patches_dir.exists() and patches_dir.is_dir():\n",
    "            for f in sorted(patches_dir.glob(\"*.h5\")):\n",
    "                sid = f.stem\n",
    "                discovered_ids.add(sid)\n",
    "                sample_sources.setdefault(sid, {}).setdefault(\"patch\", []).append(f)\n",
    "\n",
    "            # vis images\n",
    "            if vis_dir.exists() and vis_dir.is_dir():\n",
    "                for f in sorted(vis_dir.glob(\"*.png\")):\n",
    "                    # allow vis file names like '<sid>_patch_vis.png' or '<sid>.png' or anything; map by stem heuristics\n",
    "                    stem = f.stem\n",
    "                    # normalize: if stem endswith '_patch_vis', strip it\n",
    "                    stem_clean = re.sub(r\"_?patch_vis$\", \"\", stem, flags=re.IGNORECASE)\n",
    "                    # sometimes vis is named '<sid>_patch_vis' or '<sid>'\n",
    "                    sid = stem_clean\n",
    "                    discovered_ids.add(sid)\n",
    "                    sample_sources.setdefault(sid, {}).setdefault(\"vis\", []).append(f)\n",
    "                    \n",
    "    # ---- Apply exclusion ----\n",
    "    if exclude_ids:\n",
    "        exclude_set = set(exclude_ids)\n",
    "        before = len(discovered_ids)\n",
    "        discovered_ids = [sid for sid in discovered_ids if sid not in exclude_set]\n",
    "\n",
    "        missing_excludes = exclude_set - set(discovered_ids)\n",
    "        if missing_excludes:\n",
    "            print(f\"[WARN] Some exclude_ids not found: {sorted(missing_excludes)}\")\n",
    "\n",
    "        removed = before - len(discovered_ids)\n",
    "        print(f\"[INFO] Excluded {removed} samples → remaining {len(discovered_ids)}\")\n",
    "        if removed > 0:\n",
    "            for e in sorted(exclude_set & set(discovered_ids)):\n",
    "                print(f\"   - excluded: {e}\")\n",
    "\n",
    "    discovered_ids = sorted(discovered_ids)\n",
    "    if not discovered_ids:\n",
    "        raise ValueError(\"No samples discovered in provided eval_dirs (no *.h5ad or *.h5 files found).\")\n",
    "    print(f\"[INFO] Discovered sample IDs ({len(discovered_ids)}): {discovered_ids}\")\n",
    "\n",
    "    # Prepare save_dir layout\n",
    "    patches_out = save_dir / \"patches\"\n",
    "    patches_vis_out = patches_out / \"vis\"\n",
    "    adata_out = save_dir / \"adata\"\n",
    "    for p in (patches_out, patches_vis_out, adata_out):\n",
    "\n",
    "        # Load metadata CSV mapping sample_id -> patient_id\n",
    "        patient_map = {}\n",
    "        meta_df_csv = None\n",
    "    if Path(metadata_csv).exists():\n",
    "        meta_df_csv = pd.read_csv(metadata_csv, dtype=str)\n",
    "        if {\"sample_id\", \"patient_id\"}.issubset(meta_df_csv.columns):\n",
    "            meta_df_csv[\"sample_id\"] = meta_df_csv[\"sample_id\"].astype(str).str.strip()\n",
    "            meta_df_csv[\"patient_id\"] = meta_df_csv[\"patient_id\"].astype(str).str.strip()\n",
    "            patient_map = dict(zip(meta_df_csv[\"sample_id\"], meta_df_csv[\"patient_id\"]))\n",
    "            print(f\"[INFO] Loaded {len(patient_map)} entries from {metadata_csv}\")\n",
    "        else:\n",
    "            print(f\"[WARN] metadata_csv missing columns 'sample_id'/'patient_id'; will fallback to automatic patient inference\")\n",
    "    else:\n",
    "        print(f\"[WARN] metadata_csv not found: {metadata_csv}; will fallback to automatic patient inference\")\n",
    "\n",
    "    # Copy / symlink files into save_dir using sample id as filename stem\n",
    "    missing = []\n",
    "    planned_actions = []\n",
    "    for sid in discovered_ids:\n",
    "        srcs = sample_sources.get(sid, {})\n",
    "        # choose one adata: prefer first available\n",
    "        adata_src = None\n",
    "        if \"adata\" in srcs and srcs[\"adata\"]:\n",
    "            adata_src = srcs[\"adata\"][0]\n",
    "        # else fallback to none\n",
    "\n",
    "        patch_src = None\n",
    "        if \"patch\" in srcs and srcs[\"patch\"]:\n",
    "            patch_src = srcs[\"patch\"][0]\n",
    "\n",
    "        # vis: there may be multiple pngs per sample across eval_dirs — keep all but use a standardized name\n",
    "        vis_srcs = srcs.get(\"vis\", [])\n",
    "\n",
    "        # plan copy/symlink\n",
    "        if adata_src:\n",
    "            dst = adata_out / f\"{sid}.h5ad\"\n",
    "            planned_actions.append((\"adata\", adata_src, dst))\n",
    "        else:\n",
    "            # warn — adata missing for this sid\n",
    "            missing.append((sid, \"adata\"))\n",
    "\n",
    "        if patch_src:\n",
    "            dst = patches_out / f\"{sid}.h5\"\n",
    "            planned_actions.append((\"patch\", patch_src, dst))\n",
    "        else:\n",
    "            missing.append((sid, \"patch\"))\n",
    "\n",
    "        # for vis, when multiple sources exist, copy each with a numeric suffix if needed\n",
    "        for i, vs in enumerate(vis_srcs, start=1):\n",
    "            # try base name '<sid>.png' then '<sid>_1.png', '<sid>_2.png'...\n",
    "            if i == 1:\n",
    "                dst = patches_vis_out / f\"{sid}.png\"\n",
    "            else:\n",
    "                dst = patches_vis_out / f\"{sid}_{i}.png\"\n",
    "            planned_actions.append((\"vis\", vs, dst))\n",
    "\n",
    "    # Show dry run summary\n",
    "    print(f\"[INFO] Planned actions: {len(planned_actions)} file operations; {len(missing)} missing types.\")\n",
    "    # perform file ops\n",
    "    for act, src, dst in planned_actions:\n",
    "        try:\n",
    "            _transfer(src, dst, act, symlink, [])  # we pass temporary missing list per transfer\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] transferring {src} -> {dst}: {e}\")\n",
    "\n",
    "    # Build metadata DataFrame: use discovered sample IDs and patient mapping (full sample id)\n",
    "    patient_ids = []\n",
    "    unresolved = []\n",
    "    for sid in discovered_ids:\n",
    "        pid = patient_map.get(sid)\n",
    "        if pid is None:\n",
    "            # fallback: try a stem match where original source had 'orig' info: try to find sample with full stem in filenames\n",
    "            # attempt to match any filename that contains sid as suffix: useful if CSV used 'XeniumPR1S1ROI1' but discovered was 'ROI1' etc.\n",
    "            # we'll try simple heuristics:\n",
    "            matched = None\n",
    "            if meta_df_csv is not None:\n",
    "                # try find any csv sample_id that endswith sid\n",
    "                candidates = [s for s in meta_df_csv[\"sample_id\"].values if str(s).endswith(str(sid))]\n",
    "                if candidates:\n",
    "                    matched = candidates[0]\n",
    "                    pid = patient_map.get(matched)\n",
    "            if pid is None:\n",
    "                # fallback to using prefix before '_' or the sid itself as patient\n",
    "                pid = sid.split(\"_\")[0] if \"_\" in sid else sid\n",
    "                unresolved.append(sid)\n",
    "        patient_ids.append(pid)\n",
    "\n",
    "    meta = pd.DataFrame({\"id\": discovered_ids, \"patient\": patient_ids, \"dataset_title\": [\"XeniumPR\"] * len(discovered_ids)})\n",
    "\n",
    "    print(f\"[INFO] Built metadata: {len(meta)} samples, {meta['patient'].nunique()} unique patients.\")\n",
    "    print(meta.head(20).to_string(index=False))\n",
    "\n",
    "    # write var_k genes (requires adata files to be present in save_dir or accessible)\n",
    "    adata_paths = [adata_out / f\"{sid}.h5ad\" for sid in discovered_ids]\n",
    "\n",
    "    var_json = save_dir / f\"var_{gene_k}genes.json\"\n",
    "    write_var_k_genes_from_paths(adata_paths, gene_k, gene_criteria, var_json)\n",
    "    print(f\"[INFO] Wrote {var_json}\")\n",
    "\n",
    "    # patient-level splits\n",
    "    group = meta.groupby([\"dataset_title\", \"patient\"])[\"id\"].agg(list).to_dict()\n",
    "    rng = np.random.RandomState(seed)\n",
    "    for key, id_list in group.items():\n",
    "        rng.shuffle(id_list)\n",
    "\n",
    "    splits_dir = save_dir / \"splits\"\n",
    "    splits_dir.mkdir(parents=True, exist_ok=True)\n",
    "    create_splits(str(splits_dir), group, K=K)\n",
    "    print(f\"[INFO] Wrote {K}-fold patient-level splits to {splits_dir}\")\n",
    "\n",
    "    # final warnings about missing files\n",
    "    if missing:\n",
    "        print(\"[WARN] Some samples were missing adata/patch files (listing up to 50):\")\n",
    "        for sid, typ in missing[:50]:\n",
    "            print(f\"  - {sid}: missing {typ}\")\n",
    "\n",
    "    print(f\"✅ Merged benchmark created at {save_dir}\")\n",
    "    return meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4aae7dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using eval dirs: [PosixPath('/project/simmons_hts/kxu/hest/eval/data/VisiumR1'), PosixPath('/project/simmons_hts/kxu/hest/eval/data/VisiumR2'), PosixPath('/project/simmons_hts/kxu/hest/eval/data/VisiumR3'), PosixPath('/project/simmons_hts/kxu/hest/eval/data/VisiumR4'), PosixPath('/project/simmons_hts/kxu/hest/eval/data/VisiumR5'), PosixPath('/project/simmons_hts/kxu/hest/eval/data/VisiumR6')]\n",
      "[INFO] Discovered sample IDs (35): ['VisiumR1S1ROI1', 'VisiumR1S1ROI2', 'VisiumR1S1ROI3', 'VisiumR1S1ROI4', 'VisiumR2S1ROI1', 'VisiumR2S1ROI2', 'VisiumR2S1ROI3', 'VisiumR2S1ROI4', 'VisiumR2S2ROI1', 'VisiumR2S2ROI2', 'VisiumR2S2ROI3', 'VisiumR2S2ROI4', 'VisiumR3S1ROI1', 'VisiumR3S1ROI2', 'VisiumR3S1ROI3', 'VisiumR3S1ROI4', 'VisiumR4S1ROI1', 'VisiumR4S1ROI2', 'VisiumR4S1ROI3', 'VisiumR4S1ROI4', 'VisiumR5S1ROI1', 'VisiumR5S1ROI2', 'VisiumR5S1ROI3', 'VisiumR5S1ROI4', 'VisiumR5S2ROI1', 'VisiumR5S2ROI2', 'VisiumR5S2ROI3', 'VisiumR6S1ROI1', 'VisiumR6S1ROI2', 'VisiumR6S1ROI3', 'VisiumR6S1ROI4', 'VisiumR6S2ROI1', 'VisiumR6S2ROI2', 'VisiumR6S2ROI3', 'VisiumR6S2ROI4']\n",
      "[INFO] Loaded 36 entries from /project/simmons_hts/kxu/hest/visium_directory.csv\n",
      "[INFO] Planned actions: 105 file operations; 0 missing types.\n",
      "[INFO] Built metadata: 35 samples, 34 unique patients.\n",
      "            id       patient dataset_title\n",
      "VisiumR1S1ROI1       GI 7051      XeniumPR\n",
      "VisiumR1S1ROI2       GI 6968      XeniumPR\n",
      "VisiumR1S1ROI3       GI 7595      XeniumPR\n",
      "VisiumR1S1ROI4       TIP 535      XeniumPR\n",
      "VisiumR2S1ROI1       GI 6966      XeniumPR\n",
      "VisiumR2S1ROI2       GI 7738      XeniumPR\n",
      "VisiumR2S1ROI3    TIP 473 JR      XeniumPR\n",
      "VisiumR2S1ROI4    TIP 633 JR      XeniumPR\n",
      "VisiumR2S2ROI1       TIP 522      XeniumPR\n",
      "VisiumR2S2ROI2       TIP 559      XeniumPR\n",
      "VisiumR2S2ROI3       TIP 815      XeniumPR\n",
      "VisiumR2S2ROI4       TIP 535      XeniumPR\n",
      "VisiumR3S1ROI1   JR_35259_13      XeniumPR\n",
      "VisiumR3S1ROI2   JR_51343_21      XeniumPR\n",
      "VisiumR3S1ROI3   JR_31183_22      XeniumPR\n",
      "VisiumR3S1ROI4   JR_17451_20      XeniumPR\n",
      "VisiumR4S1ROI1 BAY 113385_21      XeniumPR\n",
      "VisiumR4S1ROI2  BAY_22635_21      XeniumPR\n",
      "VisiumR4S1ROI3  BAY_94350_21      XeniumPR\n",
      "VisiumR4S1ROI4    JR 9174_22      XeniumPR\n",
      "min_cells is  173.0\n",
      "min_cells is  163.0\n",
      "min_cells is  175.0\n",
      "min_cells is  134.0\n",
      "min_cells is  295.0\n",
      "min_cells is  455.0\n",
      "min_cells is  460.0\n",
      "min_cells is  462.0\n",
      "min_cells is  274.0\n",
      "min_cells is  382.0\n",
      "min_cells is  280.0\n",
      "min_cells is  393.0\n",
      "min_cells is  282.0\n",
      "min_cells is  421.0\n",
      "min_cells is  389.0\n",
      "min_cells is  382.0\n",
      "min_cells is  381.0\n",
      "min_cells is  461.0\n",
      "min_cells is  493.0\n",
      "min_cells is  428.0\n",
      "min_cells is  432.0\n",
      "min_cells is  225.0\n",
      "min_cells is  413.0\n",
      "min_cells is  253.0\n",
      "min_cells is  406.0\n",
      "min_cells is  235.0\n",
      "min_cells is  191.0\n",
      "min_cells is  245.0\n",
      "min_cells is  353.0\n",
      "min_cells is  358.0\n",
      "min_cells is  422.0\n",
      "min_cells is  303.0\n",
      "min_cells is  290.0\n",
      "min_cells is  370.0\n",
      "min_cells is  483.0\n",
      "\u001b[32m15:14:44\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mFound 128 common genes\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m15:14:56\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mselected genes ['ATP5PD', 'B2M', 'CAPN1', 'CFD', 'CHCHD2', 'CNDP2', 'COL1A2', 'COX5B', 'COX8A', 'CTSD', 'CYC1', 'CYCS', 'EDF1', 'EEF1B2', 'EIF4A1', 'EIF4H', 'ENO1', 'FLNA', 'FTH1', 'GOLM1', 'GSN', 'GSTP1', 'HDGF', 'HLA-DMA', 'HNRNPA3', 'HSPB1', 'IGFBP7', 'IGKC', 'IL32', 'ITM2B', 'LASP1', 'LGALS3BP', 'LRP10', 'MT1X', 'MT2A', 'NCL', 'NDUFA13', 'NDUFB7', 'NDUFS6', 'P4HB', 'PABPC1', 'PNPLA2', 'POR', 'RAC1', 'TAGLN2', 'TMSB4X', 'TPM1', 'TPM2', 'UBC', 'VDAC1']\u001b[0m\n",
      "[INFO] Wrote /project/simmons_hts/kxu/hest/eval/data/VisiumR1-6/var_50genes.json (top-50, criteria=var); /project/simmons_hts/kxu/hest/eval/data/VisiumR1-6/all_genes.json (all_common=17943); /project/simmons_hts/kxu/hest/eval/data/VisiumR1-6/common_genes_0.1.json (filtered_common=128, min_cells_pct=0.1)\n",
      "[INFO] Wrote /project/simmons_hts/kxu/hest/eval/data/VisiumR1-6/var_50genes.json\n",
      "K=15 doesnt match the number of patients, try to distribute the patients instead\n",
      "Split 0/18\n",
      "train set is  ['VisiumR6S2ROI2', 'VisiumR5S1ROI2', 'VisiumR4S1ROI2', 'VisiumR5S1ROI4', 'VisiumR4S1ROI3', 'VisiumR2S1ROI1', 'VisiumR1S1ROI2', 'VisiumR1S1ROI1', 'VisiumR1S1ROI3', 'VisiumR2S1ROI2', 'VisiumR4S1ROI4', 'VisiumR6S1ROI1', 'VisiumR3S1ROI4', 'VisiumR6S2ROI1', 'VisiumR5S2ROI2', 'VisiumR6S1ROI4', 'VisiumR3S1ROI3', 'VisiumR3S1ROI1', 'VisiumR6S2ROI4', 'VisiumR6S1ROI3', 'VisiumR5S2ROI1', 'VisiumR3S1ROI2', 'VisiumR5S1ROI3', 'VisiumR6S1ROI2', 'VisiumR5S1ROI1', 'VisiumR2S1ROI3', 'VisiumR2S2ROI1', 'VisiumR5S2ROI3', 'VisiumR2S2ROI4', 'VisiumR1S1ROI4', 'VisiumR2S2ROI2', 'VisiumR2S1ROI4', 'VisiumR2S2ROI3']\n",
      "\n",
      "test set is  ['VisiumR4S1ROI1' 'VisiumR6S2ROI3']\n",
      "\n",
      "Split 1/18\n",
      "train set is  ['VisiumR4S1ROI1', 'VisiumR6S2ROI3', 'VisiumR4S1ROI2', 'VisiumR5S1ROI4', 'VisiumR4S1ROI3', 'VisiumR2S1ROI1', 'VisiumR1S1ROI2', 'VisiumR1S1ROI1', 'VisiumR1S1ROI3', 'VisiumR2S1ROI2', 'VisiumR4S1ROI4', 'VisiumR6S1ROI1', 'VisiumR3S1ROI4', 'VisiumR6S2ROI1', 'VisiumR5S2ROI2', 'VisiumR6S1ROI4', 'VisiumR3S1ROI3', 'VisiumR3S1ROI1', 'VisiumR6S2ROI4', 'VisiumR6S1ROI3', 'VisiumR5S2ROI1', 'VisiumR3S1ROI2', 'VisiumR5S1ROI3', 'VisiumR6S1ROI2', 'VisiumR5S1ROI1', 'VisiumR2S1ROI3', 'VisiumR2S2ROI1', 'VisiumR5S2ROI3', 'VisiumR2S2ROI4', 'VisiumR1S1ROI4', 'VisiumR2S2ROI2', 'VisiumR2S1ROI4', 'VisiumR2S2ROI3']\n",
      "\n",
      "test set is  ['VisiumR6S2ROI2' 'VisiumR5S1ROI2']\n",
      "\n",
      "Split 2/18\n",
      "train set is  ['VisiumR4S1ROI1', 'VisiumR6S2ROI3', 'VisiumR6S2ROI2', 'VisiumR5S1ROI2', 'VisiumR4S1ROI3', 'VisiumR2S1ROI1', 'VisiumR1S1ROI2', 'VisiumR1S1ROI1', 'VisiumR1S1ROI3', 'VisiumR2S1ROI2', 'VisiumR4S1ROI4', 'VisiumR6S1ROI1', 'VisiumR3S1ROI4', 'VisiumR6S2ROI1', 'VisiumR5S2ROI2', 'VisiumR6S1ROI4', 'VisiumR3S1ROI3', 'VisiumR3S1ROI1', 'VisiumR6S2ROI4', 'VisiumR6S1ROI3', 'VisiumR5S2ROI1', 'VisiumR3S1ROI2', 'VisiumR5S1ROI3', 'VisiumR6S1ROI2', 'VisiumR5S1ROI1', 'VisiumR2S1ROI3', 'VisiumR2S2ROI1', 'VisiumR5S2ROI3', 'VisiumR2S2ROI4', 'VisiumR1S1ROI4', 'VisiumR2S2ROI2', 'VisiumR2S1ROI4', 'VisiumR2S2ROI3']\n",
      "\n",
      "test set is  ['VisiumR4S1ROI2' 'VisiumR5S1ROI4']\n",
      "\n",
      "Split 3/18\n",
      "train set is  ['VisiumR4S1ROI1', 'VisiumR6S2ROI3', 'VisiumR6S2ROI2', 'VisiumR5S1ROI2', 'VisiumR4S1ROI2', 'VisiumR5S1ROI4', 'VisiumR1S1ROI2', 'VisiumR1S1ROI1', 'VisiumR1S1ROI3', 'VisiumR2S1ROI2', 'VisiumR4S1ROI4', 'VisiumR6S1ROI1', 'VisiumR3S1ROI4', 'VisiumR6S2ROI1', 'VisiumR5S2ROI2', 'VisiumR6S1ROI4', 'VisiumR3S1ROI3', 'VisiumR3S1ROI1', 'VisiumR6S2ROI4', 'VisiumR6S1ROI3', 'VisiumR5S2ROI1', 'VisiumR3S1ROI2', 'VisiumR5S1ROI3', 'VisiumR6S1ROI2', 'VisiumR5S1ROI1', 'VisiumR2S1ROI3', 'VisiumR2S2ROI1', 'VisiumR5S2ROI3', 'VisiumR2S2ROI4', 'VisiumR1S1ROI4', 'VisiumR2S2ROI2', 'VisiumR2S1ROI4', 'VisiumR2S2ROI3']\n",
      "\n",
      "test set is  ['VisiumR4S1ROI3' 'VisiumR2S1ROI1']\n",
      "\n",
      "Split 4/18\n",
      "train set is  ['VisiumR4S1ROI1', 'VisiumR6S2ROI3', 'VisiumR6S2ROI2', 'VisiumR5S1ROI2', 'VisiumR4S1ROI2', 'VisiumR5S1ROI4', 'VisiumR4S1ROI3', 'VisiumR2S1ROI1', 'VisiumR1S1ROI3', 'VisiumR2S1ROI2', 'VisiumR4S1ROI4', 'VisiumR6S1ROI1', 'VisiumR3S1ROI4', 'VisiumR6S2ROI1', 'VisiumR5S2ROI2', 'VisiumR6S1ROI4', 'VisiumR3S1ROI3', 'VisiumR3S1ROI1', 'VisiumR6S2ROI4', 'VisiumR6S1ROI3', 'VisiumR5S2ROI1', 'VisiumR3S1ROI2', 'VisiumR5S1ROI3', 'VisiumR6S1ROI2', 'VisiumR5S1ROI1', 'VisiumR2S1ROI3', 'VisiumR2S2ROI1', 'VisiumR5S2ROI3', 'VisiumR2S2ROI4', 'VisiumR1S1ROI4', 'VisiumR2S2ROI2', 'VisiumR2S1ROI4', 'VisiumR2S2ROI3']\n",
      "\n",
      "test set is  ['VisiumR1S1ROI2' 'VisiumR1S1ROI1']\n",
      "\n",
      "Split 5/18\n",
      "train set is  ['VisiumR4S1ROI1', 'VisiumR6S2ROI3', 'VisiumR6S2ROI2', 'VisiumR5S1ROI2', 'VisiumR4S1ROI2', 'VisiumR5S1ROI4', 'VisiumR4S1ROI3', 'VisiumR2S1ROI1', 'VisiumR1S1ROI2', 'VisiumR1S1ROI1', 'VisiumR4S1ROI4', 'VisiumR6S1ROI1', 'VisiumR3S1ROI4', 'VisiumR6S2ROI1', 'VisiumR5S2ROI2', 'VisiumR6S1ROI4', 'VisiumR3S1ROI3', 'VisiumR3S1ROI1', 'VisiumR6S2ROI4', 'VisiumR6S1ROI3', 'VisiumR5S2ROI1', 'VisiumR3S1ROI2', 'VisiumR5S1ROI3', 'VisiumR6S1ROI2', 'VisiumR5S1ROI1', 'VisiumR2S1ROI3', 'VisiumR2S2ROI1', 'VisiumR5S2ROI3', 'VisiumR2S2ROI4', 'VisiumR1S1ROI4', 'VisiumR2S2ROI2', 'VisiumR2S1ROI4', 'VisiumR2S2ROI3']\n",
      "\n",
      "test set is  ['VisiumR1S1ROI3' 'VisiumR2S1ROI2']\n",
      "\n",
      "Split 6/18\n",
      "train set is  ['VisiumR4S1ROI1', 'VisiumR6S2ROI3', 'VisiumR6S2ROI2', 'VisiumR5S1ROI2', 'VisiumR4S1ROI2', 'VisiumR5S1ROI4', 'VisiumR4S1ROI3', 'VisiumR2S1ROI1', 'VisiumR1S1ROI2', 'VisiumR1S1ROI1', 'VisiumR1S1ROI3', 'VisiumR2S1ROI2', 'VisiumR3S1ROI4', 'VisiumR6S2ROI1', 'VisiumR5S2ROI2', 'VisiumR6S1ROI4', 'VisiumR3S1ROI3', 'VisiumR3S1ROI1', 'VisiumR6S2ROI4', 'VisiumR6S1ROI3', 'VisiumR5S2ROI1', 'VisiumR3S1ROI2', 'VisiumR5S1ROI3', 'VisiumR6S1ROI2', 'VisiumR5S1ROI1', 'VisiumR2S1ROI3', 'VisiumR2S2ROI1', 'VisiumR5S2ROI3', 'VisiumR2S2ROI4', 'VisiumR1S1ROI4', 'VisiumR2S2ROI2', 'VisiumR2S1ROI4', 'VisiumR2S2ROI3']\n",
      "\n",
      "test set is  ['VisiumR4S1ROI4' 'VisiumR6S1ROI1']\n",
      "\n",
      "Split 7/18\n",
      "train set is  ['VisiumR4S1ROI1', 'VisiumR6S2ROI3', 'VisiumR6S2ROI2', 'VisiumR5S1ROI2', 'VisiumR4S1ROI2', 'VisiumR5S1ROI4', 'VisiumR4S1ROI3', 'VisiumR2S1ROI1', 'VisiumR1S1ROI2', 'VisiumR1S1ROI1', 'VisiumR1S1ROI3', 'VisiumR2S1ROI2', 'VisiumR4S1ROI4', 'VisiumR6S1ROI1', 'VisiumR5S2ROI2', 'VisiumR6S1ROI4', 'VisiumR3S1ROI3', 'VisiumR3S1ROI1', 'VisiumR6S2ROI4', 'VisiumR6S1ROI3', 'VisiumR5S2ROI1', 'VisiumR3S1ROI2', 'VisiumR5S1ROI3', 'VisiumR6S1ROI2', 'VisiumR5S1ROI1', 'VisiumR2S1ROI3', 'VisiumR2S2ROI1', 'VisiumR5S2ROI3', 'VisiumR2S2ROI4', 'VisiumR1S1ROI4', 'VisiumR2S2ROI2', 'VisiumR2S1ROI4', 'VisiumR2S2ROI3']\n",
      "\n",
      "test set is  ['VisiumR3S1ROI4' 'VisiumR6S2ROI1']\n",
      "\n",
      "Split 8/18\n",
      "train set is  ['VisiumR4S1ROI1', 'VisiumR6S2ROI3', 'VisiumR6S2ROI2', 'VisiumR5S1ROI2', 'VisiumR4S1ROI2', 'VisiumR5S1ROI4', 'VisiumR4S1ROI3', 'VisiumR2S1ROI1', 'VisiumR1S1ROI2', 'VisiumR1S1ROI1', 'VisiumR1S1ROI3', 'VisiumR2S1ROI2', 'VisiumR4S1ROI4', 'VisiumR6S1ROI1', 'VisiumR3S1ROI4', 'VisiumR6S2ROI1', 'VisiumR3S1ROI3', 'VisiumR3S1ROI1', 'VisiumR6S2ROI4', 'VisiumR6S1ROI3', 'VisiumR5S2ROI1', 'VisiumR3S1ROI2', 'VisiumR5S1ROI3', 'VisiumR6S1ROI2', 'VisiumR5S1ROI1', 'VisiumR2S1ROI3', 'VisiumR2S2ROI1', 'VisiumR5S2ROI3', 'VisiumR2S2ROI4', 'VisiumR1S1ROI4', 'VisiumR2S2ROI2', 'VisiumR2S1ROI4', 'VisiumR2S2ROI3']\n",
      "\n",
      "test set is  ['VisiumR5S2ROI2' 'VisiumR6S1ROI4']\n",
      "\n",
      "Split 9/18\n",
      "train set is  ['VisiumR4S1ROI1', 'VisiumR6S2ROI3', 'VisiumR6S2ROI2', 'VisiumR5S1ROI2', 'VisiumR4S1ROI2', 'VisiumR5S1ROI4', 'VisiumR4S1ROI3', 'VisiumR2S1ROI1', 'VisiumR1S1ROI2', 'VisiumR1S1ROI1', 'VisiumR1S1ROI3', 'VisiumR2S1ROI2', 'VisiumR4S1ROI4', 'VisiumR6S1ROI1', 'VisiumR3S1ROI4', 'VisiumR6S2ROI1', 'VisiumR5S2ROI2', 'VisiumR6S1ROI4', 'VisiumR6S2ROI4', 'VisiumR6S1ROI3', 'VisiumR5S2ROI1', 'VisiumR3S1ROI2', 'VisiumR5S1ROI3', 'VisiumR6S1ROI2', 'VisiumR5S1ROI1', 'VisiumR2S1ROI3', 'VisiumR2S2ROI1', 'VisiumR5S2ROI3', 'VisiumR2S2ROI4', 'VisiumR1S1ROI4', 'VisiumR2S2ROI2', 'VisiumR2S1ROI4', 'VisiumR2S2ROI3']\n",
      "\n",
      "test set is  ['VisiumR3S1ROI3' 'VisiumR3S1ROI1']\n",
      "\n",
      "Split 10/18\n",
      "train set is  ['VisiumR4S1ROI1', 'VisiumR6S2ROI3', 'VisiumR6S2ROI2', 'VisiumR5S1ROI2', 'VisiumR4S1ROI2', 'VisiumR5S1ROI4', 'VisiumR4S1ROI3', 'VisiumR2S1ROI1', 'VisiumR1S1ROI2', 'VisiumR1S1ROI1', 'VisiumR1S1ROI3', 'VisiumR2S1ROI2', 'VisiumR4S1ROI4', 'VisiumR6S1ROI1', 'VisiumR3S1ROI4', 'VisiumR6S2ROI1', 'VisiumR5S2ROI2', 'VisiumR6S1ROI4', 'VisiumR3S1ROI3', 'VisiumR3S1ROI1', 'VisiumR5S2ROI1', 'VisiumR3S1ROI2', 'VisiumR5S1ROI3', 'VisiumR6S1ROI2', 'VisiumR5S1ROI1', 'VisiumR2S1ROI3', 'VisiumR2S2ROI1', 'VisiumR5S2ROI3', 'VisiumR2S2ROI4', 'VisiumR1S1ROI4', 'VisiumR2S2ROI2', 'VisiumR2S1ROI4', 'VisiumR2S2ROI3']\n",
      "\n",
      "test set is  ['VisiumR6S2ROI4' 'VisiumR6S1ROI3']\n",
      "\n",
      "Split 11/18\n",
      "train set is  ['VisiumR4S1ROI1', 'VisiumR6S2ROI3', 'VisiumR6S2ROI2', 'VisiumR5S1ROI2', 'VisiumR4S1ROI2', 'VisiumR5S1ROI4', 'VisiumR4S1ROI3', 'VisiumR2S1ROI1', 'VisiumR1S1ROI2', 'VisiumR1S1ROI1', 'VisiumR1S1ROI3', 'VisiumR2S1ROI2', 'VisiumR4S1ROI4', 'VisiumR6S1ROI1', 'VisiumR3S1ROI4', 'VisiumR6S2ROI1', 'VisiumR5S2ROI2', 'VisiumR6S1ROI4', 'VisiumR3S1ROI3', 'VisiumR3S1ROI1', 'VisiumR6S2ROI4', 'VisiumR6S1ROI3', 'VisiumR5S1ROI3', 'VisiumR6S1ROI2', 'VisiumR5S1ROI1', 'VisiumR2S1ROI3', 'VisiumR2S2ROI1', 'VisiumR5S2ROI3', 'VisiumR2S2ROI4', 'VisiumR1S1ROI4', 'VisiumR2S2ROI2', 'VisiumR2S1ROI4', 'VisiumR2S2ROI3']\n",
      "\n",
      "test set is  ['VisiumR5S2ROI1' 'VisiumR3S1ROI2']\n",
      "\n",
      "Split 12/18\n",
      "train set is  ['VisiumR4S1ROI1', 'VisiumR6S2ROI3', 'VisiumR6S2ROI2', 'VisiumR5S1ROI2', 'VisiumR4S1ROI2', 'VisiumR5S1ROI4', 'VisiumR4S1ROI3', 'VisiumR2S1ROI1', 'VisiumR1S1ROI2', 'VisiumR1S1ROI1', 'VisiumR1S1ROI3', 'VisiumR2S1ROI2', 'VisiumR4S1ROI4', 'VisiumR6S1ROI1', 'VisiumR3S1ROI4', 'VisiumR6S2ROI1', 'VisiumR5S2ROI2', 'VisiumR6S1ROI4', 'VisiumR3S1ROI3', 'VisiumR3S1ROI1', 'VisiumR6S2ROI4', 'VisiumR6S1ROI3', 'VisiumR5S2ROI1', 'VisiumR3S1ROI2', 'VisiumR5S1ROI1', 'VisiumR2S1ROI3', 'VisiumR2S2ROI1', 'VisiumR5S2ROI3', 'VisiumR2S2ROI4', 'VisiumR1S1ROI4', 'VisiumR2S2ROI2', 'VisiumR2S1ROI4', 'VisiumR2S2ROI3']\n",
      "\n",
      "test set is  ['VisiumR5S1ROI3' 'VisiumR6S1ROI2']\n",
      "\n",
      "Split 13/18\n",
      "train set is  ['VisiumR4S1ROI1', 'VisiumR6S2ROI3', 'VisiumR6S2ROI2', 'VisiumR5S1ROI2', 'VisiumR4S1ROI2', 'VisiumR5S1ROI4', 'VisiumR4S1ROI3', 'VisiumR2S1ROI1', 'VisiumR1S1ROI2', 'VisiumR1S1ROI1', 'VisiumR1S1ROI3', 'VisiumR2S1ROI2', 'VisiumR4S1ROI4', 'VisiumR6S1ROI1', 'VisiumR3S1ROI4', 'VisiumR6S2ROI1', 'VisiumR5S2ROI2', 'VisiumR6S1ROI4', 'VisiumR3S1ROI3', 'VisiumR3S1ROI1', 'VisiumR6S2ROI4', 'VisiumR6S1ROI3', 'VisiumR5S2ROI1', 'VisiumR3S1ROI2', 'VisiumR5S1ROI3', 'VisiumR6S1ROI2', 'VisiumR2S2ROI1', 'VisiumR5S2ROI3', 'VisiumR2S2ROI4', 'VisiumR1S1ROI4', 'VisiumR2S2ROI2', 'VisiumR2S1ROI4', 'VisiumR2S2ROI3']\n",
      "\n",
      "test set is  ['VisiumR5S1ROI1' 'VisiumR2S1ROI3']\n",
      "\n",
      "Split 14/18\n",
      "train set is  ['VisiumR4S1ROI1', 'VisiumR6S2ROI3', 'VisiumR6S2ROI2', 'VisiumR5S1ROI2', 'VisiumR4S1ROI2', 'VisiumR5S1ROI4', 'VisiumR4S1ROI3', 'VisiumR2S1ROI1', 'VisiumR1S1ROI2', 'VisiumR1S1ROI1', 'VisiumR1S1ROI3', 'VisiumR2S1ROI2', 'VisiumR4S1ROI4', 'VisiumR6S1ROI1', 'VisiumR3S1ROI4', 'VisiumR6S2ROI1', 'VisiumR5S2ROI2', 'VisiumR6S1ROI4', 'VisiumR3S1ROI3', 'VisiumR3S1ROI1', 'VisiumR6S2ROI4', 'VisiumR6S1ROI3', 'VisiumR5S2ROI1', 'VisiumR3S1ROI2', 'VisiumR5S1ROI3', 'VisiumR6S1ROI2', 'VisiumR5S1ROI1', 'VisiumR2S1ROI3', 'VisiumR2S2ROI4', 'VisiumR1S1ROI4', 'VisiumR2S2ROI2', 'VisiumR2S1ROI4', 'VisiumR2S2ROI3']\n",
      "\n",
      "test set is  ['VisiumR2S2ROI1' 'VisiumR5S2ROI3']\n",
      "\n",
      "Split 15/18\n",
      "train set is  ['VisiumR4S1ROI1', 'VisiumR6S2ROI3', 'VisiumR6S2ROI2', 'VisiumR5S1ROI2', 'VisiumR4S1ROI2', 'VisiumR5S1ROI4', 'VisiumR4S1ROI3', 'VisiumR2S1ROI1', 'VisiumR1S1ROI2', 'VisiumR1S1ROI1', 'VisiumR1S1ROI3', 'VisiumR2S1ROI2', 'VisiumR4S1ROI4', 'VisiumR6S1ROI1', 'VisiumR3S1ROI4', 'VisiumR6S2ROI1', 'VisiumR5S2ROI2', 'VisiumR6S1ROI4', 'VisiumR3S1ROI3', 'VisiumR3S1ROI1', 'VisiumR6S2ROI4', 'VisiumR6S1ROI3', 'VisiumR5S2ROI1', 'VisiumR3S1ROI2', 'VisiumR5S1ROI3', 'VisiumR6S1ROI2', 'VisiumR5S1ROI1', 'VisiumR2S1ROI3', 'VisiumR2S2ROI1', 'VisiumR5S2ROI3', 'VisiumR2S2ROI2', 'VisiumR2S1ROI4', 'VisiumR2S2ROI3']\n",
      "\n",
      "test set is  ['VisiumR2S2ROI4' 'VisiumR1S1ROI4']\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 16/18\n",
      "train set is  ['VisiumR4S1ROI1', 'VisiumR6S2ROI3', 'VisiumR6S2ROI2', 'VisiumR5S1ROI2', 'VisiumR4S1ROI2', 'VisiumR5S1ROI4', 'VisiumR4S1ROI3', 'VisiumR2S1ROI1', 'VisiumR1S1ROI2', 'VisiumR1S1ROI1', 'VisiumR1S1ROI3', 'VisiumR2S1ROI2', 'VisiumR4S1ROI4', 'VisiumR6S1ROI1', 'VisiumR3S1ROI4', 'VisiumR6S2ROI1', 'VisiumR5S2ROI2', 'VisiumR6S1ROI4', 'VisiumR3S1ROI3', 'VisiumR3S1ROI1', 'VisiumR6S2ROI4', 'VisiumR6S1ROI3', 'VisiumR5S2ROI1', 'VisiumR3S1ROI2', 'VisiumR5S1ROI3', 'VisiumR6S1ROI2', 'VisiumR5S1ROI1', 'VisiumR2S1ROI3', 'VisiumR2S2ROI1', 'VisiumR5S2ROI3', 'VisiumR2S2ROI4', 'VisiumR1S1ROI4', 'VisiumR2S2ROI3']\n",
      "\n",
      "test set is  ['VisiumR2S2ROI2' 'VisiumR2S1ROI4']\n",
      "\n",
      "Split 17/18\n",
      "train set is  ['VisiumR4S1ROI1', 'VisiumR6S2ROI3', 'VisiumR6S2ROI2', 'VisiumR5S1ROI2', 'VisiumR4S1ROI2', 'VisiumR5S1ROI4', 'VisiumR4S1ROI3', 'VisiumR2S1ROI1', 'VisiumR1S1ROI2', 'VisiumR1S1ROI1', 'VisiumR1S1ROI3', 'VisiumR2S1ROI2', 'VisiumR4S1ROI4', 'VisiumR6S1ROI1', 'VisiumR3S1ROI4', 'VisiumR6S2ROI1', 'VisiumR5S2ROI2', 'VisiumR6S1ROI4', 'VisiumR3S1ROI3', 'VisiumR3S1ROI1', 'VisiumR6S2ROI4', 'VisiumR6S1ROI3', 'VisiumR5S2ROI1', 'VisiumR3S1ROI2', 'VisiumR5S1ROI3', 'VisiumR6S1ROI2', 'VisiumR5S1ROI1', 'VisiumR2S1ROI3', 'VisiumR2S2ROI1', 'VisiumR5S2ROI3', 'VisiumR2S2ROI4', 'VisiumR1S1ROI4', 'VisiumR2S2ROI2', 'VisiumR2S1ROI4']\n",
      "\n",
      "test set is  ['VisiumR2S2ROI3']\n",
      "\n",
      "[INFO] Wrote 15-fold patient-level splits to /project/simmons_hts/kxu/hest/eval/data/VisiumR1-6/splits\n",
      "✅ Merged benchmark created at /project/simmons_hts/kxu/hest/eval/data/VisiumR1-6\n"
     ]
    }
   ],
   "source": [
    "meta = create_benchmark_from_eval_dirs(\n",
    "    save_dir=\"/project/simmons_hts/kxu/hest/eval/data/VisiumR1-6\",\n",
    "    K=15,\n",
    "    eval_dirs=[\"/project/simmons_hts/kxu/hest/eval/data/VisiumR1\",\n",
    "               \"/project/simmons_hts/kxu/hest/eval/data/VisiumR2\",\n",
    "               \"/project/simmons_hts/kxu/hest/eval/data/VisiumR3\",\n",
    "               \"/project/simmons_hts/kxu/hest/eval/data/VisiumR4\",\n",
    "               \"/project/simmons_hts/kxu/hest/eval/data/VisiumR5\",\n",
    "               \"/project/simmons_hts/kxu/hest/eval/data/VisiumR6\",\n",
    "    ],\n",
    "    gene_k=50,\n",
    "    symlink=False,\n",
    "    seed=0,\n",
    "    metadata_csv=\"/project/simmons_hts/kxu/hest/visium_directory.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f1a8ad",
   "metadata": {},
   "source": [
    "### add extra sets of variable genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e1f8fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87d4593e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- computing top-1000 (var) -> /project/simmons_hts/kxu/hest/eval/data/VisiumR1-6/var_1000genes.json ---\n",
      "min_cells is  18.0\n",
      "min_cells is  17.0\n",
      "min_cells is  18.0\n",
      "min_cells is  14.0\n",
      "min_cells is  18.0\n",
      "min_cells is  17.0\n",
      "min_cells is  18.0\n",
      "min_cells is  14.0\n",
      "min_cells is  30.0\n",
      "min_cells is  46.0\n",
      "min_cells is  46.0\n",
      "min_cells is  47.0\n",
      "min_cells is  28.0\n",
      "min_cells is  39.0\n",
      "min_cells is  28.0\n",
      "min_cells is  40.0\n",
      "min_cells is  29.0\n",
      "min_cells is  43.0\n",
      "min_cells is  39.0\n",
      "min_cells is  39.0\n",
      "min_cells is  39.0\n",
      "min_cells is  47.0\n",
      "min_cells is  50.0\n",
      "min_cells is  43.0\n",
      "min_cells is  44.0\n",
      "min_cells is  23.0\n",
      "min_cells is  42.0\n",
      "min_cells is  26.0\n",
      "min_cells is  41.0\n",
      "min_cells is  24.0\n",
      "min_cells is  20.0\n",
      "min_cells is  25.0\n",
      "min_cells is  36.0\n",
      "min_cells is  36.0\n",
      "min_cells is  43.0\n",
      "min_cells is  31.0\n",
      "min_cells is  29.0\n",
      "min_cells is  37.0\n",
      "min_cells is  49.0\n",
      "min_cells is  18.0\n",
      "min_cells is  17.0\n",
      "min_cells is  18.0\n",
      "min_cells is  14.0\n",
      "\u001b[32m15:18:15\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mFound 3046 common genes\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m15:18:50\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mselected genes ['A2M', 'AAMP', 'ABCC3', 'ABHD12', 'ABI1', 'ABLIM1', 'ABR', 'ABTB2', 'ACAA1', 'ACAA2', 'ACADM', 'ACAP1', 'ACO2', 'ACOT7', 'ACOX1', 'ACOX3', 'ACSL5', 'ACTG2', 'ACTN1', 'ACTN4', 'ACTR1A', 'ADAM15', 'ADD1', 'ADIPOR1', 'ADIRF', 'ADM', 'ADNP', 'AEBP1', 'AFDN', 'AGAP3', 'AGPAT3', 'AHCYL1', 'AKAP1', 'AKAP6', 'AKNA', 'AKT1S1', 'ALDH18A1', 'ALDH1B1', 'ALDH2', 'ALDH3A2', 'ALKBH5', 'AMOTL1', 'ANKLE2', 'ANP32B', 'ANPEP', 'ANXA1', 'ANXA2', 'ANXA7', 'AP2S1', 'APEX1', 'API5', 'APOBR', 'APOE', 'APOL1', 'APRT', 'AQP1', 'AQP3', 'ARF1', 'ARF5', 'ARHGAP45', 'ARHGDIB', 'ARHGEF10L', 'ARL2', 'ARL4A', 'ARL6IP5', 'ARPC1A', 'ARRDC4', 'ASAP2', 'ATOX1', 'ATP2A3', 'ATP2B4', 'ATP5F1A', 'ATP5F1B', 'ATP5F1D', 'ATP5F1E', 'ATP5MC3', 'ATP5ME', 'ATP5MF', 'ATP5PB', 'ATP5PF', 'ATP6V0D1', 'ATP6V1B2', 'ATP6V1E1', 'ATP6V1F', 'ATP8B1', 'ATXN7L3B', 'BCAM', 'BCAP31', 'BCL2L11', 'BCL2L2', 'BCL7C', 'BCL9L', 'BCR', 'BECN1', 'BGN', 'BICD2', 'BLMH', 'BNIP3L', 'BOK', 'BOP1', 'BRI3BP', 'BRK1', 'BSG', 'BST2', 'BTG2', 'BUB3', 'BX255925.3', 'BZW1', 'C11orf96', 'C14orf119', 'C19orf53', 'C1QB', 'C1QC', 'C1orf115', 'C1orf122', 'C1orf198', 'C3', 'C3orf70', 'CALCOCO1', 'CALCOCO2', 'CALD1', 'CAMK2N1', 'CANT1', 'CANX', 'CAPG', 'CAPN1', 'CAPNS1', 'CAST', 'CAT', 'CBFB', 'CBR1', 'CCDC124', 'CCDC47', 'CCDC9B', 'CCND2', 'CCT3', 'CCT5', 'CCT7', 'CCT8', 'CD276', 'CD2AP', 'CD34', 'CD44', 'CD68', 'CD82', 'CDC42EP1', 'CDC42EP5', 'CDC42SE1', 'CDKN1A', 'CEBPA', 'CENPB', 'CENPX', 'CEP170B', 'CFB', 'CFD', 'CFL2', 'CFLAR', 'CHMP1A', 'CHMP2A', 'CHMP4B', 'CHTOP', 'CHURC1', 'CIITA', 'CISD3', 'CKAP4', 'CLCN3', 'CLEC14A', 'CLEC3B', 'CLIC1', 'CLIP1', 'CLN3', 'CLPTM1', 'CLSTN1', 'CLTB', 'CLU', 'CLUH', 'CMPK1', 'CNDP2', 'CNKSR1', 'CNN1', 'CNN3', 'COA3', 'COA4', 'COL16A1', 'COL1A2', 'COL4A2', 'COL5A1', 'COMT', 'COPS6', 'COQ4', 'CORO1B', 'COTL1', 'COX16', 'COX4I1', 'COX5A', 'COX6A1', 'COX6B1', 'COX7C', 'COX8A', 'CPE', 'CPXM2', 'CRIP1', 'CRIP2', 'CRYBG1', 'CSNK1D', 'CST3', 'CTNNBIP1', 'CTNND1', 'CTSC', 'CTSD', 'CTSH', 'CTSK', 'CTSS', 'CUL4A', 'CXCL12', 'CYB5A', 'CYB5B', 'CYB5R1', 'CYBC1', 'CYC1', 'CYCS', 'CYP27A1', 'DAD1', 'DAZAP1', 'DBI', 'DCAF11', 'DCAF8', 'DCTD', 'DCTN2', 'DDR1', 'DDT', 'DDX21', 'DDX39B', 'DDX3X', 'DDX41', 'DDX46', 'DDX56', 'DEDD2', 'DENND2D', 'DFFA', 'DGKA', 'DHRS7', 'DHX15', 'DKK3', 'DLD', 'DLGAP4', 'DMD', 'DMPK', 'DNAJA4', 'DNAJB11', 'DNAJB2', 'DNAJB6', 'DNAJC5', 'DNMT1', 'DNPH1', 'DPT', 'DPYSL3', 'DUS1L', 'DUSP23', 'DYNC1I2', 'DYNLL1', 'DYNLL2', 'EBPL', 'ECHDC2', 'ECHS1', 'EEF1G', 'EFHD2', 'EFTUD2', 'EHD4', 'EI24', 'EIF1', 'EIF2B1', 'EIF3B', 'EIF3D', 'EIF3H', 'EIF3I', 'EIF3K', 'EIF3L', 'EIF3M', 'EIF4A1', 'EIF4G2', 'EIF6', 'EMD', 'EMP1', 'ENG', 'ENO1', 'EPB41L3', 'EPHB4', 'EPHX2', 'EPN1', 'EPN2', 'EPSTI1', 'ERG28', 'ERGIC1', 'ERN1', 'ERO1A', 'ERP29', 'ERP44', 'ERRFI1', 'ESD', 'ESYT1', 'ETFA', 'ETHE1', 'EXOC3', 'EZR', 'FAM102A', 'FAM162A', 'FAM89B', 'FARSA', 'FASN', 'FASTK', 'FBLN2', 'FBP1', 'FBXW5', 'FCHSD1', 'FDFT1', 'FDPS', 'FEM1B', 'FGFR1', 'FGL2', 'FKBP1A', 'FKBP5', 'FLVCR2', 'FOS', 'FOSL2', 'FXYD1', 'FXYD6', 'G0S2', 'GADD45A', 'GADD45B', 'GADD45GIP1', 'GALNT6', 'GBP2', 'GBP4', 'GCHFR', 'GET3', 'GGT1', 'GID8', 'GIPC1', 'GJA1', 'GLO1', 'GLUL', 'GLYCTK', 'GLYR1', 'GMPS', 'GNAI3', 'GNLY', 'GOLGA4', 'GOLGA7', 'GOLM1', 'GPAA1', 'GPI', 'GPS1', 'GPX4', 'GREM1', 'GRN', 'GRSF1', 'GSDMB', 'GSTK1', 'GSTO1', 'GSTP1', 'GTF2F2', 'GTF2I', 'GUCY1A1', 'H2AFJ', 'H2AFV', 'H2AFY', 'H3F3B', 'HAAO', 'HADHA', 'HADHB', 'HBS1L', 'HDAC5', 'HDGF', 'HDHD3', 'HEBP2', 'HECTD1', 'HINT1', 'HIP1R', 'HIPK3', 'HIST1H1D', 'HIST1H2AD', 'HIST1H2AE', 'HIST1H2BD', 'HIST1H2BN', 'HIST1H3D', 'HIST1H3G', 'HIST1H4A', 'HIST1H4B', 'HIST1H4C', 'HIST1H4D', 'HIST1H4E', 'HIST1H4H', 'HIST2H2AB', 'HLA-DMB', 'HLA-DPA1', 'HLA-DPB1', 'HLA-DRA', 'HLA-F', 'HMGA1', 'HMGB1', 'HMOX1', 'HNRNPA2B1', 'HNRNPAB', 'HNRNPC', 'HNRNPF', 'HNRNPH1', 'HNRNPR', 'HNRNPUL2', 'HPCAL1', 'HRAS', 'HSP90AA1', 'HSP90AB1', 'HSPA1A', 'HSPA1B', 'HSPA8', 'HSPB1', 'HSPB6', 'HSPD1', 'HSPE1', 'HSPG2', 'HTATIP2', 'HTRA1', 'HUWE1', 'ID1', 'ID2', 'IDH2', 'IDI1', 'IER2', 'IFI27', 'IFI6', 'IFITM3', 'IFRD2', 'IGFBP3', 'IGFBP5', 'IGHA1', 'IGKC', 'IGSF8', 'IK', 'IL2RG', 'IL32', 'ILVBL', 'IMP3', 'INCENP', 'INF2', 'INSIG1', 'INSR', 'IP6K2', 'IRAK1', 'IRF1', 'ISG15', 'ISG20', 'ITGA3', 'ITGA5', 'ITGA6', 'ITM2C', 'ITPKC', 'ITPR3', 'JCHAIN', 'JMY', 'JPT1', 'JUNB', 'KANK2', 'KCNMA1', 'KCNMB1', 'KCTD12', 'KDELR2', 'KDM5B', 'KDSR', 'KHSRP', 'KIAA1211', 'KIF1B', 'KIF1C', 'KIFC2', 'KLC1', 'KLC4', 'KLF4', 'KPNB1', 'KRT10', 'KRT8', 'KXD1', 'LAMA5', 'LAMB1', 'LAMP1', 'LAP3', 'LARP4B', 'LDB1', 'LGALS3', 'LITAF', 'LMNB2', 'LMO7', 'LMOD1', 'LPGAT1', 'LPIN2', 'LRP1', 'LSM14A', 'LSM4', 'LTB', 'LTBP4', 'LUM', 'LYZ', 'M6PR', 'MACF1', 'MAF', 'MAN1A1', 'MAN2B1', 'MAP1B', 'MAP3K11', 'MAP4', 'MAP7D1', 'MAPK13', 'MAPK14', 'MAPK1IP1L', 'MAPK3', 'MARK2', 'MATR3', 'MAX', 'MAZ', 'MBNL2', 'MCAM', 'MCFD2', 'MCM5', 'MCUR1', 'MDH1', 'MDH2', 'MED15', 'METRNL', 'MFSD1', 'MFSD11', 'MFSD14B', 'MGAT4B', 'MIA2', 'MIDN', 'MIF', 'MIGA2', 'MINK1', 'MKNK2', 'MKRN1', 'MLLT6', 'MMADHC', 'MMP2', 'MMP24OS', 'MOB3B', 'MOV10', 'MPC2', 'MPEG1', 'MPST', 'MRGPRF', 'MRVI1', 'MT1E', 'MT1X', 'MTCH2', 'MTDH', 'MTPN', 'MVD', 'MVP', 'MXD4', 'MXI1', 'MYL12B', 'MYL9', 'MYLK', 'MYO10', 'MYO15B', 'MYO18A', 'N4BP1', 'NAIP', 'NAPA', 'NBR1', 'NCK2', 'NCKAP1', 'NCSTN', 'NDFIP2', 'NDRG1', 'NDRG2', 'NDUFA1', 'NDUFA10', 'NDUFA11', 'NDUFA12', 'NDUFA7', 'NDUFA9', 'NDUFB2', 'NDUFB9', 'NDUFC1', 'NDUFC2', 'NDUFS1', 'NDUFS2', 'NDUFS3', 'NDUFS4', 'NDUFS8', 'NEDD9', 'NELFE', 'NFE2L2', 'NHP2', 'NHSL1', 'NIBAN2', 'NIPAL2', 'NME2', 'NPC2', 'NR1H3', 'NR2F2', 'NR2F6', 'NRDC', 'NRIP1', 'NRP2', 'NSA2', 'NSMF', 'NUCKS1', 'NUDT16', 'NUP62', 'NUPR1', 'NUTF2', 'NXF1', 'NXN', 'OAS3', 'OGDH', 'OGN', 'OLFM1', 'OSTF1', 'OTUB1', 'PA2G4', 'PAK4', 'PALLD', 'PAPSS2', 'PARD3', 'PATJ', 'PBX1', 'PCK2', 'PCM1', 'PCSK5', 'PCYOX1', 'PDGFA', 'PDHA1', 'PDLIM3', 'PDLIM4', 'PDLIM7', 'PDXK', 'PEBP1', 'PECAM1', 'PES1', 'PEX26', 'PFDN5', 'PFKL', 'PFKP', 'PGAM1', 'PGK1', 'PGLS', 'PGRMC2', 'PHB2', 'PHGDH', 'PIM1', 'PLAAT4', 'PLAUR', 'PLCB3', 'PLD2', 'PLEKHG5', 'PLEKHO1', 'PLIN3', 'PLOD2', 'PLPP3', 'PLS3', 'PLSCR3', 'PLXDC2', 'PLXND1', 'PMEPA1', 'PML', 'PMVK', 'PNRC1', 'POLD4', 'POLDIP2', 'POLR1D', 'POLR2A', 'POLR2B', 'POLR2H', 'POLR2I', 'POLR2L', 'POR', 'PPA2', 'PPDPF', 'PPP1CC', 'PPP1R12B', 'PPP1R14A', 'PPP1R15A', 'PPP1R16A', 'PPP2R5C', 'PPP6R1', 'PRCC', 'PRDX4', 'PRDX5', 'PRDX6', 'PRELID3B', 'PRKCD', 'PRKD2', 'PRNP', 'PRR13', 'PRSS23', 'PRXL2A', 'PRXL2B', 'PSD4', 'PSMA2', 'PSMA4', 'PSMA5', 'PSMB10', 'PSMB2', 'PSMB5', 'PSMB7', 'PSMB8', 'PSMC3', 'PSMC4', 'PSMC5', 'PSMD8', 'PSME1', 'PSME2', 'PSMF1', 'PTBP3', 'PTGES2', 'PTGS1', 'PTN', 'PTPA', 'PUF60', 'PURB', 'PYCARD', 'PYURF', 'QARS', 'QRICH1', 'RAB11A', 'RAB18', 'RAB1B', 'RAB21', 'RAB24', 'RAB5A', 'RAB5B', 'RAB5IF', 'RAB7A', 'RABGGTB', 'RABL6', 'RALA', 'RARS', 'RASD1', 'RASSF4', 'RBBP6', 'RBM15B', 'RBX1', 'RCC2', 'RCN2', 'REEP3', 'RELCH', 'RER1', 'RGL2', 'RHOF', 'RHOU', 'RNASE1', 'RNF11', 'RNF141', 'RNF167', 'RNF187', 'RNH1', 'RPN2', 'RREB1', 'RTCB', 'RUVBL2', 'RXRA', 'S100A10', 'S100A11', 'S100A13', 'S100A16', 'SAMHD1', 'SAP18', 'SAT2', 'SBNO2', 'SCP2', 'SCPEP1', 'SCRIB', 'SDC1', 'SDC4', 'SDHA', 'SEC11C', 'SEC24C', 'SEL1L3', 'SELENBP1', 'SELENOW', 'SEMA3G', 'SEPHS2', 'SEPTIN6', 'SERBP1', 'SERP1', 'SERPINB6', 'SET', 'SF3B6', 'SFPQ', 'SFXN3', 'SGK1', 'SGPL1', 'SH3BGRL3', 'SH3BP1', 'SH3BP5L', 'SH3YL1', 'SIGMAR1', 'SIRT7', 'SKAP1', 'SLC16A1', 'SLC25A10', 'SLC25A28', 'SLC25A39', 'SLC25A4', 'SLC26A2', 'SLC31A1', 'SLC35A4', 'SLC36A1', 'SLC37A1', 'SLC39A14', 'SLC43A2', 'SLC44A2', 'SLC9A3R1', 'SLC9A3R2', 'SLIRP', 'SLMAP', 'SMAD3', 'SMARCD2', 'SMDT1', 'SMG1', 'SMIM4', 'SMTN', 'SNCG', 'SNRPB', 'SNRPC', 'SNRPD1', 'SNU13', 'SNX1', 'SNX17', 'SNX3', 'SOD3', 'SON', 'SORBS1', 'SORL1', 'SPG21', 'SPTLC1', 'SPTLC2', 'SRC', 'SREBF2', 'SRP68', 'SRSF1', 'SRSF2', 'SSBP1', 'SSC5D', 'SSH2', 'SSNA1', 'SSR1', 'SSR4', 'SSU72', 'ST6GALNAC6', 'STARD5', 'STAT3', 'STAT6', 'STAU2', 'STK11', 'STK17B', 'STRAP', 'STX7', 'SUCLG1', 'SUMO1', 'SUPT16H', 'SUPT5H', 'SURF4', 'SVIL', 'SYNC', 'SYNE2', 'SYNGR2', 'SYNM', 'SYNPO2', 'TAF15', 'TAGLN', 'TAGLN2', 'TALDO1', 'TAP1', 'TAP2', 'TAX1BP1', 'TBCB', 'TCF7L2', 'TCP1', 'TDP2', 'TENT5A', 'TFG', 'TGFB1I1', 'TGFBI', 'TGIF1', 'TGM2', 'TGOLN2', 'THBS1', 'THOC7', 'THRA', 'THRAP3', 'TIMM13', 'TIMMDC1', 'TIMP1', 'TIMP3', 'TKT', 'TMBIM1', 'TMED10', 'TMED2', 'TMED9', 'TMEM134', 'TMEM159', 'TMEM189', 'TMEM43', 'TMEM59', 'TMX2', 'TNFSF10', 'TNKS1BP1', 'TNS1', 'TNXB', 'TOB2', 'TOLLIP', 'TOM1', 'TOX4', 'TP53I3', 'TPD52', 'TPM1', 'TPM2', 'TPSB2', 'TRAF4', 'TRAK1', 'TRAP1', 'TRAPPC1', 'TRAPPC5', 'TRBC1', 'TRIM22', 'TRIM25', 'TRIM26', 'TRIP12', 'TRIR', 'TRMT112', 'TRPM4', 'TSPAN13', 'TSPAN2', 'TSPO', 'TTC38', 'TTC39B', 'TUBA4A', 'TUBB6', 'TUFM', 'TXLNA', 'TXN', 'TXNDC11', 'TXNDC17', 'TXNIP', 'TYROBP', 'UACA', 'UBA2', 'UBB', 'UBC', 'UBE2E3', 'UBE2G2', 'UBE2H', 'UBE2J1', 'UBE2L6', 'UBE2R2', 'UBE2V1', 'UBE4B', 'UBL3', 'UBL5', 'UCHL1', 'ULK3', 'UQCR11', 'UQCRC1', 'UQCRC2', 'UQCRQ', 'VAMP8', 'VASH1', 'VAT1', 'VCP', 'VDAC2', 'VGLL4', 'VPS25', 'VPS29', 'VPS4B', 'VPS53', 'VWA1', 'VWF', 'WARS', 'WASF2', 'WBP2', 'WDR26', 'WDR45B', 'WDR83OS', 'WIPF1', 'WSB2', 'XBP1', 'XPOT', 'XRCC5', 'XRCC6', 'YWHAQ', 'ZBTB7B', 'ZCCHC24', 'ZFP36L1', 'ZMIZ1', 'ZMIZ2', 'ZMPSTE24', 'ZNF207', 'ZNF598', 'ZZEF1']\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Wrote /project/simmons_hts/kxu/hest/eval/data/VisiumR1-6/var_1000genes.json (top-1000, criteria=var); /project/simmons_hts/kxu/hest/eval/data/VisiumR1-6/all_genes.json (all_common=17943); /project/simmons_hts/kxu/hest/eval/data/VisiumR1-6/common_genes_0.01.json (filtered_common=3046, min_cells_pct=0.01)\n",
      "\n",
      "--- computing top-3000 (var) -> /project/simmons_hts/kxu/hest/eval/data/VisiumR1-6/var_3000genes.json ---\n",
      "min_cells is  18.0\n",
      "min_cells is  17.0\n",
      "min_cells is  18.0\n",
      "min_cells is  14.0\n",
      "min_cells is  18.0\n",
      "min_cells is  17.0\n",
      "min_cells is  18.0\n",
      "min_cells is  14.0\n",
      "min_cells is  30.0\n",
      "min_cells is  46.0\n",
      "min_cells is  46.0\n",
      "min_cells is  47.0\n",
      "min_cells is  28.0\n",
      "min_cells is  39.0\n",
      "min_cells is  28.0\n",
      "min_cells is  40.0\n",
      "min_cells is  29.0\n",
      "min_cells is  43.0\n",
      "min_cells is  39.0\n",
      "min_cells is  39.0\n",
      "min_cells is  39.0\n",
      "min_cells is  47.0\n",
      "min_cells is  50.0\n",
      "min_cells is  43.0\n",
      "min_cells is  44.0\n",
      "min_cells is  23.0\n",
      "min_cells is  42.0\n",
      "min_cells is  26.0\n",
      "min_cells is  41.0\n",
      "min_cells is  24.0\n",
      "min_cells is  20.0\n",
      "min_cells is  25.0\n",
      "min_cells is  36.0\n",
      "min_cells is  36.0\n",
      "min_cells is  43.0\n",
      "min_cells is  31.0\n",
      "min_cells is  29.0\n",
      "min_cells is  37.0\n",
      "min_cells is  49.0\n",
      "min_cells is  18.0\n",
      "min_cells is  17.0\n",
      "min_cells is  18.0\n",
      "min_cells is  14.0\n",
      "\u001b[32m15:19:01\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mFound 3046 common genes\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/package/python-cbrg/current/3.11.14/lib/python3.11/site-packages/anndata/_core/anndata.py:1796: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m15:19:22\u001b[0m | \u001b[1mINFO\u001b[0m | \u001b[1mselected genes ['A2M', 'AAMP', 'AARS', 'ABCA2', 'ABCC1', 'ABCC3', 'ABCD4', 'ABCF3', 'ABHD12', 'ABHD16A', 'ABHD17B', 'ABHD2', 'ABHD4', 'ABI1', 'ABL1', 'ABLIM1', 'ABLIM3', 'ABR', 'ABTB1', 'ABTB2', 'ACAA1', 'ACAA2', 'ACACA', 'ACACB', 'ACAD11', 'ACADM', 'ACADVL', 'ACAP1', 'ACAT1', 'ACBD6', 'ACIN1', 'ACLY', 'ACO2', 'ACOT7', 'ACOT9', 'ACOX1', 'ACOX3', 'ACP2', 'ACSL3', 'ACSL5', 'ACSS1', 'ACTA2', 'ACTB', 'ACTG2', 'ACTN1', 'ACTN4', 'ACTR1A', 'ACTR1B', 'ACTR3', 'ACVR1B', 'ADAM15', 'ADAM19', 'ADAM9', 'ADAP2', 'ADAR', 'ADARB1', 'ADCY6', 'ADD1', 'ADH5', 'ADI1', 'ADIPOR1', 'ADIRF', 'ADM', 'ADNP', 'ADSL', 'AEBP1', 'AFAP1', 'AFDN', 'AGAP1', 'AGAP3', 'AGAP9', 'AGO1', 'AGO2', 'AGPAT1', 'AGPAT3', 'AGPS', 'AGRN', 'AHCYL1', 'AHNAK', 'AHSA1', 'AIDA', 'AIG1', 'AIP', 'AK1', 'AKAP1', 'AKAP11', 'AKAP13', 'AKAP17A', 'AKAP6', 'AKNA', 'AKR1A1', 'AKT1', 'AKT1S1', 'AKT2', 'AKT3', 'ALAD', 'ALDH16A1', 'ALDH18A1', 'ALDH1B1', 'ALDH2', 'ALDH3A2', 'ALDH3B1', 'ALG11', 'ALG5', 'ALKBH5', 'ALKBH7', 'AMBRA1', 'AMDHD2', 'AMOTL1', 'ANAPC13', 'ANAPC16', 'ANAPC2', 'ANGPTL2', 'ANKH', 'ANKHD1', 'ANKLE2', 'ANKRD10', 'ANKRD17', 'ANKRD36C', 'ANKRD39', 'ANKRD52', 'ANKZF1', 'ANO6', 'ANP32A', 'ANP32B', 'ANP32E', 'ANPEP', 'ANTKMT', 'ANTXR2', 'ANXA1', 'ANXA11', 'ANXA2', 'ANXA5', 'ANXA6', 'ANXA7', 'AP1AR', 'AP1M1', 'AP2A2', 'AP2M1', 'AP2S1', 'AP3D1', 'AP5B1', 'AP5Z1', 'APBB2', 'APEX1', 'APH1A', 'API5', 'APIP', 'APLP2', 'APOBR', 'APOE', 'APOL1', 'APP', 'APPL1', 'APRT', 'AQP1', 'AQP3', 'ARAF', 'ARAP1', 'ARCN1', 'ARF1', 'ARF3', 'ARF4', 'ARF5', 'ARFGAP2', 'ARFGAP3', 'ARFGEF2', 'ARHGAP17', 'ARHGAP18', 'ARHGAP26', 'ARHGAP31', 'ARHGAP45', 'ARHGDIA', 'ARHGDIB', 'ARHGEF10L', 'ARHGEF11', 'ARHGEF17', 'ARHGEF2', 'ARHGEF25', 'ARHGEF40', 'ARHGEF7', 'ARID1A', 'ARID1B', 'ARID3A', 'ARID4A', 'ARIH1', 'ARL14EP', 'ARL17A', 'ARL2', 'ARL2BP', 'ARL4A', 'ARL6IP4', 'ARL6IP5', 'ARMC8', 'ARMCX3', 'ARPC1A', 'ARPC1B', 'ARPC2', 'ARPC3', 'ARPC4', 'ARPC5', 'ARPP19', 'ARRB1', 'ARRDC3', 'ARRDC4', 'ARSA', 'ASAH1', 'ASAP2', 'ASB1', 'ASCC3', 'ASPH', 'ASXL1', 'ATAD1', 'ATF4', 'ATF6B', 'ATG12', 'ATG13', 'ATG14', 'ATG2B', 'ATG4B', 'ATG5', 'ATG9A', 'ATIC', 'ATL3', 'ATN1', 'ATOX1', 'ATP11A', 'ATP13A2', 'ATP2A2', 'ATP2A3', 'ATP2B4', 'ATP5F1A', 'ATP5F1B', 'ATP5F1D', 'ATP5F1E', 'ATP5IF1', 'ATP5MC2', 'ATP5MC3', 'ATP5ME', 'ATP5MF', 'ATP5MG', 'ATP5PB', 'ATP5PD', 'ATP5PF', 'ATP6V0A1', 'ATP6V0B', 'ATP6V0D1', 'ATP6V1A', 'ATP6V1B2', 'ATP6V1E1', 'ATP6V1F', 'ATP8A1', 'ATP8B1', 'ATPAF1', 'ATPSCKMT', 'ATRAID', 'ATRN', 'ATXN10', 'ATXN1L', 'ATXN2L', 'ATXN7', 'ATXN7L3', 'ATXN7L3B', 'AURKAIP1', 'AVEN', 'AXL', 'AZIN1', 'B2M', 'B4GALT5', 'BABAM1', 'BACE2', 'BAD', 'BAG1', 'BAG5', 'BAG6', 'BANF1', 'BAX', 'BAZ1B', 'BCAM', 'BCAP31', 'BCKDHB', 'BCL2', 'BCL2L1', 'BCL2L11', 'BCL2L13', 'BCL2L2', 'BCL7C', 'BCL9L', 'BCR', 'BCS1L', 'BECN1', 'BET1', 'BET1L', 'BEX3', 'BGN', 'BICD2', 'BICRA', 'BIN1', 'BIRC2', 'BLMH', 'BLOC1S1', 'BLOC1S3', 'BMERB1', 'BMI1', 'BMS1', 'BNIP3L', 'BOC', 'BOD1', 'BOK', 'BOP1', 'BORCS6', 'BPNT1', 'BPTF', 'BRD1', 'BRD2', 'BRD4', 'BRI3', 'BRI3BP', 'BRK1', 'BRMS1', 'BRWD1', 'BSCL2', 'BSDC1', 'BSG', 'BST2', 'BTAF1', 'BTBD2', 'BTBD6', 'BTBD7', 'BTG2', 'BTN3A2', 'BUB3', 'BUD23', 'BX255925.3', 'BZW1', 'C11orf49', 'C11orf58', 'C11orf96', 'C11orf98', 'C12orf57', 'C14orf119', 'C16orf58', 'C16orf91', 'C17orf58', 'C19orf25', 'C19orf53', 'C1QB', 'C1QC', 'C1R', 'C1S', 'C1orf115', 'C1orf122', 'C1orf198', 'C1orf52', 'C3', 'C3orf70', 'C4orf3', 'C4orf48', 'C5orf15', 'C6orf89', 'C8orf33', 'C8orf76', 'C9orf64', 'C9orf85', 'CABIN1', 'CACTIN', 'CALCOCO1', 'CALCOCO2', 'CALD1', 'CALM3', 'CALR', 'CALU', 'CAMK2N1', 'CAMKK2', 'CAMLG', 'CAMTA2', 'CANT1', 'CANX', 'CAP1', 'CAPG', 'CAPN1', 'CAPN2', 'CAPN7', 'CAPNS1', 'CAPZA2', 'CAPZB', 'CARD19', 'CARD8', 'CARMIL1', 'CARS2', 'CASC3', 'CASP4', 'CASP6', 'CASP8AP2', 'CAST', 'CAT', 'CAVIN1', 'CAVIN3', 'CBFB', 'CBR1', 'CBX4', 'CBX5', 'CBX6', 'CCAR2', 'CCDC107', 'CCDC124', 'CCDC47', 'CCDC50', 'CCDC57', 'CCDC6', 'CCDC69', 'CCDC71L', 'CCDC84', 'CCDC85B', 'CCDC88A', 'CCDC91', 'CCDC92', 'CCDC97', 'CCDC9B', 'CCN1', 'CCN2', 'CCNB1IP1', 'CCND2', 'CCNDBP1', 'CCNI', 'CCNL1', 'CCNL2', 'CCNY', 'CCNYL1', 'CCS', 'CCT3', 'CCT5', 'CCT7', 'CCT8', 'CD151', 'CD276', 'CD2AP', 'CD2BP2', 'CD34', 'CD44', 'CD63', 'CD68', 'CD7', 'CD74', 'CD81', 'CD82', 'CD99L2', 'CDAN1', 'CDC123', 'CDC16', 'CDC34', 'CDC40', 'CDC42BPB', 'CDC42EP1', 'CDC42EP5', 'CDC42SE1', 'CDC42SE2', 'CDIP1', 'CDK10', 'CDK12', 'CDK18', 'CDK4', 'CDK6', 'CDK7', 'CDKN1A', 'CDKN1B', 'CDKN1C', 'CDS2', 'CDV3', 'CDYL', 'CEBPA', 'CEBPD', 'CEBPZ', 'CELF1', 'CENPB', 'CENPT', 'CENPX', 'CEP170B', 'CERCAM', 'CERS2', 'CFAP97', 'CFB', 'CFD', 'CFDP1', 'CFL2', 'CFLAR', 'CGGBP1', 'CGNL1', 'CHCHD1', 'CHCHD10', 'CHCHD2', 'CHD2', 'CHD4', 'CHD9', 'CHKB', 'CHMP1A', 'CHMP1B', 'CHMP2A', 'CHMP3', 'CHMP4A', 'CHMP4B', 'CHMP5', 'CHMP6', 'CHMP7', 'CHPF', 'CHTF8', 'CHTOP', 'CHURC1', 'CIAO2B', 'CIAO3', 'CIITA', 'CIRBP', 'CISD3', 'CKAP4', 'CLASP2', 'CLASRP', 'CLCN3', 'CLCN7', 'CLEC10A', 'CLEC14A', 'CLEC3B', 'CLIC1', 'CLIP1', 'CLK3', 'CLN3', 'CLN6', 'CLPTM1', 'CLPTM1L', 'CLSTN1', 'CLTA', 'CLTB', 'CLU', 'CLUH', 'CMPK1', 'CMTM4', 'CMTR1', 'CNBP', 'CNDP2', 'CNEP1R1', 'CNKSR1', 'CNKSR3', 'CNN1', 'CNN2', 'CNN3', 'CNOT2', 'CNOT3', 'CNOT4', 'CNOT7', 'CNOT8', 'CNPPD1', 'CNPY2', 'CNPY3', 'COA3', 'COA4', 'COG2', 'COG8', 'COL16A1', 'COL18A1', 'COL1A1', 'COL1A2', 'COL23A1', 'COL3A1', 'COL4A1', 'COL4A2', 'COL5A1', 'COL6A1', 'COL6A2', 'COL6A3', 'COMMD4', 'COMMD9', 'COMT', 'COMTD1', 'COPA', 'COPB2', 'COPE', 'COPG1', 'COPS3', 'COPS5', 'COPS6', 'COPS7A', 'COPS7B', 'COPS8', 'COPS9', 'COPZ1', 'COQ4', 'COQ7', 'COQ8B', 'CORO1A', 'CORO1B', 'CORO1C', 'COTL1', 'COX14', 'COX15', 'COX16', 'COX17', 'COX4I1', 'COX4I2', 'COX5A', 'COX5B', 'COX6A1', 'COX6B1', 'COX6C', 'COX7A2', 'COX7C', 'COX8A', 'CPD', 'CPE', 'CPEB4', 'CPNE1', 'CPSF1', 'CPSF4', 'CPSF6', 'CPSF7', 'CPXM2', 'CRACR2A', 'CRAT', 'CREB3', 'CREB3L1', 'CREB3L2', 'CREBZF', 'CRELD1', 'CRELD2', 'CRIM1', 'CRIP1', 'CRIP2', 'CRLF3', 'CRLS1', 'CRY2', 'CRYBG1', 'CSAD', 'CSF1', 'CSF1R', 'CSGALNACT2', 'CSNK1D', 'CSNK1G2', 'CSNK2B', 'CST3', 'CSTF3', 'CTBP1', 'CTC1', 'CTDNEP1', 'CTDP1', 'CTDSP1', 'CTDSP2', 'CTNNA1', 'CTNNAL1', 'CTNNB1', 'CTNNBIP1', 'CTNNBL1', 'CTNND1', 'CTSB', 'CTSC', 'CTSD', 'CTSH', 'CTSK', 'CTSS', 'CTSZ', 'CUEDC2', 'CUL4A', 'CUL7', 'CUTA', 'CUX1', 'CWC15', 'CWC25', 'CWC27', 'CXCL12', 'CYB5A', 'CYB5B', 'CYB5R1', 'CYB5R3', 'CYBA', 'CYBC1', 'CYC1', 'CYCS', 'CYLD', 'CYP27A1', 'CYREN', 'CYTH2', 'D2HGDH', 'DAD1', 'DAPK3', 'DAXX', 'DAZAP1', 'DBI', 'DBN1', 'DBNDD2', 'DBNL', 'DCAF11', 'DCAF16', 'DCAF5', 'DCAF7', 'DCAF8', 'DCBLD1', 'DCN', 'DCTD', 'DCTN1', 'DCTN2', 'DCTN4', 'DCTN6', 'DCUN1D1', 'DCUN1D2', 'DCXR', 'DDAH2', 'DDB1', 'DDHD2', 'DDIT3', 'DDIT4', 'DDR1', 'DDRGK1', 'DDT', 'DDX17', 'DDX21', 'DDX23', 'DDX24', 'DDX27', 'DDX39B', 'DDX3X', 'DDX41', 'DDX46', 'DDX49', 'DDX5', 'DDX54', 'DDX56', 'DECR1', 'DEDD', 'DEDD2', 'DEK', 'DELE1', 'DENND10', 'DENND1A', 'DENND2D', 'DENND6A', 'DENR', 'DESI2', 'DEXI', 'DFFA', 'DGCR8', 'DGKA', 'DGKD', 'DGKQ', 'DHPS', 'DHRS3', 'DHRS7', 'DHX15', 'DHX35', 'DIAPH2', 'DIP2A', 'DIP2C', 'DKK3', 'DLD', 'DLGAP4', 'DMAC2', 'DMAP1', 'DMD', 'DMPK', 'DMTN', 'DMXL1', 'DNAAF5', 'DNAJA3', 'DNAJA4', 'DNAJB11', 'DNAJB2', 'DNAJB6', 'DNAJC1', 'DNAJC21', 'DNAJC5', 'DNAJC7', 'DNAJC8', 'DNM2', 'DNMT1', 'DNPEP', 'DNPH1', 'DOCK1', 'DOCK5', 'DONSON', 'DOT1L', 'DPF2', 'DPM3', 'DPP7', 'DPP9', 'DPT', 'DPYSL2', 'DPYSL3', 'DR1', 'DRAP1', 'DTX3L', 'DUS1L', 'DUSP1', 'DUSP22', 'DUSP23', 'DUSP6', 'DVL3', 'DYNC1H1', 'DYNC1I2', 'DYNC1LI2', 'DYNLL1', 'DYNLL2', 'E2F4', 'E4F1', 'EBPL', 'ECE1', 'ECH1', 'ECHDC2', 'ECHS1', 'ECI1', 'ECSIT', 'EDF1', 'EEF1B2', 'EEF1D', 'EEF1G', 'EEF2', 'EFHD2', 'EFTUD2', 'EGLN2', 'EHBP1L1', 'EHD1', 'EHD2', 'EHD4', 'EHMT1', 'EI24', 'EID1', 'EID2', 'EIF1', 'EIF1AD', 'EIF1B', 'EIF2AK3', 'EIF2B1', 'EIF2B5', 'EIF2D', 'EIF3A', 'EIF3B', 'EIF3D', 'EIF3G', 'EIF3H', 'EIF3I', 'EIF3K', 'EIF3L', 'EIF3M', 'EIF4A1', 'EIF4A2', 'EIF4B', 'EIF4E2', 'EIF4E3', 'EIF4ENIF1', 'EIF4G1', 'EIF4G2', 'EIF4H', 'EIF5', 'EIF6', 'ELAVL1', 'ELF2', 'ELL', 'ELL2', 'ELMSAN1', 'ELOF1', 'ELP5', 'ELP6', 'EMC10', 'EMC4', 'EMD', 'EMILIN1', 'EML3', 'EMP1', 'EMP3', 'ENG', 'ENO1', 'ENTPD4', 'EP300', 'EPB41L3', 'EPC2', 'EPHB4', 'EPHX2', 'EPN1', 'EPN2', 'EPSTI1', 'ERCC1', 'ERCC5', 'ERG28', 'ERGIC1', 'ERGIC3', 'ERH', 'ERN1', 'ERO1A', 'ERP29', 'ERP44', 'ERRFI1', 'ERVK3-1', 'ESD', 'ESF1', 'ESS2', 'ESYT1', 'ESYT2', 'ETFA', 'ETFB', 'ETFRF1', 'ETHE1', 'ETNK1', 'ETS1', 'ETV3', 'EVI5L', 'EVL', 'EXOC3', 'EXOSC6', 'EXOSC7', 'EZR', 'FAAP100', 'FAH', 'FAHD1', 'FAM102A', 'FAM104A', 'FAM120A', 'FAM120AOS', 'FAM120B', 'FAM126B', 'FAM13A', 'FAM162A', 'FAM172A', 'FAM193A', 'FAM193B', 'FAM199X', 'FAM204A', 'FAM207A', 'FAM20C', 'FAM210B', 'FAM219B', 'FAM234A', 'FAM32A', 'FAM3A', 'FAM3C', 'FAM50A', 'FAM53C', 'FAM89B', 'FAM8A1', 'FAM98C', 'FARP1', 'FARSA', 'FASN', 'FASTK', 'FBF1', 'FBLIM1', 'FBLN1', 'FBLN2', 'FBN1', 'FBP1', 'FBRSL1', 'FBXL17', 'FBXL19', 'FBXL4', 'FBXL5', 'FBXO22', 'FBXO32', 'FBXO33', 'FBXO7', 'FBXW11', 'FBXW2', 'FBXW4', 'FBXW5', 'FCGRT', 'FCHSD1', 'FDFT1', 'FDPS', 'FEM1B', 'FEM1C', 'FERMT2', 'FGD2', 'FGFR1', 'FGFR1OP2', 'FGFRL1', 'FGL2', 'FHL2', 'FIBP', 'FIS1', 'FKBP1A', 'FKBP3', 'FKBP5', 'FKBP8', 'FKBP9', 'FLCN', 'FLII', 'FLNA', 'FLOT2', 'FLT3LG', 'FLVCR2', 'FN1', 'FNBP1', 'FNDC3B', 'FNIP2', 'FOS', 'FOSL2', 'FOXK1', 'FOXN3', 'FOXO3', 'FOXP1', 'FOXP4', 'FPGS', 'FRA10AC1', 'FRAT2', 'FRG1', 'FRZB', 'FSTL1', 'FTH1', 'FTL', 'FUBP1', 'FUBP3', 'FUOM', 'FUS', 'FXR1', 'FXYD1', 'FXYD6', 'G0S2', 'G3BP2', 'GABARAP', 'GABARAPL1', 'GABARAPL2', 'GADD45A', 'GADD45B', 'GADD45GIP1', 'GAK', 'GALNS', 'GALNT2', 'GALNT6', 'GALT', 'GANAB', 'GAS6', 'GASK1B', 'GATAD2A', 'GATD1', 'GBF1', 'GBP2', 'GBP4', 'GCHFR', 'GCN1', 'GDE1', 'GDI1', 'GDPGP1', 'GET3', 'GFER', 'GFOD1', 'GGNBP2', 'GGT1', 'GID8', 'GIGYF2', 'GIPC1', 'GIT1', 'GJA1', 'GK5', 'GLG1', 'GLO1', 'GLOD4', 'GLRX5', 'GLS', 'GLUD1', 'GLUL', 'GLYCTK', 'GLYR1', 'GMFG', 'GMIP', 'GMPS', 'GNAI2', 'GNAI3', 'GNAQ', 'GNAS', 'GNB1', 'GNLY', 'GNPTG', 'GOLGA3', 'GOLGA4', 'GOLGA5', 'GOLGA7', 'GOLGB1', 'GOLM1', 'GOLPH3', 'GORASP1', 'GOSR1', 'GPAA1', 'GPALPP1', 'GPATCH2L', 'GPCPD1', 'GPI', 'GPN2', 'GPR107', 'GPR108', 'GPR89B', 'GPS1', 'GPX4', 'GREM1', 'GRHPR', 'GRINA', 'GRIPAP1', 'GRK2', 'GRN', 'GRSF1', 'GSDMB', 'GSK3A', 'GSN', 'GSTK1', 'GSTO1', 'GSTP1', 'GTF2F1', 'GTF2F2', 'GTF2I', 'GTF2IRD1', 'GTF3C1', 'GTF3C3', 'GTF3C5', 'GTF3C6', 'GTPBP1', 'GTPBP10', 'GTPBP2', 'GTPBP3', 'GTPBP6', 'GUCY1A1', 'GUK1', 'GYPC', 'GZF1', 'H1FX', 'H2AFJ', 'H2AFV', 'H2AFY', 'H3F3A', 'H3F3B', 'H6PD', 'HAAO', 'HABP4', 'HACL1', 'HADHA', 'HADHB', 'HAGH', 'HARS', 'HARS2', 'HBS1L', 'HCFC1', 'HCFC1R1', 'HDAC1', 'HDAC10', 'HDAC5', 'HDGF', 'HDHD2', 'HDHD3', 'HDLBP', 'HEATR5B', 'HEBP2', 'HECA', 'HECTD1', 'HERC2', 'HERC4', 'HERPUD1', 'HES4', 'HEXA', 'HGS', 'HGSNAT', 'HIBADH', 'HIC1', 'HINT1', 'HIP1R', 'HIPK3', 'HIST1H1D', 'HIST1H1E', 'HIST1H2AD', 'HIST1H2AE', 'HIST1H2BD', 'HIST1H2BN', 'HIST1H3D', 'HIST1H3G', 'HIST1H4A', 'HIST1H4B', 'HIST1H4C', 'HIST1H4D', 'HIST1H4E', 'HIST1H4H', 'HIST2H2AB', 'HK1', 'HLA-DMA', 'HLA-DMB', 'HLA-DOA', 'HLA-DPA1', 'HLA-DPB1', 'HLA-DRA', 'HLA-E', 'HLA-F', 'HMG20B', 'HMGA1', 'HMGB1', 'HMGN3', 'HMGN4', 'HMOX1', 'HNRNPA0', 'HNRNPA2B1', 'HNRNPA3', 'HNRNPAB', 'HNRNPC', 'HNRNPD', 'HNRNPDL', 'HNRNPF', 'HNRNPH1', 'HNRNPH3', 'HNRNPK', 'HNRNPLL', 'HNRNPR', 'HNRNPU', 'HNRNPUL2', 'HP1BP3', 'HPCAL1', 'HRAS', 'HSBP1', 'HSF1', 'HSP90AA1', 'HSP90AB1', 'HSPA1A', 'HSPA1B', 'HSPA5', 'HSPA8', 'HSPB1', 'HSPB2', 'HSPB6', 'HSPD1', 'HSPE1', 'HSPG2', 'HTATIP2', 'HTRA1', 'HUS1', 'HUWE1', 'HYI', 'IBTK', 'ICAM2', 'ICMT', 'ID1', 'ID2', 'IDH2', 'IDH3G', 'IDI1', 'IDS', 'IER2', 'IER5', 'IFI27', 'IFI6', 'IFITM2', 'IFITM3', 'IFNAR1', 'IFNGR2', 'IFRD2', 'IFT122', 'IFT20', 'IGBP1', 'IGFBP3', 'IGFBP4', 'IGFBP5', 'IGFBP7', 'IGHA1', 'IGHMBP2', 'IGKC', 'IGSF8', 'IK', 'IKBKB', 'IKBKE', 'IKBKG', 'IL10RB', 'IL17RA', 'IL2RG', 'IL32', 'IL4R', 'IL6R', 'IL6ST', 'ILF3', 'ILRUN', 'ILVBL', 'IMMP1L', 'IMP3', 'INAFM1', 'INCENP', 'INF2', 'ING4', 'INO80B', 'INO80E', 'INPPL1', 'INSIG1', 'INSR', 'INTS1', 'INTS10', 'INTS11', 'INTS3', 'INTS4', 'IP6K2', 'IQGAP1', 'IRAK1', 'IRF1', 'IRF3', 'IRF9', 'ISCA1', 'ISCU', 'ISG15', 'ISG20', 'ITGA3', 'ITGA5', 'ITGA6', 'ITGB1', 'ITGB5', 'ITM2A', 'ITM2B', 'ITM2C', 'ITPKB', 'ITPKC', 'ITPR3', 'ITPRIPL2', 'IWS1', 'JCHAIN', 'JDP2', 'JMJD4', 'JMY', 'JPT1', 'JRK', 'JTB', 'JUN', 'JUNB', 'KANK2', 'KANSL3', 'KCMF1', 'KCNMA1', 'KCNMB1', 'KCTD12', 'KCTD13', 'KDELR1', 'KDELR2', 'KDM1A', 'KDM2A', 'KDM5B', 'KDM6A', 'KDM6B', 'KDSR', 'KHDC4', 'KHDRBS1', 'KHNYN', 'KHSRP', 'KIAA1211', 'KIF1B', 'KIF1C', 'KIFC2', 'KLC1', 'KLC4', 'KLF4', 'KLF6', 'KLF9', 'KLHDC4', 'KLHL12', 'KLHL21', 'KLHL24', 'KLHL42', 'KLHL5', 'KMT2B', 'KMT2C', 'KMT2D', 'KMT2E', 'KMT5B', 'KPNB1', 'KRAS', 'KRCC1', 'KRI1', 'KRT10', 'KRT8', 'KSR1', 'KXD1', 'LAMA4', 'LAMA5', 'LAMB1', 'LAMB2', 'LAMC1', 'LAMP1', 'LAMTOR1', 'LAMTOR4', 'LAP3', 'LAPTM5', 'LARP1B', 'LARP4', 'LARP4B', 'LARS', 'LAS1L', 'LASP1', 'LBH', 'LCMT1', 'LCOR', 'LDB1', 'LEMD2', 'LENG8', 'LEO1', 'LEPROT', 'LETMD1', 'LGALS1', 'LGALS3', 'LGALS3BP', 'LGMN', 'LHFPL6', 'LHPP', 'LIG3', 'LIMD1', 'LIMS2', 'LIN52', 'LIN7B', 'LITAF', 'LMAN2', 'LMNA', 'LMNB2', 'LMO4', 'LMO7', 'LMOD1', 'LONP1', 'LPCAT1', 'LPCAT4', 'LPGAT1', 'LPIN2', 'LRCH4', 'LRIG1', 'LRP1', 'LRP10', 'LRPAP1', 'LRRC40', 'LRRC47', 'LSM1', 'LSM10', 'LSM14A', 'LSM14B', 'LSM4', 'LSM5', 'LSM6', 'LSM8', 'LSP1', 'LTB', 'LTBP3', 'LTBP4', 'LTBR', 'LUC7L', 'LUC7L2', 'LUM', 'LYPLAL1', 'LYZ', 'LZIC', 'LZTS2', 'M6PR', 'MACF1', 'MACO1', 'MACROD1', 'MAF', 'MAGI1', 'MAN1A1', 'MAN1B1', 'MAN2A1', 'MAN2A2', 'MAN2B1', 'MAN2B2', 'MAN2C1', 'MANBAL', 'MAP1B', 'MAP2K1', 'MAP2K2', 'MAP2K3', 'MAP2K7', 'MAP3K11', 'MAP4', 'MAP7D1', 'MAPK13', 'MAPK14', 'MAPK1IP1L', 'MAPK3', 'MAPK8IP3', 'MAPKAP1', 'MAPKAPK5', 'MAPRE1', 'MARCH2', 'MARCH6', 'MARCH8', 'MARCKS', 'MARCKSL1', 'MARK2', 'MARVELD1', 'MAST3', 'MAT2A', 'MAT2B', 'MATR3', 'MAVS', 'MAX', 'MAZ', 'MBD5', 'MBNL1', 'MBNL2', 'MBOAT7', 'MBP', 'MBTD1', 'MBTPS1', 'MCAM', 'MCF2L', 'MCFD2', 'MCL1', 'MCM5', 'MCM6', 'MCM7', 'MCPH1', 'MCRIP1', 'MCRIP2', 'MCRS1', 'MCUR1', 'MDH1', 'MDH2', 'MDM4', 'ME3', 'MEAF6', 'MECR', 'MED13L', 'MED15', 'MED16', 'MED22', 'MED24', 'MED25', 'MEF2A', 'MEPCE', 'METAP2', 'METRNL', 'METTL2A', 'MFF', 'MFGE8', 'MFSD1', 'MFSD10', 'MFSD11', 'MFSD14A', 'MFSD14B', 'MFSD3', 'MGAT1', 'MGAT4A', 'MGAT4B', 'MGAT5', 'MGRN1', 'MIA2', 'MICA', 'MICAL2', 'MICOS10', 'MID1IP1', 'MIDN', 'MIEF1', 'MIEN1', 'MIER1', 'MIF', 'MIGA2', 'MIIP', 'MINDY2', 'MINK1', 'MKNK1', 'MKNK2', 'MKRN1', 'MKRN2', 'MLEC', 'MLF2', 'MLLT1', 'MLLT6', 'MMADHC', 'MMP14', 'MMP2', 'MMP24OS', 'MOB1A', 'MOB3B', 'MOB4', 'MOGS', 'MORF4L1', 'MOV10', 'MPC1', 'MPC2', 'MPDU1', 'MPEG1', 'MPG', 'MPST', 'MRGBP', 'MRGPRF', 'MRI1', 'MRNIP', 'MROH1', 'MRTFA', 'MRVI1', 'MSL1', 'MSRB2', 'MT1E', 'MT1X', 'MT2A', 'MTA1', 'MTA3', 'MTCH1', 'MTCH2', 'MTDH', 'MTFR1L', 'MTG1', 'MTLN', 'MTMR4', 'MTPN', 'MTX2', 'MUS81', 'MVD', 'MVP', 'MXD4', 'MXI1', 'MXRA7', 'MXRA8', 'MYADM', 'MYD88', 'MYDGF', 'MYH9', 'MYL12B', 'MYL9', 'MYLK', 'MYO10', 'MYO15B', 'MYO18A', 'MYO19', 'MYO1C', 'MZF1', 'N4BP1', 'NAA60', 'NAB1', 'NABP1', 'NADSYN1', 'NAGLU', 'NAIP', 'NAP1L4', 'NAPA', 'NARS', 'NAT9', 'NAXD', 'NBL1', 'NBR1', 'NCAPD3', 'NCBP2', 'NCK2', 'NCKAP1', 'NCL', 'NCLN', 'NCOA2', 'NCOR2', 'NCSTN', 'NDEL1', 'NDFIP1', 'NDFIP2', 'NDRG1', 'NDRG2', 'NDST1', 'NDST2', 'NDUFA1', 'NDUFA10', 'NDUFA11', 'NDUFA12', 'NDUFA13', 'NDUFA2', 'NDUFA7', 'NDUFA8', 'NDUFA9', 'NDUFAF2', 'NDUFAF3', 'NDUFAF5', 'NDUFB10', 'NDUFB11', 'NDUFB2', 'NDUFB6', 'NDUFB7', 'NDUFB9', 'NDUFC1', 'NDUFC2', 'NDUFS1', 'NDUFS2', 'NDUFS3', 'NDUFS4', 'NDUFS5', 'NDUFS6', 'NDUFS7', 'NDUFS8', 'NDUFV1', 'NDUFV2', 'NDUFV3', 'NECAP2', 'NEDD8', 'NEDD9', 'NEGR1', 'NEK6', 'NEK7', 'NEK9', 'NELFE', 'NEMF', 'NENF', 'NF2', 'NFATC3', 'NFE2L1', 'NFE2L2', 'NFIA', 'NFIB', 'NFIC', 'NFIL3', 'NFKB1', 'NFKB2', 'NFKBIA', 'NFKBIE', 'NFX1', 'NFYC', 'NHP2', 'NHSL1', 'NIBAN2', 'NIPAL2', 'NIPBL', 'NISCH', 'NIT1', 'NKIRAS2', 'NKTR', 'NME2', 'NME3', 'NMRAL1', 'NMT1', 'NOL10', 'NOL12', 'NOL4L', 'NOM1', 'NONO', 'NOP53', 'NPC2', 'NPDC1', 'NPEPL1', 'NPHP3', 'NPTN', 'NR1H3', 'NR2F2', 'NR2F6', 'NRDC', 'NRIP1', 'NRP2', 'NSA2', 'NSF', 'NSMCE4A', 'NSMF', 'NT5C', 'NT5C2', 'NTMT1', 'NTPCR', 'NUBP2', 'NUCB1', 'NUCKS1', 'NUDC', 'NUDT15', 'NUDT16', 'NUDT3', 'NUMA1', 'NUMB', 'NUP214', 'NUP42', 'NUP54', 'NUP62', 'NUP85', 'NUP88', 'NUPR1', 'NUTF2', 'NXF1', 'NXN', 'OAF', 'OAS3', 'OAZ1', 'OAZ2', 'OBSCN', 'OBSL1', 'OCEL1', 'OCIAD1', 'ODF2L', 'OGDH', 'OGN', 'OLFM1', 'OPA1', 'OPTN', 'ORC5', 'ORMDL3', 'OSBPL9', 'OSER1', 'OSGEP', 'OSTF1', 'OSTM1', 'OTUB1', 'OTUD4', 'OTUD5', 'OXLD1', 'P2RX4', 'P4HA2', 'P4HB', 'PA2G4', 'PABPC1', 'PABPC4', 'PACS2', 'PACSIN2', 'PAFAH1B1', 'PAFAH2', 'PAG1', 'PAK4', 'PALLD', 'PALM2-AKAP2', 'PAM', 'PANK4', 'PAPSS2', 'PARD3', 'PARK7', 'PARL', 'PARP10', 'PARP4', 'PATJ', 'PAXBP1', 'PAXX', 'PBRM1', 'PBX1', 'PBXIP1', 'PCBP1', 'PCBP2', 'PCED1A', 'PCGF2', 'PCID2', 'PCK2', 'PCM1', 'PCMT1', 'PCNT', 'PCNX1', 'PCOLCE', 'PCSK5', 'PCSK7', 'PCYOX1', 'PCYT2', 'PDCD4', 'PDCD5', 'PDCD6', 'PDE6D', 'PDGFA', 'PDGFRA', 'PDGFRB', 'PDHA1', 'PDHB', 'PDIA4', 'PDIA6', 'PDLIM2', 'PDLIM3', 'PDLIM4', 'PDLIM5', 'PDLIM7', 'PDRG1', 'PDS5A', 'PDXK', 'PEA15', 'PEBP1', 'PECAM1', 'PELP1', 'PES1', 'PET100', 'PEX13', 'PEX16', 'PEX26', 'PEX6', 'PFAS', 'PFDN5', 'PFKL', 'PFKM', 'PFKP', 'PFN1', 'PFN2', 'PGAM1', 'PGD', 'PGGHG', 'PGGT1B', 'PGK1', 'PGLS', 'PGM1', 'PGP', 'PGRMC2', 'PHB2', 'PHF1', 'PHF11', 'PHF19', 'PHF20', 'PHF20L1', 'PHF23', 'PHGDH', 'PHIP', 'PHLDB1', 'PHLDB2', 'PHPT1', 'PHRF1', 'PHYKPL', 'PI4K2A', 'PI4KA', 'PIAS4', 'PIEZO1', 'PIGC', 'PIGH', 'PIGO', 'PIGT', 'PIH1D1', 'PIK3C2B', 'PIK3CB', 'PILRB', 'PIM1', 'PIM3', 'PIN1', 'PIP4K2B', 'PIP4K2C', 'PIP5K1C', 'PISD', 'PITPNA', 'PITPNM1', 'PJA2', 'PKD2', 'PKIG', 'PLAAT4', 'PLAUR', 'PLCB3', 'PLD2', 'PLD3', 'PLEC', 'PLEKHA8', 'PLEKHG2', 'PLEKHG5', 'PLEKHH3', 'PLEKHM2', 'PLEKHO1', 'PLIN3', 'PLOD2', 'PLPP1', 'PLPP3', 'PLPPR2', 'PLRG1', 'PLS3', 'PLSCR1', 'PLSCR3', 'PLXDC2', 'PLXNB2', 'PLXND1', 'PMEPA1', 'PMF1', 'PML', 'PMM1', 'PMPCB', 'PMVK', 'PNKD', 'PNKP', 'PNN', 'PNPLA2', 'PNPLA6', 'PNRC1', 'PNRC2', 'POFUT2', 'POLA2', 'POLD2', 'POLD4', 'POLDIP2', 'POLDIP3', 'POLG', 'POLG2', 'POLR1D', 'POLR2A', 'POLR2B', 'POLR2C', 'POLR2F', 'POLR2G', 'POLR2H', 'POLR2I', 'POLR2L', 'POLR3A', 'POLR3D', 'POLR3E', 'POM121', 'POMT1', 'POR', 'PPA2', 'PPARG', 'PPDPF', 'PPFIA1', 'PPFIBP1', 'PPIB', 'PPIE', 'PPIL2', 'PPIL4', 'PPIP5K2', 'PPM1A', 'PPM1F', 'PPM1G', 'PPP1CA', 'PPP1CC', 'PPP1R10', 'PPP1R12B', 'PPP1R12C', 'PPP1R14A', 'PPP1R15A', 'PPP1R15B', 'PPP1R16A', 'PPP1R18', 'PPP1R35', 'PPP1R9B', 'PPP2CB', 'PPP2R2D', 'PPP2R3C', 'PPP2R5C', 'PPP3CB', 'PPP4R2', 'PPP4R3A', 'PPP6R1', 'PPP6R2', 'PQBP1', 'PRAG1', 'PRCC', 'PRDM2', 'PRDX4', 'PRDX5', 'PRDX6', 'PRELID3B', 'PREP', 'PREPL', 'PRKAB1', 'PRKAB2', 'PRKACA', 'PRKAR1B', 'PRKAR2A', 'PRKAR2B', 'PRKCD', 'PRKD2', 'PRKG1', 'PRKRIP1', 'PRMT2', 'PRNP', 'PRPF3', 'PRPF38A', 'PRPF39', 'PRPF4B', 'PRPF6', 'PRPF8', 'PRPSAP1', 'PRR13', 'PRR14', 'PRRC1', 'PRRC2A', 'PRRC2B', 'PRRC2C', 'PRSS23', 'PRXL2A', 'PRXL2B', 'PSAP', 'PSD4', 'PSEN1', 'PSENEN', 'PSIP1', 'PSKH1', 'PSMA1', 'PSMA2', 'PSMA4', 'PSMA5', 'PSMA7', 'PSMB1', 'PSMB10', 'PSMB2', 'PSMB4', 'PSMB5', 'PSMB7', 'PSMB8', 'PSMC3', 'PSMC4', 'PSMC5', 'PSMD10', 'PSMD11', 'PSMD13', 'PSMD2', 'PSMD4', 'PSMD8', 'PSME1', 'PSME2', 'PSMF1', 'PTAR1', 'PTBP3', 'PTGDS', 'PTGER4', 'PTGES2', 'PTGES3', 'PTGS1', 'PTK2', 'PTK2B', 'PTMS', 'PTN', 'PTOV1', 'PTPA', 'PTPN18', 'PTPRA', 'PTPRC', 'PTPRE', 'PTPRG', 'PTPRJ', 'PTTG1IP', 'PUF60', 'PUM1', 'PURB', 'PYCARD', 'PYCR2', 'PYGO2', 'PYURF', 'QARS', 'QDPR', 'QKI', 'QRICH1', 'QSOX1', 'QSOX2', 'QTRT1', 'R3HCC1', 'RAB11A', 'RAB13', 'RAB14', 'RAB18', 'RAB1A', 'RAB1B', 'RAB21', 'RAB24', 'RAB27A', 'RAB4B', 'RAB5A', 'RAB5B', 'RAB5C', 'RAB5IF', 'RAB7A', 'RAB9A', 'RABAC1', 'RABEP2', 'RABGAP1L', 'RABGGTB', 'RABIF', 'RABL3', 'RABL6', 'RAC1', 'RACK1', 'RAD23A', 'RALA', 'RALY', 'RANBP2', 'RAP1A', 'RAPGEF1', 'RARRES2', 'RARS', 'RASA2', 'RASD1', 'RASSF4', 'RB1', 'RBBP6', 'RBCK1', 'RBL2', 'RBM12', 'RBM14', 'RBM15B', 'RBM17', 'RBM23', 'RBM26', 'RBM3', 'RBM38', 'RBM39', 'RBM42', 'RBM5', 'RBM6', 'RBM8A', 'RBMX2', 'RBX1', 'RCAN1', 'RCC2', 'RCN2', 'RCN3', 'RDH5', 'REEP3', 'REEP5', 'RELA', 'RELCH', 'RELL1', 'REPIN1', 'RER1', 'RERE', 'REX1BD', 'REXO2', 'RFFL', 'RFNG', 'RFX1', 'RFX5', 'RGL2', 'RHBDD3', 'RHOA', 'RHOB', 'RHOF', 'RHOG', 'RHOT2', 'RHOU', 'RIC8A', 'RILP', 'RILPL1', 'RING1', 'RMC1', 'RMND5A', 'RNASE1', 'RNASET2', 'RNF10', 'RNF11', 'RNF114', 'RNF121', 'RNF123', 'RNF126', 'RNF13', 'RNF135', 'RNF141', 'RNF146', 'RNF149', 'RNF167', 'RNF185', 'RNF187', 'RNF213', 'RNF216', 'RNF26', 'RNF4', 'RNF41', 'RNF5', 'RNFT1', 'RNH1', 'RNPEP', 'RO60', 'ROCK1', 'ROMO1', 'RPF1', 'RPH3AL', 'RPN1', 'RPN2', 'RRAGB', 'RRAS', 'RRAS2', 'RREB1', 'RRP7A', 'RRP8', 'RSBN1', 'RSRP1', 'RTCA', 'RTCB', 'RTF2', 'RTL8C', 'RTN4', 'RTRAF', 'RUFY2', 'RUNX1', 'RUVBL2', 'RWDD1', 'RXRA', 'S100A10', 'S100A11', 'S100A13', 'S100A16', 'S100A4', 'S100A6', 'SAFB', 'SAFB2', 'SAMD4B', 'SAMHD1', 'SAMM50', 'SAP18', 'SAP30', 'SAP30BP', 'SAR1A', 'SAR1B', 'SARS', 'SART1', 'SART3', 'SAT1', 'SAT2', 'SBNO1', 'SBNO2', 'SCAF1', 'SCAF11', 'SCAF4', 'SCAMP5', 'SCAND1', 'SCAP', 'SCARB1', 'SCARF1', 'SCP2', 'SCPEP1', 'SCRIB', 'SCYL1', 'SDC1', 'SDC4', 'SDCBP', 'SDE2', 'SDF2', 'SDF2L1', 'SDF4', 'SDHA', 'SEC11A', 'SEC11C', 'SEC13', 'SEC22B', 'SEC23A', 'SEC24C', 'SEC24D', 'SEC63', 'SEL1L3', 'SELENBP1', 'SELENOH', 'SELENOK', 'SELENOM', 'SELENOO', 'SELENOS', 'SELENOW', 'SEM1', 'SEMA3G', 'SEMA4C', 'SEMA5A', 'SENP2', 'SEPHS2', 'SEPTIN2', 'SEPTIN6', 'SERBP1', 'SERF2', 'SERP1', 'SERPINB6', 'SERPINF1', 'SERTAD1', 'SESN2', 'SET', 'SETD3', 'SETD4', 'SETX', 'SF3B1', 'SF3B2', 'SF3B5', 'SF3B6', 'SFI1', 'SFPQ', 'SFXN3', 'SGK1', 'SGPL1', 'SGPP1', 'SGTA', 'SH2B1', 'SH3BGRL', 'SH3BGRL3', 'SH3BP1', 'SH3BP5', 'SH3BP5L', 'SH3D21', 'SH3GLB2', 'SH3PXD2A', 'SH3YL1', 'SHARPIN', 'SHFL', 'SHISA5', 'SHKBP1', 'SHTN1', 'SIGIRR', 'SIGMAR1', 'SIK3', 'SIL1', 'SIRT5', 'SIRT7', 'SIVA1', 'SKAP1', 'SKI', 'SKIL', 'SLA2', 'SLBP', 'SLC12A4', 'SLC16A1', 'SLC16A3', 'SLC25A10', 'SLC25A28', 'SLC25A3', 'SLC25A37', 'SLC25A39', 'SLC25A4', 'SLC26A2', 'SLC2A4RG', 'SLC30A9', 'SLC31A1', 'SLC35A4', 'SLC35B1', 'SLC35C2', 'SLC36A1', 'SLC37A1', 'SLC38A1', 'SLC38A10', 'SLC39A1', 'SLC39A11', 'SLC39A14', 'SLC39A7', 'SLC39A9', 'SLC3A2', 'SLC43A2', 'SLC44A2', 'SLC4A2', 'SLC5A3', 'SLC66A1', 'SLC9A3R1', 'SLC9A3R2', 'SLCO2B1', 'SLIRP', 'SLMAP', 'SLTM', 'SMAD3', 'SMAD4', 'SMAD7', 'SMARCA2', 'SMARCC1', 'SMARCC2', 'SMARCD2', 'SMARCE1', 'SMC5', 'SMCHD1', 'SMCO4', 'SMDT1', 'SMG1', 'SMIM12', 'SMIM20', 'SMIM4', 'SMPD1', 'SMPD4', 'SMTN', 'SNAP47', 'SNCG', 'SND1', 'SNF8', 'SNRK', 'SNRNP200', 'SNRNP25', 'SNRNP35', 'SNRPB', 'SNRPC', 'SNRPD1', 'SNRPG', 'SNU13', 'SNX1', 'SNX17', 'SNX19', 'SNX29', 'SNX3', 'SNX30', 'SNX33', 'SNX4', 'SOD1', 'SOD2', 'SOD3', 'SOGA1', 'SON', 'SORBS1', 'SORBS3', 'SORL1', 'SOX12', 'SOX13', 'SPAG7', 'SPARC', 'SPARCL1', 'SPCS3', 'SPECC1', 'SPG11', 'SPG21', 'SPHK2', 'SPIN1', 'SPNS1', 'SPON2', 'SPRYD3', 'SPSB3', 'SPTLC1', 'SPTLC2', 'SQOR', 'SQSTM1', 'SRC', 'SRCAP', 'SREBF1', 'SREBF2', 'SRF', 'SRP19', 'SRP68', 'SRP9', 'SRPRA', 'SRRM2', 'SRSF1', 'SRSF11', 'SRSF2', 'SRSF3', 'SRSF5', 'SRSF6', 'SRSF7', 'SSBP1', 'SSBP3', 'SSC5D', 'SSH2', 'SSNA1', 'SSR1', 'SSR2', 'SSR4', 'SSU72', 'ST13', 'ST5', 'ST6GALNAC6', 'STAM2', 'STARD3', 'STARD5', 'STAT2', 'STAT3', 'STAT5A', 'STAT6', 'STAU2', 'STIM1', 'STK11', 'STK17B', 'STK19', 'STK25', 'STK35', 'STK40', 'STOM', 'STRAP', 'STRIP1', 'STRN4', 'STUB1', 'STX10', 'STX4', 'STX7', 'STX8', 'STXBP2', 'SUCLG1', 'SUCLG2', 'SUDS3', 'SUMF2', 'SUMO1', 'SUMO3', 'SUN2', 'SUPT16H', 'SUPT5H', 'SUPT6H', 'SURF1', 'SURF2', 'SURF4', 'SURF6', 'SUZ12', 'SVIL', 'SVIP', 'SYAP1', 'SYNC', 'SYNE2', 'SYNGR2', 'SYNM', 'SYNPO2', 'SYVN1', 'SZRD1', 'SZT2', 'TACC1', 'TADA2B', 'TADA3', 'TAF1', 'TAF10', 'TAF15', 'TAF7', 'TAF8', 'TAGLN', 'TAGLN2', 'TALDO1', 'TAOK1', 'TAOK2', 'TAOK3', 'TAP1', 'TAP2', 'TAPBP', 'TAPBPL', 'TARS', 'TATDN3', 'TAX1BP1', 'TAZ', 'TBC1D1', 'TBC1D17', 'TBC1D22A', 'TBC1D9B', 'TBCB', 'TBCC', 'TBCD', 'TBCK', 'TBRG4', 'TCEA2', 'TCEAL8', 'TCERG1', 'TCF7L2', 'TCHP', 'TCIRG1', 'TCP1', 'TCTA', 'TDP2', 'TDRD7', 'TECPR1', 'TEF', 'TELO2', 'TENT4A', 'TENT5A', 'TERF2IP', 'TES', 'TFG', 'TFPT', 'TGFB1I1', 'TGFBI', 'TGFBR2', 'TGIF1', 'TGM2', 'TGOLN2', 'THAP11', 'THAP7', 'THBS1', 'THG1L', 'THOC2', 'THOC7', 'THRA', 'THRAP3', 'TIAL1', 'TIMM13', 'TIMM44', 'TIMM8B', 'TIMMDC1', 'TIMP1', 'TIMP2', 'TIMP3', 'TKT', 'TLE2', 'TLE5', 'TLK1', 'TLN1', 'TM2D1', 'TM2D2', 'TM9SF1', 'TM9SF3', 'TM9SF4', 'TMBIM1', 'TMBIM6', 'TMC6', 'TMCO4', 'TMED10', 'TMED2', 'TMED5', 'TMED9', 'TMEM101', 'TMEM109', 'TMEM129', 'TMEM134', 'TMEM140', 'TMEM159', 'TMEM161A', 'TMEM167B', 'TMEM168', 'TMEM185B', 'TMEM189', 'TMEM208', 'TMEM214', 'TMEM219', 'TMEM245', 'TMEM256', 'TMEM258', 'TMEM259', 'TMEM263', 'TMEM43', 'TMEM50A', 'TMEM59', 'TMEM63A', 'TMEM70', 'TMEM74B', 'TMEM87B', 'TMEM94', 'TMSB4X', 'TMUB2', 'TMX1', 'TMX2', 'TMX4', 'TNC', 'TNFRSF12A', 'TNFRSF14', 'TNFRSF21', 'TNFSF10', 'TNFSF13', 'TNIK', 'TNIP1', 'TNKS', 'TNKS1BP1', 'TNKS2', 'TNPO1', 'TNS1', 'TNS3', 'TNXB', 'TOB2', 'TOLLIP', 'TOM1', 'TOMM22', 'TOMM5', 'TOMM7', 'TOP1', 'TOP2B', 'TOP3B', 'TOR3A', 'TOX4', 'TP53I11', 'TP53I13', 'TP53I3', 'TPCN2', 'TPD52', 'TPD52L2', 'TPGS1', 'TPGS2', 'TPM1', 'TPM2', 'TPP1', 'TPRA1', 'TPSB2', 'TRA2A', 'TRA2B', 'TRABD', 'TRADD', 'TRAF3', 'TRAF3IP2', 'TRAF4', 'TRAK1', 'TRAM1', 'TRANK1', 'TRAP1', 'TRAPPC1', 'TRAPPC10', 'TRAPPC2L', 'TRAPPC4', 'TRAPPC5', 'TRAPPC6B', 'TRAPPC9', 'TRBC1', 'TRIM11', 'TRIM21', 'TRIM22', 'TRIM25', 'TRIM26', 'TRIM28', 'TRIM38', 'TRIM4', 'TRIM47', 'TRIM56', 'TRIM65', 'TRIM8', 'TRIOBP', 'TRIP12', 'TRIR', 'TRMT11', 'TRMT112', 'TRMT2A', 'TRPC4AP', 'TRPM4', 'TRUB2', 'TSC22D2', 'TSC22D3', 'TSPAN13', 'TSPAN2', 'TSPAN4', 'TSPO', 'TSPYL1', 'TSR3', 'TTC1', 'TTC14', 'TTC17', 'TTC3', 'TTC31', 'TTC37', 'TTC38', 'TTC39B', 'TTC7A', 'TTC9C', 'TTLL3', 'TUBA4A', 'TUBB6', 'TUBGCP2', 'TUBGCP6', 'TUFM', 'TULP4', 'TUT7', 'TXLNA', 'TXN', 'TXN2', 'TXNDC11', 'TXNDC12', 'TXNDC15', 'TXNDC17', 'TXNIP', 'TXNL4A', 'TYK2', 'TYROBP', 'TYSND1', 'U2AF2', 'UACA', 'UBA2', 'UBA52', 'UBB', 'UBC', 'UBE2A', 'UBE2E3', 'UBE2G2', 'UBE2H', 'UBE2J1', 'UBE2L6', 'UBE2Q1', 'UBE2R2', 'UBE2V1', 'UBE3B', 'UBE3C', 'UBE4B', 'UBL3', 'UBL5', 'UBN1', 'UBP1', 'UBQLN4', 'UBR1', 'UBR2', 'UBR4', 'UBR5', 'UBTF', 'UCHL1', 'UGDH', 'ULK1', 'ULK3', 'UNC93B1', 'UPF1', 'UPRT', 'UQCC1', 'UQCC3', 'UQCR11', 'UQCRB', 'UQCRC1', 'UQCRC2', 'UQCRQ', 'URGCP', 'UROD', 'UROS', 'USF1', 'USF2', 'USP11', 'USP19', 'USP22', 'USP25', 'USP32', 'USP33', 'USP34', 'USP36', 'USP4', 'USP40', 'USP7', 'VAMP5', 'VAMP8', 'VAPB', 'VASH1', 'VASP', 'VAT1', 'VAV2', 'VCL', 'VCP', 'VDAC1', 'VDAC2', 'VDAC3', 'VGLL4', 'VIM', 'VMP1', 'VOPP1', 'VPS11', 'VPS13A', 'VPS13C', 'VPS25', 'VPS26B', 'VPS28', 'VPS29', 'VPS33A', 'VPS36', 'VPS37B', 'VPS37C', 'VPS4A', 'VPS4B', 'VPS53', 'VPS9D1', 'VSIR', 'VTI1A', 'VWA1', 'VWF', 'WAC', 'WARS', 'WASF2', 'WASHC2C', 'WASHC5', 'WBP2', 'WDFY1', 'WDR1', 'WDR13', 'WDR18', 'WDR26', 'WDR45B', 'WDR59', 'WDR6', 'WDR82', 'WDR83OS', 'WDTC1', 'WEE1', 'WFS1', 'WIPF1', 'WIPF2', 'WNK1', 'WRNIP1', 'WSB1', 'WSB2', 'XBP1', 'XPC', 'XPNPEP1', 'XPO6', 'XPOT', 'XRCC5', 'XRCC6', 'YAF2', 'YEATS4', 'YIF1A', 'YIF1B', 'YIPF2', 'YIPF3', 'YIPF4', 'YJU2', 'YPEL3', 'YPEL5', 'YTHDC1', 'YWHAG', 'YWHAH', 'YWHAQ', 'YY1', 'YY1AP1', 'ZADH2', 'ZBED5', 'ZBTB38', 'ZBTB43', 'ZBTB7A', 'ZBTB7B', 'ZC3H12D', 'ZC3H18', 'ZC3H4', 'ZCCHC14', 'ZCCHC24', 'ZCCHC3', 'ZDHHC12', 'ZDHHC16', 'ZDHHC2', 'ZDHHC20', 'ZDHHC24', 'ZDHHC4', 'ZDHHC6', 'ZDHHC7', 'ZER1', 'ZFAND1', 'ZFAND2B', 'ZFAND3', 'ZFAND5', 'ZFC3H1', 'ZFP36', 'ZFP36L1', 'ZFP36L2', 'ZFP91', 'ZFPL1', 'ZFR', 'ZFYVE27', 'ZFYVE28', 'ZFYVE9', 'ZGPAT', 'ZHX2', 'ZKSCAN1', 'ZMIZ1', 'ZMIZ2', 'ZMPSTE24', 'ZMYND8', 'ZNF106', 'ZNF124', 'ZNF134', 'ZNF143', 'ZNF195', 'ZNF207', 'ZNF212', 'ZNF264', 'ZNF266', 'ZNF3', 'ZNF317', 'ZNF326', 'ZNF330', 'ZNF33A', 'ZNF358', 'ZNF410', 'ZNF428', 'ZNF451', 'ZNF496', 'ZNF511', 'ZNF552', 'ZNF586', 'ZNF592', 'ZNF598', 'ZNF622', 'ZNF638', 'ZNF655', 'ZNF688', 'ZNF707', 'ZNF740', 'ZNF747', 'ZNF787', 'ZNFX1', 'ZNHIT3', 'ZRANB2', 'ZSCAN25', 'ZSWIM8', 'ZYX', 'ZZEF1']\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Wrote /project/simmons_hts/kxu/hest/eval/data/VisiumR1-6/var_3000genes.json (top-3000, criteria=var); /project/simmons_hts/kxu/hest/eval/data/VisiumR1-6/all_genes.json (all_common=17943); /project/simmons_hts/kxu/hest/eval/data/VisiumR1-6/common_genes_0.01.json (filtered_common=3046, min_cells_pct=0.01)\n"
     ]
    }
   ],
   "source": [
    "save_dir = Path(\"/project/simmons_hts/kxu/hest/eval/data/VisiumR1-6\")\n",
    "adata_dir = save_dir / \"adata\"\n",
    "adata_paths = sorted([p for p in adata_dir.glob(\"*.h5ad\") if p.is_file()])\n",
    "\n",
    "ks = [1000, 3000]\n",
    "criteria = \"var\"\n",
    "\n",
    "for k in ks:\n",
    "    var_out = save_dir / f\"var_{k}genes.json\"\n",
    "    print(f\"\\n--- computing top-{k} ({criteria}) -> {var_out} ---\")\n",
    "    write_var_k_genes_from_paths(adata_paths, k, criteria, var_out,min_cells_pct=0.01) # 3046 common genes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c19186f",
   "metadata": {},
   "source": [
    "### create leave one patient out cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4494f900",
   "metadata": {},
   "source": [
    "The above split created 19 splits for K+15. Modify it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2256593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def create_splits(dest_dir, splits, K=None):\n",
    "    \"\"\"\n",
    "    Create K patient-level splits where no patient appears in both train and test\n",
    "    for the same split.\n",
    "\n",
    "    Args:\n",
    "        dest_dir (str or Path): directory to write train_i.csv and test_i.csv\n",
    "        splits (dict): mapping patient_id -> list of sample_ids (samples are strings)\n",
    "        K (int or None): number of splits to create. If None, defaults to number of patients.\n",
    "                         If K > number_of_patients, K is reduced to number_of_patients.\n",
    "\n",
    "    Returns:\n",
    "        dict: the patient-chunk splits used (mapping chunk_index -> list of patient_ids)\n",
    "    \"\"\"\n",
    "    dest_dir = Path(dest_dir)\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "\n",
    "    # canonical ordering for determinism\n",
    "    patients = sorted(list(splits.keys()))\n",
    "    n_patients = len(patients)\n",
    "\n",
    "    if n_patients == 0:\n",
    "        raise ValueError(\"splits dict is empty (no patients).\")\n",
    "\n",
    "    if K is None:\n",
    "        K = n_patients\n",
    "\n",
    "    if K < 1:\n",
    "        raise ValueError(\"K must be >= 1\")\n",
    "\n",
    "    # If requested K is greater than number of patients, reduce it (can't split patients finer)\n",
    "    if K > n_patients:\n",
    "        print(f\"Requested K={K} > n_patients={n_patients}; reducing K -> {n_patients}\")\n",
    "        K = n_patients\n",
    "\n",
    "    # chunk patients into exactly K groups (patient-level)\n",
    "    patient_chunks = np.array_split(np.array(patients, dtype=object), K)\n",
    "    # convert to dict: chunk_index -> list(patient_ids)\n",
    "    patient_splits = {i: list(chunk.tolist()) for i, chunk in enumerate(patient_chunks)}\n",
    "\n",
    "    # For each chunk: that chunk's patients -> TEST, other chunks' patients -> TRAIN\n",
    "    for i in range(len(patient_splits)):\n",
    "        test_patients = patient_splits[i]\n",
    "        # flatten sample lists for test\n",
    "        test_ids = [s for p in test_patients for s in splits[p]]\n",
    "\n",
    "        # train patients are all other patient groups\n",
    "        train_patients = [p for j, group in patient_splits.items() if j != i for p in group]\n",
    "        train_ids = [s for p in train_patients for s in splits[p]]\n",
    "\n",
    "        print(f\"Split {i+1}/{len(patient_splits)}: {len(train_ids)} train samples, {len(test_ids)} test samples\")\n",
    "        # optionally print patient-level composition:\n",
    "        print(f\"  test patients: {test_patients}\")\n",
    "        print(\"\")\n",
    "\n",
    "        # Build dataframes (keep same columns as your pipeline expects)\n",
    "        train_df = pd.DataFrame({\n",
    "            \"sample_id\": train_ids,\n",
    "            \"patches_path\": [os.path.join(\"patches\", sid + \".h5\") for sid in train_ids],\n",
    "            \"expr_path\":   [os.path.join(\"adata\", sid + \".h5ad\") for sid in train_ids],\n",
    "        })\n",
    "\n",
    "        test_df = pd.DataFrame({\n",
    "            \"sample_id\": test_ids,\n",
    "            \"patches_path\": [os.path.join(\"patches\", sid + \".h5\") for sid in test_ids],\n",
    "            \"expr_path\":   [os.path.join(\"adata\", sid + \".h5ad\") for sid in test_ids],\n",
    "        })\n",
    "\n",
    "        train_df.to_csv(dest_dir / f\"train_{i}.csv\", index=False)\n",
    "        test_df.to_csv(dest_dir / f\"test_{i}.csv\", index=False)\n",
    "\n",
    "    return patient_splits\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
